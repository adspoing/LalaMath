const data =
[{"model": "mathematics.question", "pk": 9, "fields": {"code": "3.4.5", "category": 3, "problem": "A white rat is put into compartment 4 of the maze shown below.\r\nHe moves through the compartments at random; i.e., if there are k ways to\r\nleave a compartment, he chooses each of these with probability 1/k. What\r\nis the probability that the rat finds the food in compartment 3 before feeling\r\nthe electric shock in compartment 7?", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "$\\frac{7}{12}$", "choicesb": "$\\frac{1}{4}$", "choicesc": "$\\frac{5}{12}$", "choicesd": "$\\frac{1}{3}$", "choicese": "$\\frac{1}{6}$", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "C", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "The question ask about some probability, probability $p_i$ have to be defined for each state.<br>\r\nNote: This probability is different from transition probability $P_{ij}$.Here $P_{ij}$ is $\\frac{1}{k}$.<br>\r\nSince the mouse have to reach 3 before 7, set\r\n\\begin{equation*}\r\np_3=1 \\qquad p_7=0\r\n\\end{equation*}\r\nThen, consider the probability of other states, now you need the transition probabilities\r\n\\begin{align*}\r\np_1&=\\frac{1}{2}p_2+\\frac{1}{2}p_4\\\\\r\np_2&=\\frac{1}{3}p_1+\\frac{1}{3}p_3+\\frac{1}{3}p_5\\\\\r\np_4&=\\frac{1}{3}p_1+\\frac{1}{3}p_5+\\frac{1}{3}p_7\\\\\r\np_5&=\\frac{1}{3}p_2+\\frac{1}{3}p_4+\\frac{1}{3}p_6\\\\\r\np_6&=\\frac{1}{2}p_3+\\frac{1}{2}p_5\\\\\r\n\\end{align*}\r\nThen do Gaussian elimination\r\n\\[\\left(\\begin{array}{ccccccc|c}\r\n1&-1/2&0&-1/2&0&0&0&0\\\\\r\n-1/3&1&-1/3&0&-1/3&0&0&0\\\\\r\n0&0&1&0&0&0&0&1\\\\\r\n-1/3&0&0&1&-1/3&0&-1/3&0\\\\\r\n0&-1/3&0&-1/3&1&-1/3&0&0\\\\\r\n0&0&-1/2&0&-1/2&1&0&0\\\\\r\n0&0&0&0&0&0&1&0\r\n\\end{array}\\right)\\]\r\n\r\nAfter tedious calculation, we have\r\n\\begin{align*}\r\np_1&=7/12\\\\\r\np_2&=3/4\\\\\r\np_4&=5/12\\\\\r\np_5&=2/3\\\\\r\np_6&=5/6\\\\\r\n\\end{align*}\r\n\r\nThe answer is 5/12.", "linkability1": 0.0, "linkability2": 0.0, "linkability3": 0.0, "linkability4": 0.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": null, "difficulty": 3, "calculateddifficulty": null, "linkneuron": [6, 9, 12], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 56, "fields": {"code": "3.1.1", "category": 3, "problem": "A simplified model for the spread of a disease goes this way: The\r\ntotal population size is $N=5$, of which some are diseased and the remainder\r\nare healthy. During any single period of time, two people are selected\r\nat random from the population and assumed to interact. The selection\r\nis such that an encounter between any pair of individuals in the\r\npopulation is just as likely as between any other pair. If one of these persons\r\nis diseased and the other not, then with probability $\\alpha=0.1$ the disease\r\nis transmitted to the healthy person. Otherwise, no disease transmission\r\ntakes place. Let $X_n$, denote the number of diseased persons in the\r\npopulation at the end of the $n$th period. Specify the transition probability\r\nmatrix.", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "\\[\r\n\\begin{array}{c cccccc }\r\n\\,\\,\\,&0 \\,\\,\\,\\,\\,\\,\\,&1\\,\\,\\,\\,\\,\\,\\,&2\\,\\,\\,\\,\\,\\,\\,\r\n&3\\,\\,\\,\\,\\,\\,\\,&4\\,\\,\\,\\,\\,\\,\\,\r\n&5\\,\\,\\,\\,\\,\\,\\, \\\\\r\n\\end{array}\r\n\\]\r\n\\[\r\n\\begin{array}{c||cccccc||}\r\n0&1&0&0&0&0&0\\\\\r\n1&0&0.96&0.04&0&0&0\\\\\r\n2&0&0&0.94&0.06&0&0\\\\\r\n3&0&0&0&0.94&0.06&0\\\\\r\n4&0&0&0&0&0.96&0.04\\\\\r\n5&0&0&0&0&0&1\\\\\r\n\\end{array}\r\n\\]", "choicesb": "\\[\r\n\\begin{array}{c cccccc }\r\n\\,\\,\\,&0 \\,\\,\\,\\,\\,\\,\\,&1\\,\\,\\,\\,\\,\\,\\,&2\\,\\,\\,\\,\\,\\,\\,\r\n&3\\,\\,\\,\\,\\,\\,\\,&4\\,\\,\\,\\,\\,\\,\\,\r\n&5\\,\\,\\,\\,\\,\\,\\, \\\\\r\n\\end{array}\r\n\\]\r\n\\[\r\n\\begin{array}{c||cccccc||}\r\n0&0.96&0.04&0&0&0&0\\\\\r\n1&0&0.96&0.04&0&0&0\\\\\r\n2&0&0&0.94&0.06&0&0\\\\\r\n3&0&0&0&0.94&0.06&0\\\\\r\n4&0&0&0&0&0.96&0.04\\\\\r\n5&0&0&0&0&0&1\\\\\r\n\\end{array}\r\n\\]", "choicesc": "\\[\r\n\\begin{array}{c cccccc }\r\n\\,\\,\\,&0 \\,\\,\\,\\,\\,\\,\\,&1\\,\\,\\,\\,\\,\\,\\,&2\\,\\,\\,\\,\\,\\,\\,\r\n&3\\,\\,\\,\\,\\,\\,\\,&4\\,\\,\\,\\,\\,\\,\\,\r\n&5\\,\\,\\,\\,\\,\\,\\, \\\\\r\n\\end{array}\r\n\\]\r\n\\[\r\n\\begin{array}{c||cccccc||}\r\n0&0&0&0&0&0&0\\\\\r\n1&0&0.96&0.04&0&0&0\\\\\r\n2&0&0&0.94&0.06&0&0\\\\\r\n3&0&0&0&0.94&0.06&0\\\\\r\n4&0&0&0&0&0.96&0.04\\\\\r\n5&0&0&0&0&0&1\\\\\r\n\\end{array}\r\n\\]", "choicesd": "\\[\r\n\\begin{array}{c cccccc }\r\n\\,\\,\\,&0 \\,\\,\\,\\,\\,\\,\\,&1\\,\\,\\,\\,\\,\\,\\,&2\\,\\,\\,\\,\\,\\,\\,\r\n&3\\,\\,\\,\\,\\,\\,\\,&4\\,\\,\\,\\,\\,\\,\\,\r\n&5\\,\\,\\,\\,\\,\\,\\, \\\\\r\n\\end{array}\r\n\\]\r\n\\[\r\n\\begin{array}{c||cccccc||}\r\n0&1&0&0&0&0&0\\\\\r\n1&0&0.96&0.04&0&0&0\\\\\r\n2&0&0&0.94&0.06&0&0\\\\\r\n3&0&0&0&0.94&0.06&0\\\\\r\n4&0&0&0&0&0.96&0.04\\\\\r\n5&0.04&0&0&0&0&0.96\\\\\r\n\\end{array}\r\n\\]", "choicese": "", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "A", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "State i: Number of people infected<br>\r\nType of Interaction that more people get infected($i\\to i+1$): One infected and one uninfected<br>\r\nProbability of such kind of interaction:\r\n$\\binom{i}{1}\\binom{N-i}{1}/\\binom{N}{2}$<br>\r\nTherefore,\r\n\\begin{align*}\r\nP_{i(i+1)}=\\alpha\\binom{i}{1}\\binom{N-i}{1}/\\binom{N}{2}\\\\\r\nP_{ii}=1-\\alpha\\binom{i}{1}\\binom{N-i}{1}/\\binom{N}{2}\r\n\\end{align*}\r\nNote that 0 and 5 are two absorbing state, their diagonal entries is 1.", "linkability1": 0.0, "linkability2": 0.0, "linkability3": 0.0, "linkability4": 0.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": 4.0, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [2, 4], "rightproblems": [], "wrongproblems": [74], "twinproblems": []}}, {"model": "mathematics.question", "pk": 57, "fields": {"code": "3.1.4", "category": 3, "problem": "The random variables $\\xi_1,\\xi_2,...$ are independent and with the common probability mass function\r\n\\[\\begin{array}{ccccc}\\hline\r\nk &=&0&1&2&3\\\\\r\n\\text{Pr}\\{\\xi=k\\}& =&0.1&0.3&0.2&0.4\\\\\\hline\r\n\\end{array}\r\n\\] Set $X_0=0$, and let $X_n$=max\\{$\\xi_1,...,\\xi_n$\\} be the largest $\\xi$ observed to date. Determine the transition probability matrix for the Markov chain \\{$X_n$\\}", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "\\[\r\n\\begin{array}{ccccc }\r\n\\,\\,\\,\\, & 0 \\,\\,\\,\\,\\,\\,\\,&1\\,\\,\\,\\,\\,\\,\\,&2\\,\\,\\,\\,\\,\\,\\,\r\n&3\\\\\r\n\\end{array}\r\n\\]\r\n\\[\r\n\\begin{array}{c||cccc||}\r\n0&0.1&0.3&0.2&0.4\\\\\r\n1&0.1&0.3&0.2&0.4\\\\\r\n2&0.1&0.3&0.2&0.4\\\\\r\n3&0.1&0.3&0.2&0.4\r\n\\end{array}\r\n\\]", "choicesb": "\\[\r\n\\begin{array}{c||cccc||}\r\n&0&1&2&3\\\\\r\n0&0.1&0.3&0.2&0.4\\\\\r\n1&0&0.3&0.2&0.4\\\\\r\n2&0&0&0.2&0.4\\\\\r\n3&0&0&0&0.4\r\n\\end{array}\r\n\\]", "choicesc": "\\[\r\n\\begin{array}{c||cccc||}\r\n&0&1&2&3\\\\\r\n0&0.1&0.3&0.2&0.4\\\\\r\n1&0&0.4&0.2&0.4\\\\\r\n2&0&0&0.6&0.4\\\\\r\n3&0&0&0&1\r\n\\end{array}\r\n\\]", "choicesd": "", "choicese": "", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "C", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "$P_{ij}=0$ if $j\\neq i$ because we only consider the maximum.\r\nMaximum will remain unchanged when you roll a smaller value: those probabilities are added to $P_{ii}$.", "linkability1": 0.0, "linkability2": 0.0, "linkability3": 0.0, "linkability4": 0.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": null, "difficulty": 1, "calculateddifficulty": null, "linkneuron": [2, 4], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 58, "fields": {"code": "3.1.2", "category": 3, "problem": "Consider the problem of sending a binary message, 0 or 1, through a signal channel consisting of several stages, where transmission through each stage is subject to a fixed probability of error ?. Suppose that $ X_0 = 0 $ is the signal that is sent and let $ X_n $ be the signal that is received at the nth stage. Assume that$ \\{X_n\\} $ is a Markov chain with transition probabilities $ P_{00} = P_{11} = 1 - \\alpha $ and $ P_{01} = P_{10} = \\alpha $, where $ 0 < \\alpha < 1 $. <br>\r\n (a) Determine $ \\Pr\\{X_0 =0,X_1 =0,X_2 =0\\}$,the probability that no error occurs up to stage $ n = 2$.<br>\r\n (b) Determine the probability that a correct signal is received at stage 2. (Hint: This is $ \\Pr\\{X_0 = 0,X_1 = 0,X_2 = 0\\} + \\Pr\\{ X_0 = 0 ,X_1 = 1,X_2 =0\\}$.)", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "A. (a) $ 1 - \\alpha \\ $ ;  (b) $  1 - \\alpha $", "choicesb": "B. (a) $ 1 - \\alpha \\ $ ;  (b) $ (1 - \\alpha)^2   $", "choicesc": "C. (a) $ (1 - \\alpha)^2 \\ $ ; (b) $ (1 - \\alpha)^2 $", "choicesd": "D. (a) $ (1 - \\alpha)^2 \\ $ ;  (b) $ 1 - (1 - \\alpha)^2 $", "choicese": "E. (a) $ (1 - \\alpha)^2 \\ $ ; (b) $  1 - 2\\alpha(1 - \\alpha)   $", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "E", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "(a)\r\n\\begin{align*}\r\n\\Pr\\{X_0 = 0,X_1 = 0,X_2 = 0\\} = P_{00} \\cdot P_{00} = \\left( 1 - \\alpha \\right)^2\r\n\\end{align*}\r\n(b) \r\n\\begin{align*}\r\n \\Pr\\{X_0 = 0,X_1 = 0,X_2 = 0\\} + \\Pr\\{ X_0 = 0 ,X_1 = 1,X_2 =0\\}\r\n&= P_{00} \\cdot P_{00} + P_{01} \\cdot P_{10}\\\\\r\n&= \\left( 1 - \\alpha \\right)^2 + \\alpha^2 = 1 - 2\\alpha + 2\\alpha^2 \\\\\r\n&= 1 - 2\\alpha(1-\\alpha)\r\n\\end{align*}", "linkability1": 1.0, "linkability2": 2.0, "linkability3": 1.0, "linkability4": 1.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": 0.0, "errors": "", "alternativesolutions": "", "messagefailure": "Oops, your answer is not correct. You may not fully understand the concept of Markov chain and transition probability. You could try other similar problems.", "messagesuccess": "Good job! You are quite familiar with the concept of Markov chain and transition probability.", "sensitivity": null, "gussingparameter": 0.2, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [3, 6], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 61, "fields": {"code": "3.2.3", "category": 3, "problem": "Let $X_n$ denote the quality of $n$th item produced by a production system with $X_n=0$ meaning \"good\" and $X_n=1$ meaning \"defective.\" Suppose that $X_n$ evolve as a Markov chain whose transition probability matrix is \r\n\\[P=\r\n\\begin{array}{c||cc||}\r\n&0&1\\\\\r\n0&0.99&0.01\\\\\r\n1&0.12&0.88\r\n\\end{array}\r\n\\]\r\nWhat is the probability that the fourth item is defective given that the first item is defective", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "0.973731", "choicesb": "0.026269", "choicesc": "0.315228", "choicesd": "0.684772", "choicese": "0.605752", "choicesf": "0.88", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "D", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "\\[P^{(4-1)}=P^{(3)}=\r\n\\begin{array}{c||cc||}\r\n&0&1\\\\\r\n0&0.973731&0.026269\\\\\r\n1&0.315228&0.684772\r\n\\end{array}\\]\r\nSince we know the first one is defective: original state is 1,\r\nwe want to calculate the probability the probability of defective (1), so we calculate\r\n$P_{11}^{(3)}=0.684772$", "linkability1": 0.0, "linkability2": 0.0, "linkability3": 0.0, "linkability4": 0.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": 5.0, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [2, 5, 10], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 62, "fields": {"code": "3.3.1", "category": 3, "problem": "An urn contains six tags, of which three are red and three green.\r\nTwo tags are selected from the urn. If one tag is red and the other is green,\r\nthen the selected tags are discarded and two blue tags are returned to the\r\nurn. Otherwise, the selected tags are returned to the urn. This process repeats\r\nuntil the urn contains only blue tags. Let $X_n$, denote the number of red\r\ntags in the urn after the $n$th draw, with $X_0=3$. (This is an elementary\r\nmodel of a chemical reaction in which red and green atoms combine to\r\nform a blue molecule.) Give the transition probability matrix.", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "\\[\r\n\\begin{array}{c||cccc||}\r\n&0&1&2&3\\\\\r\n0&1&0&0&0\\\\\r\n1&1/15&14/15&0&0\\\\\r\n2&0&4/15&11/15&0\\\\\r\n3&0&0&3/5&2/5\\\\\r\n\\end{array}\\]", "choicesb": "\\[\r\n\\begin{array}{c||cccc||}\r\n&0&1&2&3\\\\\r\n0&1&0&0&0\\\\\r\n1&14/15&1/15&0&0\\\\\r\n2&0&11/15&4/15&0\\\\\r\n3&0&0&2/5&3/5\\\\\r\n\\end{array}\\]", "choicesc": "\\[\r\n\\begin{array}{c||cccc||}\r\n&0&1&2&3\\\\\r\n0&1&0&0&0\\\\\r\n1&0&14/15&1/15&0\\\\\r\n2&0&0&11/15&4/15\\\\\r\n3&0&0&0&1\\\\\r\n\\end{array}\\]", "choicesd": "", "choicese": "", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "A", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "Consider the possible state in the urn:<br>\r\n3 red, 3 green, 0 blue<br>\r\n2 red, 2 green, 2 blue<br>\r\n1 red, 1 green, 4 blue<br>\r\n0 red, 0 green, 6 blue<br>\r\n\r\nNow we know the transition probability \r\n\\[P_{i(i-1)}=X^2/\\binom{6}{2}\\]\r\n\\[P_{ii}=1-X^2/\\binom{6}{2}\\]\r\n\r\nSo we have the transition probability matrix is\r\n\\[P=\r\n\\begin{array}{c||cccc||}\r\n&0&1&2&3\\\\\r\n0&1&0&0&0\\\\\r\n1&1/15&14/15&0&0\\\\\r\n2&0&4/15&11/15&0\\\\\r\n3&0&0&3/5&2/5\\\\\r\n\\end{array}\\]", "linkability1": 0.0, "linkability2": 0.0, "linkability3": 0.0, "linkability4": 0.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": null, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [2, 6], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 63, "fields": {"code": "3.2.1", "category": 3, "problem": "Consider the Markov chain whose transition probability matrix is given by \r\n\\[ \r\n\\mathbf{P} = \r\n \\begin{array}{l}\r\n \\begin{array}{lllll}\r\n \\hspace{0.1cm} & \\ \\ \\ 0 \\ & \\  \\ 1 \\ \\  & \\hspace{0.05cm} \\ 2 \\ \\  & \\hspace{0.05cm}  3 \\  \\ \\ \\ \\ \\\r\n \\end{array}\\\\\r\n\\begin{array}{c}\r\n0\\\\\r\n1\\\\\r\n2\\\\\r\n3\\\\\r\n\\end{array}\r\n\\begin{Vmatrix}\r\n  0.4 & 0.3 & 0.2 & 0.1 \\\\ \r\n  0.1 & 0.4 & 0.3 & 0.2 \\\\ \r\n  0.3 & 0.2 & 0.1 & 0.4\\\\\t\r\n  0.2 & 0.1 & 0.4 & 0.3 \\\\ \r\n\\end{Vmatrix}\r\n \\end{array}\r\n \\]\r\nSuppose that the initial distribution is $ p_i = \\frac{1}{4} $ for $ i=0,1,2,3 $. Given that $ \\Pr\\{X_n = k\\} = \\frac{1}{4},k=0,1,2,3 $ for all $ n $, where $k$ is the state of the Markov chain. For $n \\in \\mathbb{N}$ (the set of all natural numbers), deduce a general result from this example.", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "A. $ \\Pr\\{X_n = k\\} = \\frac{1}{N + 1} $", "choicesb": "B. $ \\Pr\\{X_n = k\\} = \\frac{1}{N} $", "choicesc": "C. $\\Pr\\{X_n = k\\} = \\frac{N}{N + 1} $", "choicesd": "D. $\\Pr\\{X_n = k\\} = \\frac{1}{k}$", "choicese": "E. No general result can be deduced. The result depends on the transition probabilities.", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "A", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "\\[p_i = \\Pr\\{X_0 = i\\} =  \\frac{1}{4} \\ \\text{for} \\ i = 0, 1, 2, 3\\]\r\nFor $k = 0,1,2,3$ :\r\n\\begin{align*}\r\n\\Pr\\{X_1 = k\\} \r\n&= \\Pr\\{X_1 = k | X_0 = 0\\} \\cdot \\Pr\\{X_0 = 0\\} + \\cdots + \\Pr\\{X_1 = k | X_0 = 3\\} \\cdot \\Pr\\{X_0 = 3\\}\\\\\r\n& \\ \\ \\  (\\text{Slicing the universe according to } X_0 ) \\\\\r\n&= \\sum_{j=0}^{3} \\Pr\\{X_1 = k | X_0 = j\\} \\cdot \\Pr\\{X_0 = j\\} \\\\\r\n&= \\sum_{j=0}^{3} \\textbf{P}_{jk} \\cdot p_j \\ (\\text{by the definition of transition probability})\\\\\r\n&= \\frac{1}{4} \\cdot \\sum_{j=0}^{3} \\textbf{P}_{jk} \\\\\r\n&= \\frac{1}{4} \\cdot 1 \\ (\\text{by the property of transition probability}) \\\\\r\n&= \\frac{1}{4} = \\Pr\\{X_0 = k\\} \r\n\\end{align*}\r\nBy induction, $\\Pr\\{X_n = k\\} = \\Pr\\{X_{n-1} = k\\} = \\cdots = \\Pr\\{X_1 = k\\} = \\Pr\\{X_0 = k\\} = \\frac{1}{4} \\ \\forall n \\in \\mathbb{N}$ ($\\mathbb{N}$ is the set of all natural numbers). <br>\r\nTherefore, for any $N \\in \\mathbb{N}$, \\[\\text{if} \\ \\Pr\\{X_0 = k\\} = \\frac{1}{N + 1} \\ \\text{for} \\  k = 0, 1, ..., N\\] where $k$ is the state of a Markov chain, then \\[\\Pr\\{X_n = k\\} = \\frac{1}{N + 1} \\ \\forall n \\in \\mathbb{N}\\]", "linkability1": 3.0, "linkability2": 1.0, "linkability3": 3.0, "linkability4": 1.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": 0.0, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": 0.2, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [3, 6, 26], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 64, "fields": {"code": "3.3.7", "category": 3, "problem": "A component in a system is placed into service, where it operates until its failure, whereupon it is replaced at the end of the period with a new component having statistically identical properties, and the process repeats. The probability that a component lasts for $k$ periods is $\\alpha_k$, for $k=1,2,...$ Let$X_n$ be the remaining life of the component in service \\emph{at the end of period n}. Then $X_n=0$ means that $X_{n+1}$ will be the total operating life of the next component. Give the transition probabilities for the Markov chain $\\{X_n\\}$.", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "\\[\r\n\\begin{array}{c||cccccc||}\r\n&0&1&2&\\dots&k&\\dots\\\\\r\n0&1&0&0&\\dots&0&\\dots\\\\\r\n1&1&0&0&\\dots&0&\\dots\\\\\r\n2&0&1&0&\\dots&0&\\dots\\\\\r\n\\vdots&\\vdots&\\vdots&\\vdots&\\ddots&\\vdots&\\vdots\\\\\r\n\\end{array}\r\n\\]", "choicesb": "\\[\r\n\\begin{array}{c||cccccc||}\r\n&0&1&2&\\dots&k&\\dots\\\\\r\n0&0&\\alpha_1&\\alpha_2&\\dots&\\alpha_k&\\dots\\\\\r\n1&1&0&0&\\dots&0&\\dots\\\\\r\n2&0&1&0&\\dots&0&\\dots\\\\\r\n\\vdots&\\vdots&\\vdots&\\vdots&\\ddots&\\vdots&\\vdots\\\\\r\n\\end{array}\r\n\\]", "choicesc": "\\[\r\n\\begin{array}{c||cccccc||}\r\n&0&1&2&\\dots&k&\\dots\\\\\r\n0&0&\\alpha_1&\\alpha_2&\\dots&\\alpha_k&\\dots\\\\\r\n1&1-\\alpha_1&\\alpha_1&0&\\dots&0&\\dots\\\\\r\n2&0&1-\\alpha_2&\\alpha_2&\\dots&0&\\dots\\\\\r\n\\vdots&\\vdots&\\vdots&\\vdots&\\ddots&\\vdots&\\vdots\\\\\r\n\\end{array}\r\n\\]", "choicesd": "", "choicese": "", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "B", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "Note that the state always decrease by 1 ($i\\to i-1$) as times go by. Once it reaches 0, it is replaced ($0\\to k$).\r\nSo \r\n\\[P=\r\n\\begin{array}{c||cccccc||}\r\n&0&1&2&\\dots&k&\\dots\\\\\r\n0&0&\\alpha_1&\\alpha_2&\\dots&\\alpha_k&\\dots\\\\\r\n1&1&0&0&\\dots&0&\\dots\\\\\r\n2&0&1&0&\\dots&0&\\dots\\\\\r\n\\vdots&\\vdots&\\vdots&\\vdots&\\ddots&\\vdots&\\vdots\\\\\r\n\\end{array}\r\n\\]", "linkability1": 0.0, "linkability2": 0.0, "linkability3": 0.0, "linkability4": 0.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": null, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [2, 6], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 66, "fields": {"code": "3.2.4", "category": 3, "problem": "Problem: \r\n Suppose $ X_n $ is a two-state Markov chain whose transition probability matrix is \r\n  \\[ \r\n \\mathbf{P} = \r\n \\begin{array}{l}\r\n \\begin{array}{lll}\r\n \\hspace{0.1cm} & \\ \\ \\ \\ \\ 0 \\ & \\  \\  \\  \\  \\  \\  1 \\ \\ \r\n \\end{array} \\\\\r\n \\begin{array}{c}\r\n 0\\\\\r\n 1\\\\\r\n \\end{array}\r\n \\begin{Vmatrix}\r\n \\alpha & 1 - \\alpha   \\\\ \r\n 1 - \\beta & \\beta   \\\\ \r\n \\end{Vmatrix}\r\n \\end{array}\r\n \\]\r\nThen, $ Z_n =(X_{n-1},X_n) $ is a Markov chain having the four states $\\{0, 1, 2, 3\\} = \\{(0,0),(0,1), (1,0), (1,1)\\}$. Determine the transition probability matrix.", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "A. $ \\begin{pmatrix}\r\n \t\\alpha & 1 - \\alpha & 0 & 0\\\\\r\n \t1 - \\beta & \\beta & 0 & 0 \\\\\r\n \t0 & 0 & \\alpha & 1 - \\alpha\\\\\r\n \t0 & 0 & 1 - \\beta & \\beta\\\\\r\n \\end{pmatrix} $", "choicesb": "B. $ \\begin{pmatrix}\r\n0 & 0 & \\alpha & 1 - \\alpha\\\\\r\n0 & 0 & 1 - \\beta & \\beta\\\\\r\n\\alpha & 1 - \\alpha & 0 & 0\\\\\r\n1 - \\beta & \\beta & 0 & 0 \\\\\r\n\\end{pmatrix} $", "choicesc": "C. $ \\begin{pmatrix}\r\n\t\\alpha & 1 - \\alpha & 0 & 0\\\\\r\n0& 0& 1 - \\beta & \\beta \\\\\r\n\t\\alpha & 1 - \\alpha & 0 & 0\\\\\r\n0& 0& 1 - \\beta & \\beta  \\\\\r\n\\end{pmatrix} $", "choicesd": "D. $ \\begin{pmatrix}\r\n1 - \\beta & \\beta & 0 & 0 \\\\\r\n\\alpha & 1 - \\alpha & 0 & 0\\\\\r\n1 - \\beta & \\beta & 0 & 0 \\\\\r\n\\alpha & 1 - \\alpha & 0 & 0\\\\\r\n\\end{pmatrix} $", "choicese": "E. $ \\begin{pmatrix}\r\n0 & 0 &\\alpha & 1 - \\alpha\\\\\r\n1 - \\beta & \\beta & 0 & 0 \\\\\r\n0 & 0 & \\beta & 1 - \\beta  \\\\\r\n1 - \\alpha &  \\alpha & 0 & 0\\\\\r\n\\end{pmatrix} $", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "C", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "\\begin{align*}\r\n\\Pr\\{Z_0 = (0,0) = 0\\} \r\n&= \\textbf{P}_{00} = \\alpha\\\\\r\n\\Pr\\{Z_0 = (0,1) = 1\\} \r\n&= \\textbf{P}_{01} = 1 - \\alpha\\\\\r\n\\Pr\\{Z_0 = (1,0) = 2\\} \r\n&= \\textbf{P}_{10} = 1 - \\beta\\\\\r\n\\Pr\\{Z_0 = (1,1) = 3\\} \r\n&= \\textbf{P}_{11} = \\beta\\\\ \r\n\\\\\r\n\\Pr\\{Z_1 = 0 | Z_0 = 0\\} \r\n&= \\textbf{P}'_{00} = \\textbf{P}_{00}= \\alpha\\\\\r\n\\Pr\\{Z_1 = 1 | Z_0 = 0\\} \r\n&= \\textbf{P}'_{01} = \\textbf{P}_{01} = 1 - \\alpha\\\\\r\n\\Pr\\{Z_1 = 2 | Z_0 = 0\\} \r\n&= \\textbf{P}'_{02} = 0 = \\Pr\\{Z_1 = 3 | Z_0 = 0\\} = \\textbf{P}_{03} \\\\\r\n\\end{align*}\r\nOther transition probabilities are computed similarly, and finally the transition probability matrix is:\r\n \\[\r\n\\mathbf{P}' = \r\n\\begin{array}{l}\r\n\\begin{array}{lllll}\r\n\\hspace{0.075cm} & \\ \\ 0 \\ & \\hspace{0.1cm} \\ \\  1 \\ \\  & \\hspace{0.1cm} \\ \\ \\ \\ 2 \\ \\  & \\hspace{0.1cm} \\  3 \\  \\ \\ \\ \\\\\r\n\\end{array}\\\\\r\n\\begin{array}{c}\r\n0\\\\\r\n1\\\\\r\n2\\\\\r\n3\\\\\r\n\\end{array}\r\n\\begin{Vmatrix}\r\n\\alpha & 1 - \\alpha & 0 & 0  \\\\ \r\n0 & 0 & 1 - \\beta & \\beta \\\\ \r\n\\alpha & 1 - \\alpha & 0 & 0  \\\\ \r\n0 & 0 & 1 - \\beta & \\beta \\\\ \r\n\\end{Vmatrix}\r\n\\end{array}\r\n\\]", "linkability1": 1.0, "linkability2": 3.0, "linkability3": 2.0, "linkability4": 1.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": 0.2, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [6], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 67, "fields": {"code": "3.3.10", "category": 3, "problem": "Consider a discrete-time, periodic reciew inventory model and let $\\xi_n$ be the total demand in period $n$, and let $X_N$ be the inventory quantity on hand at the end-of-period $n$. An ($s,S$) inventory policy is used: If the end-of-oeriod stock is not greater than $s$, then a quantity is instantly procured to bring the level up to $S$. If the end-of-period stock exceeds s, then no replenishment takes place.<br>\r\nSuppose that $\\xi_1, \\xi_2,...$ are undependent random variables where $Pr\\{\\xi_n=0\\}$=0.1, Pr$\\{\\xi_n=1\\}$=0.3, Pr$\\{\\xi_n=2\\}$=0.3, Pr$\\{\\xi_n=3\\}$=0.2, Pr$\\{\\xi_n=4\\}$=0.1. Then $X_0,X_1,...$ is a Markov chain. Determine $P_{41}$ and $P_{04}$.", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "$P_{41}=0.2\\qquad P_{04}=0.4$", "choicesb": "$P_{41}=0.3\\qquad P_{04}=0.3$", "choicesc": "$P_{41}=0.1\\qquad P_{04}=0.2$", "choicesd": "$P_{41}=0.2\\qquad P_{04}=0.1$", "choicese": "", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "A", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "The only possible way to achieve ($4\\to1$) is the demand is 3. Therefore $P_{41}=\\xi_3=0.2$.<br>\r\nAs for $P_{04}$, the possible route can be $\\xi=0$ or $\\xi=4$ or $\\xi=3$\r\n$P_{04}=0.1+0.1+0.2=0.4$", "linkability1": 0.0, "linkability2": 0.0, "linkability3": 0.0, "linkability4": 0.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": null, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 68, "fields": {"code": "3.3.2", "category": 3, "problem": "Three fair coins are tossed, and we let $ X_1 $ denote the number of heads that appear. Those coins that were heads on the first trial (there were $ X_1 $ of them) we pick up and toss again, and now we let $ X_2 $ be the total number of tails, including those left from the first toss. We toss again all coins showing tails, and let $ X_3 $ be the resulting total number of heads, including those left from the previous toss. We continue the process.The pattern is,count heads,toss heads, count tails, toss tails, count heads, toss heads, etc., and $ X_0 = 3 $. Then, $ {Xn} $ is a Markov chain. What is the transition probability matrix?", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "A. $ \\begin{pmatrix}\r\n1 & 0 & 0 & 0\\\\\r\n1/2 & 1/2 & 0 & 0\\\\\r\n1/4 & 1/2 & 1/4 & 0 \\\\\r\n1/8 & 3/8 & 3/8 & 1/8\\\\\r\n\\end{pmatrix}  $", "choicesb": "B. $ \\begin{pmatrix}\r\n1/8 & 3/8 & 3/8 & 1/8\\\\\r\n0 & 1/4 & 1/2 & 1/4 \\\\\r\n0 & 0 & 1/2 & 1/2 \\\\\r\n0 & 0 & 0 & 1\\\\\r\n\\end{pmatrix}  $", "choicesc": "C. $ \\begin{pmatrix}\r\n0 & 0 & 0 & 1\\\\\r\n0 & 0 & 1/2 & 1/2 \\\\\r\n0 & 1/4 & 1/2 & 1/4 \\\\\r\n1/8 & 3/8 & 3/8 & 1/8\\\\\r\n\\end{pmatrix}  $", "choicesd": "D. $ \\begin{pmatrix}\r\n1/8 & 3/8 & 3/8 & 3/8\\\\\r\n1/4 & 1/2 & 1/4 & 0\\\\\r\n1/2 & 1/2 & 0 & 0 \\\\\r\n1 & 0 & 0 & 0 \\\\\r\n\\end{pmatrix}  $", "choicese": "E. $ \\begin{pmatrix}\r\n0 & 0 & 0 & 1\\\\\r\n0 & 0 & 1/2 & 1/2 \\\\\r\n0 & 1/3 & 1/3 & 1/3 \\\\\r\n1/4 & 1/4 & 1/4 & 1/4\\\\\r\n\\end{pmatrix}  $", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "C", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "\\[\\Pr\\{X_0 = 0\\} = \\frac{1}{8}, \\Pr\\{X_0 = 1\\} = \\frac{3}{8}, \\Pr\\{X_0 = 2\\} = \\frac{3}{8}, \\Pr\\{X_0 = 3\\} = \\frac{1}{8} \\]\r\n\r\nIf 0 head appears in the previous toss, then 3 tails must appear in this toss:\r\n\\begin{align*}\r\n\\rightarrow \\Pr\\{X_1 = 0| X_0 = 0\\} \r\n&= \\Pr\\{X_1 = 1| X_0 = 0\\} = \\Pr\\{X_1 = 2| X_0 = 0\\} = 0\\\\\r\n\\Pr\\{X_1 = 3| X_0 = 0\\} \r\n&= 1\\\\\r\n\\end{align*}\r\nIf 1 head appears in the previous toss, then 2 or 3 tails will appear in this toss where both probabilities are 1/2 :\r\n\\begin{align*}\r\n\\rightarrow \\Pr\\{X_1 = 2| X_0 = 1\\} \r\n&= \\frac{1}{2} = \\Pr\\{X_1 = 3| X_0 = 1\\} \\\\\r\n\\Pr\\{X_1 = 0| X_0 = 1\\} \r\n&= 0 = \\Pr\\{X_1 = 1| X_0 = 1\\} \\\\\r\n\\end{align*}\r\nIf 2 head appear in the previous toss, then 1, 2 or 3 tail(s) will appear in this toss where the corresponding probabilities are 1/4, 1/2 and 1/4 respectively :\r\n\\begin{align*}\r\n\\rightarrow \\Pr\\{X_1 = 3| X_0 = 2\\} \r\n&= \\frac{1}{4} = \\Pr\\{X_1 = 1| X_0 = 2\\}\\\\\r\n\\Pr\\{X_1 = 2| X_0 = 2\\}  \r\n&= \\frac{1}{2} \\\\\r\n\\Pr\\{X_1 = 0| X_0 = 2\\} \r\n&= 0  \\\\\r\n\\end{align*}\r\nIf 3 head appear in the previous toss, then 0, 1, 2 or 3 tail(s) will appear in this toss where the corresponding probabilities are 1/8, 3/8, 3/8 and 1/8 respectively :\r\n\\begin{align*}\r\n\\rightarrow \\Pr\\{X_1 = 3| X_0 = 3\\} \r\n&= \\frac{1}{8} = \\Pr\\{X_1 = 0| X_0 = 3\\} \\\\\r\n\\Pr\\{X_1 = 2| X_0 = 3\\} \r\n&= \\frac{3}{8} = \\Pr\\{X_1 = 1| X_0 = 3\\} \r\n\\end{align*}\r\nthe transition probability matrix is:\r\n \\[\r\n \\mathbf{P} = \r\n \\begin{array}{l}\r\n \\begin{array}{lllll}\r\n \\hspace{0.125cm} & \\ \\  \\ 0 \\ & \\hspace{0.125cm} \\ \\ 1 \\ \\  & \\hspace{0.125cm}  \\ 2 \\ \\  & \\hspace{0.125cm} \\  3 \\  \\ \\ \\ \\\\\r\n \\end{array}\\\\\r\n\\begin{array}{c}\r\n0\\\\\r\n1\\\\\r\n2\\\\\r\n3\\\\\r\n\\end{array}\r\n\\begin{Vmatrix}\r\n  0 & 0 & 0 & 1  \\\\ \r\n  0 & 0 & 1/2 & 1/2 \\\\ \r\n  0 & 1/4 & 1/2 & 1/4  \\\\ \r\n  1/8 & 3/8 & 3/8 & 1/8 \\\\ \r\n\\end{Vmatrix}\r\n \\end{array}\r\n \\]", "linkability1": 2.0, "linkability2": 3.0, "linkability3": 1.0, "linkability4": 3.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": 0.2, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [6], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 69, "fields": {"code": "3.3.5", "category": 3, "problem": "You are going to successively flip a quarter until the pattern $ HHT $ appears, that is, until you observe two successive heads followed by a tails. In order to calculate some properties of this game, you set up a Markov chain with the following states: 0,$ H $,$ HH $, and $ HHT $, where 0 represents the starting point, $ H $ represents a single observed head on the last flip, $ HH $ represents two successive heads on the last two flips, and $ HHT $ is the sequence that you are looking for. Observe that if you have just tossed a tails, followed by a heads, a next toss of a tails effectively starts you over again in your quest for the $ HHT $ sequence. Let the state $\\{0, H, HH, HHT\\}$ be state $\\{0, 1, 2, 3\\}$ of this Markov chain $X_n$. Set up the transition probability matrix.", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "A. $ \\begin{pmatrix}\r\n1/2 & 1/2 & 0 & 0\\\\\r\n1/2 & 0 & 1/2 & 0\\\\\r\n1/2 & 0 & 0 & 1/2 \\\\\r\n1 & 0 & 0 & 0  \\\\\r\n\\end{pmatrix}  $", "choicesb": "B. $ \\begin{pmatrix}\r\n1/2 & 1/2 & 0 & 0\\\\\r\n0 & 1/2 & 1/2 & 0\\\\\r\n0 & 0 & 1/2 & 1/2 \\\\\r\n1 & 0 & 0 & 0  \\\\\r\n\\end{pmatrix}  $", "choicesc": "C.  $ \\begin{pmatrix}\r\n1/2 & 1/2 & 0 & 0\\\\\r\n0 & 1/2 & 1/2 & 0\\\\\r\n0 & 0 & 1/2 & 1/2 \\\\\r\n0 & 0 & 0 & 1  \\\\\r\n\\end{pmatrix}  $", "choicesd": "D.  $ \\begin{pmatrix}\r\n1/2 & 1/2 & 0 & 0\\\\\r\n1/2 & 0 & 1/2 & 0\\\\\r\n1/2 & 0 & 0 & 1/2 \\\\\r\n0 & 0 & 0 & 1 \\\\\r\n\\end{pmatrix}  $", "choicese": "E. $ \\begin{pmatrix}\r\n1/2 & 0 & 0 & 1/2\\\\\r\n0 & 1/2 & 0 & 1/2\\\\\r\n0 & 0 & 1/2 & 1/2 \\\\\r\n0 & 0 & 0 & 1  \\\\\r\n\\end{pmatrix}  $", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "D", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "If a head appears in the this toss and no head appeared in the previous toss, then it will become state 1; otherwise it returns to state 0:\r\n\\begin{align*}\r\n\\rightarrow \\Pr\\{X_1 = 0| X_0 = 0\\} \r\n&= \\frac{1}{2} = \\Pr\\{X_1 = 1| X_0 = 0\\} \\\\\r\n\\Pr\\{X_1 = 2| X_0 = 0\\} \r\n&= 0 = \\Pr\\{X_1 = 3| X_0 = 0\\} \\\\\r\n\\end{align*}\r\nIf a head appears in this toss and one head appeared in the previous toss, then it will become state 2; otherwise it returns to state 0:\r\n\\begin{align*}\r\n\\rightarrow \\Pr\\{X_1 = 0| X_0 = 1\\} \r\n&= \\frac{1}{2} = \\Pr\\{X_1 = 2| X_0 = 1\\} \\\\\r\n\\Pr\\{X_1 = 1| X_0 = 1\\} \r\n&= 0 = \\Pr\\{X_1 = 3| X_0 = 1\\} \\\\\r\n\\end{align*}\r\nIf a tail appears in this toss and two heads appeared in the last two tosses, then it will become state 3; otherwise it returns to state 0:\r\n\\begin{align*}\r\n\\rightarrow \\Pr\\{X_1 = 0| X_0 = 2\\} \r\n&= \\frac{1}{2} = \\Pr\\{X_1 = 3| X_0 = 2\\} \\\\\r\n\\Pr\\{X_1 = 1| X_0 = 2\\} \r\n&= 0 = \\Pr\\{X_1 = 2| X_0 = 2\\} \\\\\r\n\\end{align*}\r\nIf it is at state 3, you win the game which means you stay at state 3:\r\n\\begin{align*}\r\n\\rightarrow \\Pr\\{X_1 = 3| X_0 = 3\\} \r\n&= 1  \\\\\r\n\\Pr\\{X_1 = 0| X_0 = 3\\} \r\n&= 0 = \\Pr\\{X_1 = 1| X_0 = 3\\}  = \\Pr\\{X_1 = 2| X_0 = 3\\}\r\n\\end{align*}\r\nthe transition probability matrix is:\r\n \\[\r\n \\mathbf{P} = \r\n \\begin{array}{l}\r\n \\begin{array}{lllll}\r\n \\hspace{0.125cm} & \\ \\  \\ 0 \\ & \\hspace{0.125cm} \\ \\ 1 \\ \\  & \\hspace{0.1cm}  \\ 2 \\ \\  & \\hspace{0.125cm} \\  3 \\  \\ \\ \\ \\\\\r\n \\end{array}\\\\\r\n\\begin{array}{c}\r\n0\\\\\r\n1\\\\\r\n2\\\\\r\n3\\\\\r\n\\end{array}\r\n\\begin{Vmatrix}\r\n  1/2 & 1/2 & 0 & 0  \\\\ \r\n  1/2 & 0 & 1/2 & 0 \\\\ \r\n  1/2 & 0 & 0 & 1/2  \\\\ \r\n  0 & 0 & 0 & 1 \\\\ \r\n\\end{Vmatrix}\r\n \\end{array}\r\n \\]", "linkability1": 2.0, "linkability2": 3.0, "linkability3": 1.0, "linkability4": 3.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": 0.2, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [6], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 70, "fields": {"code": "3.3.8", "category": 3, "problem": "Two urns A and B contain a total of $ N $ balls. Assume that at time $ t $, there were exactly $ k $ balls in A. At time $ t+1 $, an urn is selected at random in proportion to its contents (i.e., A is chosen with probability $ k/N $ and B is chosen with probability $ (N - k)/N $). Then, a ball is selected from A with probability $ p $ or from B with probability $ q $ and placed in the previously chosen urn. Determine the transition matrix for this Markov chain. (Note that the states of this M.C. are $\\{0,1,2,...,N\\}$)", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "A. $ \\begin{pmatrix}\r\n1 & 0 & 0 & \\cdots & 0 & 0\\\\\r\np & q & 0 & \\cdots & 0 & 0\\\\\r\n0 & p & q & \\cdots & 0 & 0\\\\\r\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\r\n0 & 0 & 0 & \\cdots & p & q\\\\\r\n0 & 0 & 0 & \\cdots & 0 & 1\\\\\r\n\\end{pmatrix}  $", "choicesb": "B.$ \\begin{pmatrix}\r\n1 & 0 & 0 & \\cdots & 0 & 0\\\\\r\n\\left(\\frac{1}{N} \\right) p & \\left(\\frac{N-1}{N} \\right)q & 0 & \\cdots & 0 & 0\\\\\r\n0 & \\left(\\frac{2}{N} \\right)p & \\left(\\frac{N-2}{N} \\right)q & \\cdots & 0 & 0\\\\\r\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\r\n0 & 0 & 0 & \\cdots & \\left(\\frac{N-1}{N} \\right) p & \\left(\\frac{1}{N} \\right) q\\\\\r\n0 & 0 & 0 & \\cdots & 0 & 1\\\\\r\n\\end{pmatrix}  $", "choicesc": "C.  $ \\begin{pmatrix}\r\n1 & 0 & 0 & \\cdots & 0 & 0\\\\\r\n\\left(\\frac{N-1}{N} \\right) p & \\left(\\frac{1}{N} \\right)q & 0 & \\cdots & 0 & 0\\\\\r\n0 & \\left(\\frac{N-2}{N} \\right)p & \\left(\\frac{2}{N} \\right)q & \\cdots & 0 & 0\\\\\r\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\r\n0 & 0 & 0 & \\cdots & \\left(\\frac{1}{N} \\right) p & \\left(\\frac{N-1}{N} \\right) q\\\\\r\n0 & 0 & 0 & \\cdots & 0 & 1\\\\\r\n\\end{pmatrix}  $", "choicesd": "D. $ \\begin{pmatrix}\r\n1 & 0 & 0 & \\cdots & 0 & 0\\\\\r\n\\left(\\frac{1}{N} \\right) p & \\left(\\frac{N-1}{N} \\right) p + \\left(\\frac{1}{N} \\right) q  & \\left(\\frac{N-1}{N} \\right) q & \\cdots & 0 & 0\\\\\r\n0 & \\left(\\frac{2}{N} \\right) p & \\left(\\frac{N-2}{N} \\right) p + \\left(\\frac{2}{N} \\right) q & \\cdots & 0 & 0\\\\\r\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\r\n0 & 0 & 0 & \\cdots & \\left(\\frac{1}{N} \\right) p + \\left(\\frac{N-1}{N} \\right) q  & \\left(\\frac{1}{N} \\right) q\\\\\r\n0 & 0 & 0 & \\cdots & 0 & 1\\\\\r\n\\end{pmatrix}  $", "choicese": "E. $ \\begin{pmatrix}\r\n1 & 0 & 0 & \\cdots & 0 & 0\\\\\r\n\\left(\\frac{N-1}{N} \\right) p & \\left(\\frac{1}{N} \\right) p + \\left(\\frac{N-1}{N} \\right) q  & \\left(\\frac{1}{N} \\right) q & \\cdots & 0 & 0\\\\\r\n0 & \\left(\\frac{N-2}{N} \\right) p & \\left(\\frac{2}{N} \\right) p + \\left(\\frac{N-2}{N} \\right) q & \\cdots & 0 & 0\\\\\r\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\r\n0 & 0 & 0 & \\cdots & \\left(\\frac{N-1}{N} \\right) p + \\left(\\frac{1}{N} \\right) q  & \\left(\\frac{N-1}{N} \\right) q\\\\\r\n0 & 0 & 0 & \\cdots & 0 & 1\\\\\r\n\\end{pmatrix}  $", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "E", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "Let $X_n$ be the number of balls in urn A at time $n$ for $n = 0,1,...,N$. Then, for $k=1,2,...,N-1$ and $n=0,1,...$,\r\n\\begin{align*}\r\nX_n \r\n&= k,\\\\\r\n\\Pr\\{X_{n+1} = k - 1 | X_n = k\\} \r\n&= (\\frac{N-k}{N}) \\cdot p,\\\\\r\n\\Pr\\{X_{n+1} = k|X_n = k\\} \r\n&= (\\frac{k}{N}) \\cdot p + (\\frac{N-k}{N}) \\cdot q, \\text{and} \\\\\r\n\\Pr\\{X_{n+1} = k + 1|X_n = k\\} \r\n&= (\\frac{k}{N}) \\cdot q \r\n\\end{align*}\r\nFor $k = 0$, $X_n = 0$, urn B must be chosen. Although urn A may be selected to take out one ball, urn A is empty and therefore number of balls in urn A and urn B will remain 0 and N respectively. It is like the end of the process, and we called this 'ending' state ($X_n = 0$) as '\\textit{absorbing state}'. The corresponding transition probabilities are    \r\n\\begin{align*}\r\n\\Pr\\{X_{n+1} = - 1 | X_n = 0 \\} \r\n&= 0\\\\\r\n\\Pr\\{X_{n+1} = 0 | X_n = 0 \\} \r\n&= 1\\\\\r\n\\Pr\\{X_{n+1} = 1 | X_n = 0 \\} \r\n&= 0\r\n\\end{align*}\r\nSimilarly, for $k = N$, $X_n = N$ urn A must be chosen. It is another absorbing state with transition probabilities \r\n\\begin{align*}\r\n\\Pr\\{X_{n+1} = N - 1 | X_n = N \\} \r\n&= 0\\\\\r\n\\Pr\\{X_{n+1} = N | X_n = N \\} \r\n&= 1\\\\\r\n\\Pr\\{X_{n+1} = N + 1 | X_n = N \\} \r\n&= 0\r\n\\end{align*}\r\nTherefore, the desired transition probability matrix is:\r\n \\[\r\n \\mathbf{P} = \r\n \\begin{array}{l}\r\n \\begin{array}{lllllll}\r\n \\hspace{0.175cm} & \\ \\ \\ \\ \\ \\ \\ \\ \\ 0 \\ & \\hspace{0.125cm} \\ \\ \\ \\ \\ \\ \\ \\ \\ \\  \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ 1 \\ \\  & \\hspace{0.2cm} \\ \\ \\ \\ \\ \\ \\ \\ \\ \\  \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ 2 \\ \\  & \\hspace{0.175cm} \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\cdots & N-1 & N \\\\\r\n \\end{array}\\\\\r\n\\begin{array}[c]{c}\r\n0\\\\ \r\n1\\\\\r\n2\\\\\r\n\\vdots\\\\\r\n\\\\[-1em]\r\nN\\\\\r\n\\end{array}\r\n\\begin{Vmatrix}\r\n  1 & 0 & 0  & \\cdots & \\ \\ \\ 0 & \\ \\ \\ \\ \\ 0 \\ \\ \\\\ \r\n    (\\frac{N-1}{N}) \\cdot p & (\\frac{1}{N}) \\cdot p + (\\frac{N-1}{N}) \\cdot q & (\\frac{1}{N}) \\cdot q & \\cdots & \\ \\ \\ 0 & \\ \\ \\ \\ \\ 0 \\ \\ \\\\ \r\n  0 & (\\frac{N-2}{N}) \\cdot p & (\\frac{2}{N}) \\cdot p + (\\frac{N-2}{N}) \\cdot q & \\cdots & \\ \\ \\ 0 & \\ \\ \\ \\ \\ 0 \\ \\ \\\\\r\n  \\vdots & \\vdots & \\vdots   & \\ddots & \\ \\ \\ 0 & \\ \\ \\ \\ 0 \\ \\\\\\ \r\n  0 & 0 & 0 & \\cdots & \\ \\ \\ 0 & \\ \\ \\ \\ \\ 1 \\ \\ \\\\ \r\n\\end{Vmatrix}\r\n \\end{array}\r\n \\]", "linkability1": 2.0, "linkability2": 3.0, "linkability3": 2.0, "linkability4": 3.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": 0.2, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [6], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 71, "fields": {"code": "3.4.6", "category": 3, "problem": "Consider the Markov chain whose transition matrix is\r\n\\[P=\r\n\\begin{array}{c||ccccc||}\r\n&0&1&2&3&4\\\\\r\n0&q&p&0&0&0\\\\\r\n1&q&0&p&0&0\\\\\r\n2&q&0&0&p&0\\\\\r\n3&q&0&0&0&p\\\\\r\n4&0&0&0&0&1\\\\\r\n\\end{array}\r\n\\]\r\nwhere $p+q=1$. Determine the mean time to reach state 4 starting from  state 0. That is, find $E[T|X_0=i]$ where $T=\\min\\{n\\geq 0; X_n=4\\}$", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "$t_0=\\frac{1}{1-q-pq-p^2q-p^3q-p^4q}$", "choicesb": "$t_0=\\frac{1+p+p^2+p^3}{1-q-pq-p^2q-p^3q-p^4q}$", "choicesc": "$t_0=1+p+p^2+p^3$", "choicesd": "$t_0=\\frac{1}{1-q-pq-p^2q-p^3q-p^4q}$", "choicese": "", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "B", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "Now we want to find the mean time, so the unknowns are the mean time $t_i$. For each state, you have to take one more step to reach the next state.\r\n\\begin{align*}\r\nt_0=qt_0+pt_1+1\\\\\r\nt_1=qt_0+pt_2+1\\\\\r\nt_2=qt_0+pt_3+1\\\\\r\nt_3=qt_0+pt_4+1\\\\\r\nt_4=qt_0+pt_5+1\\\\\r\nt_5=0\r\n\\end{align*}\r\n\r\n\\begin{align*}\r\n\tt_3&=qt_0+p(qt_0+1)+1=qt_0+pqt_0+p+1\\\\\r\n\tt_2&=qt_0+p(qt_0+pqt_0+p+1)+1=qt_0+pqt_0+p^2qt_0+p+1\\\\\r\n\tt_1&=qt_0+p(qt_0+pqt_0+p^2qt_0+p+1)+1=qt_0+pqt_0+p^2qt_0+p^3qt_0+p^2+p+1\\\\\r\n\tt_0&=qt_0+pqt_0+p^2qt_0+p^3qt_0+p^4qt_0+p^3+p^2+p+1\r\n\\end{align*}", "linkability1": 0.0, "linkability2": 0.0, "linkability3": 0.0, "linkability4": 0.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": null, "difficulty": 3, "calculateddifficulty": null, "linkneuron": [2, 9, 13], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 72, "fields": {"code": "3.4.9", "category": 3, "problem": "An urn contains five red and three yellow balls. The balls are chosen\r\nat random, one by one, from the urn. Each ball removed is replaced in the\r\nurn by a yellow ball. The selection process continues until all of the red balls\r\nhave been removed from the urn. What is the mean duration of the game?", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "8", "choicesb": "12", "choicesc": "274/15", "choicesd": "50/3", "choicese": "44/3", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "C", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "Define the mean duration $t_i$ of each state(number of red ball)<br>\r\nNow consider the transition probability \r\n\\begin{equation*}\r\nP_{i(i-1)}=i/8\r\n\\end{equation*}\r\nand \r\n\\begin{equation*}\r\nP_{ii}=1-i/8\r\n\\end{equation*}\r\n\r\nso the system of equations are\r\n\\begin{align*}\r\nt_5=\\frac{5}{8}t_4+\\frac{3}{8}t_5+1\\\\\r\nt_4=\\frac{1}{2}t_3+\\frac{1}{2}t_4+1\\\\\r\nt_3=\\frac{3}{8}t_2+\\frac{5}{8}t_3+1\\\\\r\nt_2=\\frac{1}{4}t_1+\\frac{3}{4}t_2+1\\\\\r\nt_1=\\frac{7}{8}t_1+1\\\\\r\n\\end{align*}\r\nso\r\n\\begin{align*}\r\nt_1=8\\\\\r\nt_2=12\\\\\r\nt_3=44/3\\\\\r\nt_4=50/3\\\\\r\nt_5=274/15\r\n\\end{align*}", "linkability1": 0.0, "linkability2": 0.0, "linkability3": 0.0, "linkability4": 0.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": null, "difficulty": 3, "calculateddifficulty": null, "linkneuron": [2, 6, 9, 13], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 73, "fields": {"code": "3.4.12", "category": 3, "problem": "A Markov chain $X_0, X_1, X_2,...$ has the transition probability matrix\r\n\\[P=\r\n\\begin{array}{c||ccc||}\r\n&0&1&2\\\\\r\n0&0.3&0.2&0.5\\\\\r\n1&0.5&0.1&0.4\\\\\r\n2&0&0&1\r\n\\end{array}\r\n\\]\r\nand is known to start in state $X_0=0$. Eventually, the process will end up\r\nin state 2. What is the probability that when the process moves into state\r\n2, it does so from state 1?", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "0.150943", "choicesb": "0.528302", "choicesc": "0.849057", "choicesd": "0.471698", "choicese": "", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "A", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "Note that two events have to be defined:<br>\r\n($1\\to2$) with win probability 1 <br>\r\n($0\\to2$) with win probability 0 <br>\r\n\r\nSo we define the unknown:win probability to be $p_1$ and $p_2$<br>\r\n\r\n\\begin{align*}\r\np_0&=0.3p_0+0.2p_1\\\\\r\np_1&=0.5p_0+0.1p_1+0.4(1)\\\\\r\n\\end{align*}\r\nso\r\n\\begin{equation*}\r\np_0=0.150943\\qquad p_1=0.528302\r\n\\end{equation*}\r\nSo the probability is 0.150943", "linkability1": 0.0, "linkability2": 0.0, "linkability3": 0.0, "linkability4": 0.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": null, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [2, 9, 12], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 74, "fields": {"code": "3.4.15", "category": 3, "problem": "A simplified model for the spread of a rumor goes this way: There\r\nare $N=5$ people in a group of friends, of which some have heard the\r\nrumor and the others have not. During any single period of time, two people\r\nare selected at random from the group and assumed to interact. The selection\r\nis such that an encounter between any pair of friends is just as\r\nlikely as between any other pair. If one of these persons has heard the\r\nrumor and the other has not, then with probability $a = 0.1$ the rumor is\r\ntransmitted. Let $X_n$, denote the number of friends who have heard the\r\nrumor at the end of the nth period.\r\nAssuming that the process begins at time 0 with a single person knowing\r\nthe rumor, what is the mean time that it takes for everyone to hear it?", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "83.3333", "choicesb": "58.3333", "choicesc": "41.6777", "choicesd": "25", "choicese": "", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "A", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "The transition probability for $X_n$ can be written as\r\n$P_{i(i+1)}=\\alpha i(5-i)/\\binom{5}{2}$<br>\r\n$P_{ii}=1-i(5-i)/\\binom{5}{2}$<br>\r\n\r\nNow define the mean time $t_i$ starting at each state\r\n\\begin{align*}\r\nt_1=0.96t_1+0.04t_2+1\\\\\r\nt_2=0.94t_2+0.06t_3+1\\\\\r\nt_3=0.94t_3+0.06t_4+1\\\\\r\nt_4=0.96t_4+1\\\\\r\n\\end{align*} \r\nso\r\n\\begin{align*}\r\nt_1=83.3333\\\\\r\nt_2=58.3333\\\\\r\nt_3=41.6667\\\\\r\nt_4=25\r\n\\end{align*}\r\n\r\nThe answer is $t_1=83.3333$.", "linkability1": 0.0, "linkability2": 0.0, "linkability3": 0.0, "linkability4": 0.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": null, "difficulty": 3, "calculateddifficulty": null, "linkneuron": [], "rightproblems": [], "wrongproblems": [56], "twinproblems": []}}, {"model": "mathematics.question", "pk": 75, "fields": {"code": "3.4.1", "category": 3, "problem": "A coin is being flipped. How many flips are needed to take, on average: successively flipping a quarter until the pattern $ HHT $ appears, i.e., until you observe two successive heads followed by a tails; or successively flipping a quarter until the pattern $ HTH $ appears?", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "A. $HHT$: 14 flips; $HTH$: 10 flips.", "choicesb": "B. $HHT$: 13 flips; $HTH$: 11 flips.", "choicesc": "C. $HHT$: 12 flips; $HTH$: 12 flips.", "choicesd": "D. $HHT$: 11 flips; $HTH$: 13 flips.", "choicese": "E. $HHT$: 10 flips; $HTH$: 14 flips.", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "A", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "Let $u_i$ ,$v_j$ be the mean numbers of flip to reach $HHT$ and $HTH$ starting at state $i$ and $j$ respectively, for $i \\in \\{0, H, HH, HHT\\} = \\{0, 1, 2, 3\\}$ and $j \\in \\{0, H, HT, HTH\\} = \\{0, 1, 2, 3\\}$. Then, for the first case:\r\n\t\\begin{align}\r\n\tu_0 &= 1 + \\frac{1}{2} u_0 + \\frac{1}{2} u_1\\\\\r\n\tu_1 &= 1 + \\frac{1}{2} u_0 + \\frac{1}{2} u_2\\\\\r\n\tu_2 &= 1 + \\frac{1}{2} u_0 + \\frac{1}{2} u_3\\\\\r\n\tu_3 &= 0\r\n\t\\end{align}\r\n\tBy solving the above linear system of equations, we have $\\underline{u_0 = 14}$, $u_1 = 12$ and $u_2 = 8$. For the second case:\r\n\t\\begin{align}\r\n\tv_0 &= 1 + \\frac{1}{2} v_0 + \\frac{1}{2} v_1\\\\\r\n\tv_1 &= 1 + \\frac{1}{2} v_1 + \\frac{1}{2} u_2\\\\\r\n\tv_2 &= 1 + \\frac{1}{2} v_2 + \\frac{1}{2} u_3\\\\\r\n\tv_3 &= 0\r\n\t\\end{align}\r\n\tBy solving the above linear system of equations, we have $\\underline{v_0 = 10}$, $v_1 = 8$ and $v_2 = 6$. Therefore, the desired numbers of flips are 14 flips and 10 flips respectively.   \r\n<br> <br>\r\n\tAn intuitive way to think of the reason that the second case takes fewer flips is: it is harder to obtain $HH$ than $HT$ since you have to restart the steps from state 0 if you flipped a tail. In the second case, you stay at state of your previous step if you flipped a tail.", "linkability1": 1.0, "linkability2": 3.0, "linkability3": 2.0, "linkability4": 2.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": 0.2, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [9], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 76, "fields": {"code": "3.4.4", "category": 3, "problem": "Consider the Markov chain whose transition probability matrix is given by\r\n \\[\r\n \\mathbf{P} = \r\n \\begin{array}{l}\r\n \\begin{array}{lllll}\r\n \\hspace{0.075cm} & \\ \\ \\ 0 \\ & \\hspace{0.125cm} \\  1 \\ \\  & \\hspace{0.125cm}   2 \\ \\  & \\hspace{0.125cm}  3 \\  \\ \\ \\ \\\\\r\n \\end{array}\\\\\r\n\\begin{array}{c}\r\n0\\\\\r\n1\\\\\r\n2\\\\\r\n3\\\\\r\n\\end{array}\r\n\\begin{Vmatrix}\r\n  1 & 0 & 0 & 0  \\\\ \r\n  0.1 & 0.2 & 0.5 & 0.2 \\\\ \r\n  0.1 & 0.2 & 0.6 & 0.2 \\\\ \r\n  0.2 & 0.2 & 0.3 & 0.3 \\\\ \r\n\\end{Vmatrix}\r\n \\end{array}\r\n \\]\r\nStarting in state $ X_0 = 1 $, determine the probability that the process never visits state 2.", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "A. 0", "choicesb": "B. 11/52", "choicesc": "C. 41/52", "choicesd": "D. 17/26", "choicese": "E. 9/26", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "B", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "Let $p_i = \\Pr\\{\\text{reaching state 2} \\ | \\ \\text{start from state} \\ i\\}$. Then, we have:\r\n\t\\begin{align}\r\np_0 &= \\textbf{P}_{00} \\cdot p_0 + \\textbf{P}_{01} \\cdot p_1 + \\textbf{P}_{02} \\cdot p_2 + \\textbf{P}_{03} \\cdot p_3 = p_0 = 0\\\\\r\np_1 &= 0.2 p_1 + 0.5 p_2 + 0.2 p_3\\\\\r\np_2 &= 1\\\\\r\np_3 &= 0.2 p_1 + 0.3 p_2 + 0.3 p_3\\\\\r\n\\end{align}\r\nBy solving the above linear system of equations, we have $p_1 = 41/52$, and $p_3 = 34/52$. The desired probability is\r\n\\begin{align*}\r\n1 - p_1 &= 11/52 \\\\\r\n\t\t&\\approx 0.2115\r\n\\end{align*}", "linkability1": 2.0, "linkability2": 2.0, "linkability3": 2.0, "linkability4": 1.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": 0.2, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [9], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 77, "fields": {"code": "3.4.7", "category": 3, "problem": "Let $ X_n $ be a Markov chain with transition probabilities $ P_{ij} $. We are given a \u201cdiscount factor\u201d $ \\beta $ with $ 0 < \\beta < 1 $ and a cost function $ c(i) $, and we wish to determine the total expected discounted cost starting from state $ i $, de?ned by \r\n \\[h_i = E \\left[ \\sum_{n = 0}^{\\infty} \\beta^n c(X_n) | X_0 = i\\right] \\]\r\n Using a first step analysis show that $ h_i $ is a solution of one of the following system of linear equations for all states i.", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "A. \\[c(i) + \\beta^i \\sum_{j} \\textbf{P}_{ij} h_j\\] \\", "choicesb": "B. \\[c(i) + \\beta \\sum_{j} \\textbf{P}_{ij} h_j\\] \\", "choicesc": "C. \\[c(0) + \\beta^j \\sum_{j} \\textbf{P}_{ij} h_j\\]", "choicesd": "D. \\[c(0) + \\beta \\sum_{j} \\textbf{P}_{ij} h_j\\]", "choicese": "E. \\[c(i) + \\beta \\sum_{j}  h_j\\]", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "B", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "\\begin{align*}\r\nh_i\r\n&= E \\left[ \\sum_{n = 0}^{\\infty} \\beta^n c(X_n) | X_0 = i\\right]\\\\\r\n&= E \\left[  \\sum_{n = 0}^{\\infty} \\beta^n c(X_n) \\cdot 1_{ \\{X_1 = i \\} } | X_0 = i \\right] \\ \\ \\left( \\ \\text{where} \\ \\ 1_{ \\{X_1 = i \\} } = \\begin{cases}\r\n1 &  \\ \\ \\text{if} \\ \\ X_1 = i\\\\\r\n0 &  \\ \\ \\text{if} \\ \\ X_1 \\neq i\\\\\r\n\\end{cases} \\ \\ \\right) \\\\\r\n&= E \\left[  \\sum_{n = 0}^{\\infty} \\beta^n c(X_n) \\cdot 1_{ \\{X_1 = 0 \\} } | X_0 = i \\right] + \r\n   E \\left[  \\sum_{n = 0}^{\\infty} \\beta^n c(X_n) \\cdot 1_{ \\{X_1 = 1 \\} } | X_0 = i \\right] + \\cdots \\\\\r\n&= E \\left[  \\sum_{n = 0}^{\\infty} \\beta^n c(X_n) | X_1 = 0, X_0 = i \\right] \\cdot \\Pr\\{X_1 = 0 | X_0 = i\\}  \\\\\r\n& \\ \\ + E \\left[  \\sum_{n = 0}^{\\infty} \\beta^n c(X_n) | X_1 = 1, X_0 = i \\right] \\cdot \\Pr\\{X_1 = 1 | X_0 = i\\} + \\cdots \\ \\left( \\ \\text{Conditional Independence} \\ \\right) \\\\\r\n&= E \\left[  \\sum_{n = 0}^{\\infty} \\beta^n c(X_n) | X_1 = 0, X_0 = i \\right] \\cdot \\textbf{P}_{i0} + \r\n   E \\left[  \\sum_{n = 0}^{\\infty} \\beta^n c(X_n) | X_1 = 1, X_0 = i \\right] \\cdot \\textbf{P}_{i1} + \\cdots \\\\\r\n&= E \\left[  \\sum_{n = 0}^{\\infty} \\beta^n c(X_n) | X_1 = 0 \\right] \\cdot \\textbf{P}_{i0} + \r\n   E \\left[  \\sum_{n = 0}^{\\infty} \\beta^n c(X_n) | X_1 = 1 \\right] \\cdot \\textbf{P}_{i1} + \\cdots \\ (\\text{property of Markov Chain})\\\\\r\n&= E \\left[  c(X_0) + \\beta c(X_1) + \\cdots | X_1 = 0 \\right] \\cdot \\textbf{P}_{i0} +\r\n   E \\left[  c(X_0) + \\beta c(X_1) + \\cdots | X_1 = 1 \\right] \\cdot \\textbf{P}_{i1} + \\cdots \\\\\r\n&= E \\left[ c(x_0) \\right] \\cdot (\\textbf{P}_{i0} + \\textbf{P}_{i1} + \\cdots) + \r\n   E \\left[ \\beta c(X_1) + \\cdots | X_1 = 0 \\right] \\cdot \\textbf{P}_{i0} +\r\n   E \\left[ \\beta c(X_1) + \\cdots | X_1 = 1 \\right] \\cdot \\textbf{P}_{i1} + \\cdots \\\\\r\n&= E \\left[ c(x_0) \\right] \\cdot 1 + \r\n   \\beta E \\left[  \\sum_{n = 1}^{\\infty} \\beta^{n-1} c(X_n) | X_1 = 0 \\right] \\cdot \\textbf{P}_{i0} +\r\n   \\beta E \\left[  \\sum_{n = 1}^{\\infty} \\beta^{n-1} c(X_n)  | X_1 = 1 \\right] \\cdot \\textbf{P}_{i1} + \\cdots \\\\\r\n&= E \\left[ c(x_0) \\right] + \r\n\\beta \\cdot \\left( E \\left[  \\sum_{n = 0}^{\\infty} \\beta^{n} c(X_{n+1}) | X_1 = 0 \\right] \\cdot \\textbf{P}_{i0} +\r\n\t\t\t\t   E \\left[  \\sum_{n = 0}^{\\infty} \\beta^{n} c(X_{n+1})  | X_1 = 1 \\right] \\cdot \\textbf{P}_{i1} + \\cdots\r\n\t\t    \\right) \\ (\\text{shifting index})\\\\\r\n&= c(i) + \r\n\\beta \\cdot \\sum_{j} \\left( E \\left[  \\sum_{n = 0}^{\\infty} \\beta^{n} c(X_{n+1}) | X_1 = j \\right] \\cdot \\textbf{P}_{ij} \\right) \\\\\r\n&= c(i) + \r\n\\beta \\cdot \\sum_{j} \\left( E \\left[  \\sum_{n = 0}^{\\infty} \\beta^{n} c(X_{n}) | X_0 = j \\right] \\cdot \\textbf{P}_{ij} \\right) \\ (\\text{it takes same number of steps from 0 to $n$ and from 1 to $n+1$}) \\\\\r\n&= c(i) + \r\n\\beta \\cdot \\sum_{j} \\left( h_j \\cdot \\textbf{P}_{ij} \\right) \r\n = \\underline{c(i) + \\beta \\sum_{j} \\textbf{P}_{ij} h_j} \\\\\r\n\\end{align*}", "linkability1": 3.0, "linkability2": 1.0, "linkability3": 3.0, "linkability4": 1.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": 0.2, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [3, 7, 9], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 78, "fields": {"code": "3.4.16", "category": 3, "problem": "An urn contains five tags, of which three are red and two are green. A tag is randomly selected from the urn and replaced with a tag of the opposite color. This continues until only tags of a single color remain in the urn. Let $ X_n $ denote the number of red tags in the urn after the nth draw, with $ X_0 = 3 $. What is the probability that the game ends with the urn containing only red tags?", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "A. 1/2", "choicesb": "B. 3/8", "choicesc": "C. 5/8", "choicesd": "D. 15/32", "choicese": "E. 17/32", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "E", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "Let \\[p_i = \\Pr \\{ \\text{reach state 5} \\ | \\ \\text{starting at state} \\ i \\}.\\] <br>\r\nThen, the transition probability matrix is \r\n \\[\r\n \\mathbf{P} = \r\n \\begin{array}{l}\r\n \\begin{array}{lllll}\r\n \\hspace{0.125cm} & \\ \\  \\ 0 \\ & \\hspace{0.125cm} \\ \\ 1 \\ \\  & \\hspace{0.125cm} \\  2 \\ \\  & \\hspace{0.125cm}  \\ 3 \\  \\ & \\hspace{0.125cm}  4 & \\hspace{0.125cm}  \\ \\ \\ 5\\\\\r\n \\end{array}\\\\\r\n\\begin{array}{c}\r\n0\\\\\r\n1\\\\\r\n2\\\\\r\n3\\\\\r\n4\\\\\r\n5\\\\\r\n\\end{array}\r\n\\begin{Vmatrix}\r\n  1 & 0 & 0 & 0 & 0 & 0 \\\\ \r\n  1/5 & 0 & 4/5 & 0 & 0 & 0  \\\\ \r\n  0 & 2/5 & 0 & 3/5 & 0 & 0  \\\\ \r\n  0 & 0 & 3/5 & 0 & 2/5 & 0 \\\\ \r\n  0 & 0 & 0 & 4/5 & 0 & 1/5 \\\\ \r\n  0 & 0 & 0 & 0 & 0 & 1 \\\\ \r\n\\end{Vmatrix}\r\n \\end{array}\r\n \\]\r\nThen, we have:\r\n\\begin{align}\r\np_0 &= 0\\\\\r\np_1 &= 1/5 p_0 + 4/5 p_2\\\\\r\np_2 &= 2/5 p_1 + 3/5 p_3\\\\\r\np_3 &= 3/5 p_2 + 2/5 p_4\\\\\r\np_4 &= 4/5 p_3 + 1/5 p_5\\\\\r\np_5 &= 1\r\n\\end{align}\r\nBy solving the above linear system of equations, we have $p_1 = 3/8$, $p_2 = 15/32$, $\\underline{p_3 = 17/32}$ and $p_4 = 5/8$. The desired probability is \\[p_3 = 17/32 = 0.53125\\]", "linkability1": 1.0, "linkability2": 3.0, "linkability3": 1.0, "linkability4": 3.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": 0.2, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [9], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 79, "fields": {"code": "3.8.3", "category": 3, "problem": "Families in a certain society choose the number of children that they will have according to the following rule: If the first child is a girl, they have exactly one more child. If the first child is a boy, they continue to have children until the first girl, and then cease childbearing. <br>\r\n (a) Let $\\xi$ denotes the number of children of a particular family. For $ k=0,1,2,... $, what is the probability that a particular family will have $ k $ children in total? <br>\r\n (b) Let $\\xi$ denotes the number of male children of a particular family. For $ k=0,1,2,... $, what is the probability that a particular family will have exactly $ k $ male children among their offspring?", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "A. <br>\r\n(a). $P(\\xi = 0) = 0, P(\\xi = 1) = \\frac{1}{2}, P(\\xi = k) = \\left(  \\frac{1}{2}\\right)^k$ for $k \\geq 2$  <br>\r\n(b). $P(\\xi = 0) = \\frac{1}{4}, P(\\xi = k) = \\left(  \\frac{1}{2}\\right)^{k+1}$ for $k \\geq 1$  <br>", "choicesb": "B. <br>\r\n(a). $P(\\xi = 0) = 0, P(\\xi = 1) = 0, P(\\xi = 2) = \\frac{3}{4}, P(\\xi = k) = \\left(  \\frac{1}{2}\\right)^k$ for $k \\geq 3$  <br>\r\n\t(b). $P(\\xi = 0) = \\frac{1}{4}, P(\\xi = 1) = \\frac{1}{2}, P(\\xi = k) = \\left(  \\frac{1}{2}\\right)^{k+1}$ for $k \\geq 2$  <br>", "choicesc": "C. <br>\r\n\t(a). $P(\\xi = 0) = \\frac{1}{4}, P(\\xi = 1) = \\frac{1}{4}, P(\\xi = k) = \\left(  \\frac{1}{2}\\right)^k$ for $k \\geq 2$ <br>\r\n\t(b). $P(\\xi = 0) = \\frac{1}{4}, P(\\xi = 1) = \\frac{1}{2}, P(\\xi = k) = \\left(  \\frac{1}{2}\\right)^{k+1}$ for $k \\geq 2$  <br>", "choicesd": "D. <br>\r\n\t(a). $P(\\xi = 0) = 0, P(\\xi = 1) = 0, P(\\xi = 2) = \\frac{3}{4}, P(\\xi = k) = \\left(  \\frac{1}{2}\\right)^k$ for $k \\geq 3$ <br>\r\n\t(b). $P(\\xi = 0) = \\frac{1}{4}, P(\\xi = 1) = \\frac{1}{4}, P(\\xi = k) = \\left(  \\frac{1}{2}\\right)^{k}$ for $k \\geq 2$  <br>", "choicese": "E. <br>\r\n\t\t(a). $P(\\xi = 0) = \\frac{1}{4}, P(\\xi = 1) = \\frac{1}{4}, P(\\xi = k) = \\left(  \\frac{1}{2}\\right)^k$ for $k \\geq 2$ <br>\r\n\t(b). $P(\\xi = 0) = \\frac{1}{4}, P(\\xi = 1) = \\frac{1}{4}, P(\\xi = k) = \\left(  \\frac{1}{2}\\right)^{k}$ for $k \\geq 2$  <br>", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "B", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "(a).\r\n\\begin{align*}\r\nP(\\xi = 0) \r\n&= 0 = P(\\xi = 1), (\\text{all families will have at least 2 baby}) \\\\\r\nP(\\xi = 2) \r\n&= \\frac{1}{2} + \\frac{1}{2} \\cdot \\frac{1}{2} = \\frac{3}{4} \\\\\r\n& \\ \\ (\\text{first term refers to the case where first child is a girl, and second  }\\\\ \r\n& \\ \\ \\text{ term refers to another case where the second child is a girl}) \\\\\r\nP(\\xi = k)\r\n&= \\left( \\frac{1}{2} \\right)^k \\ \\text{for} \\ k \\geq 3\\\\\r\n& (\\text{the families stop having more children when their $k$th child is a girl})\r\n\\end{align*}\r\n(b).\r\n\\begin{align*}\r\nP(\\xi = 0) \r\n&= \\frac{1}{2} \\cdot \\frac{1}{2} = \\frac{1}{4} \\ \\ (\\text{first 2 children are both female}) \\\\\r\nP(\\xi = 1) \r\n&= \\frac{1}{2} \\cdot \\frac{1}{2} + \\frac{1}{2} \\cdot \\frac{1}{2} = \\frac{1}{2} \\\\\r\n& \\ \\ (\\text{first term refers to the case where first child is a girl, and second child is a boy. }\\\\ \r\n& \\ \\ \\text{  The second term refers to another case where the second child is a girl}) \\\\\r\nP(\\xi = k)\r\n&= \\left( \\frac{1}{2} \\right)^{k+1} \\ \\text{for} \\ k \\geq 2\\\\\r\n& (\\text{the families stop having more children when their $k$th child is a girl, and so there} \\\\\r\n& \\text{ are (k-1) of boys} )\r\n\\end{align*}", "linkability1": 3.0, "linkability2": 2.0, "linkability3": 3.0, "linkability4": 3.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": 0.2, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [14], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 80, "fields": {"code": "3.9.2", "category": 3, "problem": "One-fourth of the married couples in a far-off society have exactly three children. The other three-fourths of couples continue to have children until the first boy and then cease childbearing. Assume that each child is equally likely to be a boy or girl. Let $\\xi$ denotes the number of male offspring of a pair of married couple, and assumes all the married couple will have at least one child. What is the probability that the male line of descent of a particular husband $u_\\infty$ will eventually die out?", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "A. 1", "choicesb": "B. $\\sqrt{2}/2$", "choicesc": "C. $2(\\sqrt{2} - 1)$", "choicesd": "D. $(\\sqrt{2} - 1)/2$", "choicese": "E. It cannot be determined.", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "C", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "Let $p_k = \\Pr\\{\\xi = k\\}$. Then,\r\n\\begin{align*}\r\np_0 &= \\frac{1}{4} \\cdot \\left( \\frac{1}{2} \\right)^3 + \\frac{3}{4} \\cdot \\left( \\frac{1}{2} \\right)^3 = \\frac{1}{8}\\\\\r\np_1 &= \\frac{1}{4} \\cdot \\left( \\frac{3}{8} \\right) + \\frac{3}{4} \\cdot \\left( \\frac{1}{2} + \\frac{1}{4} + \\frac{1}{8} \\right) = \\frac{3}{4}\\\\\r\np_2 &= \\frac{1}{4} \\cdot \\left( \\frac{3}{8} \\right) + 0 = \\frac{3}{32}\\\\\r\np_3 &= \\frac{1}{4} \\cdot \\left( \\frac{1}{8} \\right) + 0 = \\frac{1}{32}\\\\\r\n\\end{align*}\r\nThe first terms are the contribution from one-fourth of the married couples who have exactly three children. The second terms are from the other three-fourth of the married couple. Therefore, the probability generation function $\\phi(s)$ is given as\r\n\\[\\phi(s) =E \\left( s^\\xi \\right) = \\sum_{k = 0}^{3} s^k p_k = \\frac{1}{8} + \\frac{3}{4} s + \\frac{3}{32} s^2 + \\frac{1}{32} s^3 \\]\r\nSolving $\\phi(s) - s = 0$, we have:\r\n\\begin{align*}\r\n\\phi(s) - s &= 0 \\\\\r\n \\longrightarrow s^3 + 3s^2 - 8s + 4 &= 0\\\\\r\n (s-1)(s^2 + 4s - 4) &= 0\\\\\r\n s &= 1 \\ \\text{or} \\ \\frac{-4 \\pm \\sqrt{16 + 16}}{2}\\\\\r\n   &= 1 \\ \\text{or} \\ -2 \\pm 2 \\sqrt{2}\\\\\r\n   &= -2(\\sqrt{2} + 1) \\  \\text{or} \\ 2(\\sqrt{2} - 1) \\ \\text{or} \\ 1\\\\\r\n\\because 0 < 2(\\sqrt{2} - 1) < 1, \\\\\r\n\\therefore u_\\infty &= \\underline{2(\\sqrt{2} - 1)} \\approx 0.828\r\n\\end{align*}", "linkability1": 2.0, "linkability2": 3.0, "linkability3": 1.0, "linkability4": 3.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": 0.2, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [14, 20, 21], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 81, "fields": {"code": "3.9.5", "category": 3, "problem": "At time 0, a blood culture starts with one red cell. At the end of 1 min, the red cell dies and is replaced by one of the following combinations with the probabilities as indicated:\r\n\\[\r\n\\begin{array}{rc}\r\n\\hline \r\n\\text{Two red cells} & \\frac{1}{4} \\\\ \r\n\\text{One red cell, One white cell} & \\frac{2}{3} \\\\\r\n\\text{Two white cells} & \\frac{1}{12} \\\\ \r\n \\hline\r\n\\end{array}\r\n\\]\r\nEach red cell lives for 1 min and gives birth to offspring in the same way as the parent cell. Each white cell lives for 1 min and dies without reproducing. Assume that individual cells behave independently.  <br>\r\n(a) Let $\\xi^{(n)}$ be the number of red cells after $n$th generation. At time $ n + \\frac{1}{2} $ min after the culture begins, what is the probability that no white cells have yet appeared? <br>\r\n(b) Let $\\xi$ be the number of red cells in the offspring of a red cell. What is the probability that the entire culture eventually dies out entirely?", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "A. <br>\r\n\t (a). \\[\\left( \\frac{1}{4} \\right)^{2^n} \\] <br>\r\n\t (b). \\[1\\]", "choicesb": "B. <br>\r\n\t (a). \\[\\left( \\frac{1}{4} \\right)^{2^n} \\] <br>\r\n \t (b). \\[ \\frac{1}{3}\\]", "choicesc": "C. <br>\r\n\t (a). \\[\\left( \\frac{1}{4} \\right)^{2^n - 1} \\] <br>\r\n \t (b). \\[1\\]", "choicesd": "D. <br>\r\n \t(a). \\[\\left( \\frac{1}{4} \\right)^{2^n - 1} \\] <br>\r\n \t(b). \\[ \\frac{1}{3}\\]", "choicese": "E. <br>\r\n \t(a). \\[\\left( \\frac{1}{4} \\right)^{2n} \\] <br>\r\n \t(b). \\[ \\frac{1}{3}\\]", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "D", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "(a).\r\n\\begin{align*}\r\nP(\\xi^{(0)} =2) &= \\frac{1}{4}\\\\\r\nP(\\xi^{(1)} =2^2 = 4) &= \\left( \\frac{1}{4} \\right)^2\\\\\r\n\\vdots \\ \\ \\ \\ \\ \\ & \\ \\ \\ \\ \\ \\ \\ \\vdots\\\\\r\nP(\\xi^{(n-1)} = 2^{n}) &= \\left( \\frac{1}{4} \\right)^{2^{n-1}}\\\\ \r\n\\therefore \\ P( \\text{no white cells for} \\ n \\text{th generation})\r\n&= P(\\xi^{(0)} \\cap \\xi^{(1)} \\cap \\cdots \\cap \\xi^{(n-1)}) \\  (\\text{there are $n$ terms in total})\\\\\r\n&= \\left( \\frac{1}{4} \\right) \\left( \\frac{1}{4} \\right)^2 \\left( \\frac{1}{4} \\right)^4 \\cdots \\left( \\frac{1}{4} \\right)^{2^{n-1}}\\\\\r\n&=\\left( \\frac{1}{4} \\right)^{1 + 2 + 4 + \\cdots + 2^{n-1}}\\\\\r\n&= \\underline{\\left( \\frac{1}{4} \\right)^{2^n - 1}}\r\n\\end{align*}\r\n(b).\r\n\\[ P(\\xi = 0) = \\frac{1}{12}, \\ P(\\xi = 1) = \\frac{2}{3}, \\ P(\\xi = 2) = \\frac{1}{4} \\]\r\nThe probability generation function $\\phi(s)$ is given as\r\n\\[ \\phi(s) = \\frac{1}{12} + \\frac{2}{3} s + \\frac{1}{4} s^2 \\]\r\nSolving $\\phi(s) - s = 0$, we have:\r\n\\begin{align*}\r\n\\phi(s) - s &= 0 \\\\\r\n\\longrightarrow 3s^2 - 4s + 1 &= 0\\\\\r\n(s-1)(3s - 1) &= 0\\\\\r\ns &= 1 \\ \\text{or} \\ \\frac{1}{3}\\\\\r\n\\because 0 < \\frac{1}{3} < 1, \\ \\\r\n\\therefore u_\\infty &= \\underline{\\frac{1}{3}} \r\n\\end{align*}", "linkability1": 2.0, "linkability2": 3.0, "linkability3": 2.0, "linkability4": 3.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": 0.2, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [14, 20, 21], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 82, "fields": {"code": "3.8.2", "category": 3, "problem": "Let $Z=\\sum_{n=0}^{\\infty}X_n$, be the total family size in a branching process\r\nwhose offspring distribution has a mean $\\mu = E[\\xi] < 1$. Assuming that\r\n$X_0 = 1$, what is $E[Z]$?.", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "$1/(1+\\mu)$", "choicesb": "$1/(1-\\mu)$", "choicesc": "$\\mu/(1-\\mu)$", "choicesd": "", "choicese": "", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "B", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "\\begin{align*}\r\nE[z]&=\\sum_{n=0}^{\\infty}E[X_n]=\\sum_{n=0}^{\\infty}\\mu^n=1/(1-\\mu)\r\n\\end{align*}", "linkability1": 0.0, "linkability2": 0.0, "linkability3": 0.0, "linkability4": 0.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": null, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [2, 16], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 83, "fields": {"code": "3.9.8", "category": 3, "problem": "Consider a branching process whose offspring follow the geometric distribution $p_k = ( 1 - c) \\ c^k$ for $k = 0,1,...$, where $0.5 < c < 1$. Determine the probability of eventual extinction.", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "A. \\[0\\]", "choicesb": "B. \\[1\\]", "choicesc": "C. \\[\\frac{2c - 1}{2c}\\]", "choicesd": "D. \\[\\frac{1 -c}{1 + c}\\]", "choicese": "E. \\[\\frac{1 -c}{c}\\]", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "E", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "\\begin{align*}\r\np_k \r\n&= (1-c) \\ c^k \\ \\ \\text{for} \\ \\ k = 0,1,... , \\ \\text{where} \\ \\ c \\in (0,1) \\\\\r\n\\therefore \\ \\ \\phi(s)\r\n&= (1-c) + (1-c) \\ c \\cdot s + (1-c) \\ c^2 \\cdot s^2 + \\cdots \\\\\r\n&= (1-c) \\cdot [1 + cs + (cs)^2 + \\cdots]\\\\\r\n&= (1-c) \\ \\sum_{k = 0}^{\\infty} (cs)^k \\\\\r\n&= (1-c) \\cdot \\frac{1}{1 - cs} \\ \\text{(using Taylor Series Expansion to obtain the latter term from the infinite sum)}\\\\\r\n&= \\frac{1 - c}{1 - cs}\r\n\\end{align*}\r\nSolving $\\phi(s) - s = 0$, we have: \r\n\\begin{align*}\r\n\\frac{1 - c}{1 - cs}\r\n&= s \\\\\r\n\\rightarrow c \\cdot s^2 - s + (1 - c)\r\n&= 0\\\\\r\ns\r\n&= \\frac{1 \\pm \\sqrt{1^2 - 4c(1-c)}}{2c}\\\\\r\n&= \\frac{1 \\pm \\sqrt{4c^2 - 4c + 1}}{2c}\\\\\r\n&= \\frac{1 \\pm \\sqrt{(2c - 1)^2}}{2c} = \\frac{1 \\pm (2c -1)}{2c} = 1 \\ \\text{or} \\ \\frac{1-c}{c}\\\\ \\\\\r\n\\therefore \\ \\ u_\\infty \r\n&= \\begin{cases}\r\n1 & \\text{if} \\ \\ \\ c \\leq 0.5  \\\\\r\n\\frac{1 - c}{c} & \\text{if} \\ \\ \\ 0.5 < c < 1\\\\\r\n\\end{cases}\r\n\\end{align*}", "linkability1": 3.0, "linkability2": 2.0, "linkability3": 1.0, "linkability4": 1.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": 0.2, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [14, 20, 21], "rightproblems": [], "wrongproblems": [131], "twinproblems": [131]}}, {"model": "mathematics.question", "pk": 84, "fields": {"code": "3.9.1", "category": 3, "problem": "One-fourth of the married couples in a far-off society have no children\r\nat all. The other three-fourths of families have exactly three children,\r\neach child equally likely to be a boy or a girl. What is the probability that\r\nthe male line of descent of a particular husband will eventually die out?", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "0", "choicesb": "$\\frac{\\sqrt{69}-6}{3}$", "choicesc": "1", "choicesd": "$\\frac{-\\sqrt{69}-6}{3}$", "choicese": "none of the above", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "B", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "The probability of having\r\n0 boy:$1/4+3/4(1/8)=11/32$<br>\r\n1 boy:$3/4(3/8)=9/32$<br>\r\n2 boy:$3/4(3/8)=9/32$<br>\r\n3 boy:$3/4(1/8)=3/32$<br>\r\nApply $u_{\\infty}=\\phi(u_{\\infty})$\r\n\\begin{equation*}\r\nu_{\\infty}=11/32+(9/32)u_{\\infty}+(9/32)u_{\\infty}^2+(3/32)u_{\\infty}^3\r\n\\end{equation*}\r\nSo\r\n\\begin{equation*}\r\nu_{\\infty}=\\frac{-\\sqrt{69}-6}{3}\\text{  or  }\\frac{\\sqrt{69}-6}{3}\\text{  or  }1\r\n\\end{equation*}\r\nSince $u_{\\infty}$ converge to the smallest solution between 0 and 1, the answer is $\\frac{\\sqrt{69}-6}{3}$.", "linkability1": 0.0, "linkability2": 0.0, "linkability3": 0.0, "linkability4": 0.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": null, "difficulty": 3, "calculateddifficulty": null, "linkneuron": [2, 20, 21, 22], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 85, "fields": {"code": "3.9.7", "category": 3, "problem": "Families in a certain society choose the number of children that\r\nthey will have according to the following rule: If the first child is a girl,\r\nthey have exactly one more child. If the first child is a boy, they continue\r\nto have children until the first girl and then cease childbearing. Let $\\xi$ be\r\nthe number of male children in a particular family. Determine the mean of $\\xi$ directly or by differentiating the generating function.", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "2", "choicesb": "0.5", "choicesc": "1.75", "choicesd": "2.5", "choicese": "", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "C", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "Consider the second rule, $\\xi$ obviously follow the geometric distribution.\r\nConsider the first rule, there is half the probability having one male child.\r\n\r\nSo \r\nPr\\{$\\xi=0$\\}$=\\frac{1}{2^2}$<br>\r\nPr\\{$\\xi=1$\\}$=\\frac{1}{2^2}$<br>\r\nPr\\{$\\xi=k>1$\\}$=\\frac{1}{2^k}$<br>\r\n\\begin{align*}\r\n\\phi(s)=\\frac{1}{2^2}+\\frac{1}{2^2}s+\\sum_{k=2}^{\\infty}\\frac{1}{2^k}s^k=\\frac{1}{2^2}+\\frac{1}{2^2}s+\\frac{s^2/4}{1-s/2}\r\n\\end{align*} \r\nOnce we differentiate the probability generating function, \r\n\\begin{align*}\r\n\\phi'(s)=\\frac{1}{2^2}-\\frac{s(s-4)}{2(s-2)^2}\\\\\r\n\\phi'(1)=\\frac{1}{2^2}+\\frac{3}{2}\r\n\\end{align*}\r\nIf we consider the mean of $\\xi$ directly, it is complicated as it involve clever shifting of index so that the $k$ is cancelled.\r\n\\begin{align*}\r\nE[\\xi]&=\\frac{1}{2^2}+\\sum_{k=2}^{\\infty}\\frac{k}{2^{k-1}}(1-\\frac{1}{2})\\\\\r\n&=\\frac{1}{2^2}+\\sum_{k=2}^{\\infty}\\frac{k}{2^{k-1}}-\\frac{k}{2^{k}}\\\\\r\n&=\\frac{1}{2^2}+\\sum_{k=1}^{\\infty}\\frac{k+1}{2^{k}}-\\frac{k+1}{2^{k+1}}\\\\\r\n&=\\frac{1}{2^2}+\\sum_{k=0}^{\\infty}\\frac{k}{2^{k+1}}+\\left(\\frac{2}{2^{k+1}}-\\frac{1}{2^{k+2}}\\right)-\\sum_{k=1}^{\\infty}\\frac{k}{2^{k+1}}\\\\\r\n&=\\frac{1}{2^2}+\\sum_{k=0}^{\\infty}\\frac{k}{2^{k+1}}+\\left(\\frac{2}{2^{k+1}}-\\frac{1}{2^{k+2}}\\right)-\\sum_{k=0}^{\\infty}\\frac{k}{2^{k+1}}\\\\\r\n&=\\frac{1}{2^2}+\\sum_{k=0}^{\\infty}\\left(\\frac{2}{2^{k+1}}-\\frac{1}{2^{k+2}}\\right)\\\\\r\n&=\\frac{1}{2^2}+\\frac{3}{2}\\\\\r\n\\end{align*}\r\nAnother way of doing it is to calculate the expectation value of a geometric distribution from 1 is $\\frac{1}{p}=2$. Now we start at $k=2$, so we subtract the contribution of $k=1$:$\\frac{1}{2}$. So the value of the second term is $2-\\frac{1}{2}=\\frac{3}{2}$", "linkability1": 0.0, "linkability2": 0.0, "linkability3": 0.0, "linkability4": 0.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": null, "difficulty": 4, "calculateddifficulty": null, "linkneuron": [], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 86, "fields": {"code": "3.9.10.a", "category": 3, "problem": "Suppose that in a branching process the number of offspring of an initial particle has a distribution whose generating function is $f(s)$. Each member of the first generation has a number of offspring whose distribution has generating function $g(s)$. The next generation has generating function $f$, the next has $g$ , and the distribution continue to alternate in this way from generation to generation. <br>\r\nDetermine the extinction probability of the process in terms of $f(s)$ and $g(s)$.", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "$(f+g)(u_{\\infty})$", "choicesb": "$(fg)(u_{\\infty})$", "choicesc": "$f\\circ g(u_{\\infty})$", "choicesd": "$f\\ast g(u_{\\infty})$<br>\r\n$\\ast$ denote convolution operation", "choicese": "$g\\circ f(u_{\\infty})$", "choicesf": "$f^g(u_{\\infty})$", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "C", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "Here,  the key idea is to treat each two transition as one transition. First we have $\\xi_1\\to k_1$ and $\\xi_2\\to k_{2,i}$(i run from 1 to $k_1$, denoting the index of the second transition) for the two process $f$ and $g$.<br>\r\nThe outcome $k$ of each two transition(there are $k_1$ roll for $\\xi_2$, each $\\xi_2$ give out $k_2$) is then \r\n\\begin{equation*}\r\nk=\\sum_{i=0}^{k_1}k_{2,i}\r\n\\end{equation*}\r\nFor each outcome $\\sum_{i=0}^{k_1}k_{2,i}$,  the probability is\r\n\\begin{equation*}\r\nP(k)={\\xi}_1(k_1)\\prod_{i=0}^{k_1}{\\xi}_2(k_{2,i})\r\n\\end{equation*}\r\nNow we have our generating function $\\phi(s)$ for the two steps transition, note to run over all the outcomes, the summation is $\\sum_k=\\sum_{k_1}\\sum_{i=0}^{k_1}$\r\n\\begin{align*}\r\n\\phi(s)=\\sum_kP(k)s^k&=\\sum_{k_1}\\sum_{i=0}^{k_1}s^{\\sum_{i=0}^{k_1}k_{2,i}}{\\xi}_1(k_1)\\prod_{i=0}^{k_1}{\\xi}_2(k_{2,i})\\\\\r\n&=\\sum_{k_1}{\\xi}_1(k_1)\\sum_{i=0}^{k_1}\\prod_{i=0}^{k_1}{\\xi}_2(k_{2,i})s^{k_{2,i}}\r\n\\end{align*}\r\nSince each term have element $\\prod_{i=0}^{k_1}{\\xi}_2(k_{2,i})s^{k_{2,i}}$ and we have to run over all possible outcomes $k$ (usually come from multiplication of series), it is natural to think of $g^{k_1}$.<br>\r\nAfter identifying the $g^{k_1}$ term, everything is straight forward:\r\n\\begin{align*}\r\n\\phi(s)&=\\sum_{k_1}{\\xi}_1(k_1)\\sum_{i=0}^{k_1}\\prod_{i=0}^{k_1}{\\xi}_2(k_{2,i})s^{k_{2,i}}\\\\&=\\sum_{k_1}\\xi_1(k_1)g^{k_1}=f\\circ g(s)\r\n\\end{align*}\r\nTherefore, the extinction probability is $f\\circ g(u_{\\infty})$", "linkability1": 0.0, "linkability2": 0.0, "linkability3": 0.0, "linkability4": 0.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": null, "difficulty": 4, "calculateddifficulty": null, "linkneuron": [20, 21, 22, 28], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 87, "fields": {"code": "3.4.10", "category": 3, "problem": "You have five fair coins. You toss them all so that they randomly fall heads or tails. Those that fall tails in the first toss you pick up and toss again. You toss again those that show tails after the second toss, and so on, until all show heads. Let $ X $ be the number of coins involved in the last toss. Find $ \\Pr\\{X=1\\} $.", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "A. 2/3", "choicesb": "B. 5/7", "choicesc": "C. 29/105", "choicesd": "D. 76/105", "choicese": "E. 157/217", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "E", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "Let $X_n$ be the number of tails at the end of period $n$. Then, $\\{X_n\\}$ is a Markov chain with state $ \\{0, 1, 2, 3, 4, 5\\} $. \\\\ \\\\\r\nIf 0 tail appears in the previous toss, the process will be ended. So it is an absorbing state:\r\n\\begin{align*}\r\n\\Pr\\{X_1 = 0 | X_0 = 0\\} &= 1\\\\\r\n\\Pr\\{X_1 = 0 | X_0 \\neq 0\\} &= 0\\\\\r\n\\end{align*}\r\nIf 1 tail appears in the previous toss, 0 or 1 tail will appear in this toss where both probabilities are 1/2:\r\n\\begin{align*}\r\n\\Pr\\{X_1 = 0 | X_0 = 1\\} &= \\frac{1}{2} = \\Pr\\{X_1 = 1 | X_0 = 1\\} \\\\\r\n\\Pr\\{X_1 = 0 | X_0 \\neq 0 \\ \\text{or} \\  1 \\} &= 0\\\\\r\n\\end{align*}\r\nIf 2 tails appear in the previous toss, 0, 1 or 2 tail(s) will appear in this toss where the probabilities are 1/4, 1/2 and 1/4 respectively:\r\n\\begin{align*}\r\n\\Pr\\{X_1 = 0 | X_0 = 2\\} &= \\frac{1}{4} = \\Pr\\{X_1 = 2 | X_0 = 2\\} \\\\\r\n\\Pr\\{X_1 = 1 | X_0 = 2\\} &= \\frac{1}{2}\\\\\r\n\\Pr\\{X_1 = 0 | X_0 \\neq 0, 1 \\ \\text{or} \\  2 \\} &= 0\\\\\r\n\\end{align*}\r\nIf 3 tails appear in the previous toss, 0, 1, 2 or 3 tail(s) will appear in this toss where the probabilities are 1/8, 3/8, 3/8 and 1/8 respectively:\r\n\\begin{align*}\r\n\\Pr\\{X_1 = 0 | X_0 = 3\\} &= \\frac{1}{8} = \\Pr\\{X_1 = 3 | X_0 = 3\\} \\\\\r\n\\Pr\\{X_1 = 1 | X_0 = 3\\} &= \\frac{3}{8} = \\Pr\\{X_1 = 2 | X_0 = 3\\}\\\\\r\n\\Pr\\{X_1 = 0 | X_0 \\neq 0, 1, 2 \\ \\text{or} \\  3 \\} &= 0\\\\\r\n\\end{align*}\r\nIf 4 tails appear in the previous toss, 0, 1, 2, 3, 4 tail(s) will appear in this toss where the probabilities are 1/16, 1/4, 3/8, 1/4 and 1/16 respectively:\r\n\\begin{align*}\r\n\\Pr\\{X_1 = 0 | X_0 = 4\\} &= \\frac{1}{16} = \\Pr\\{X_1 = 4 | X_0 = 4\\} \\\\\r\n\\Pr\\{X_1 = 1 | X_0 = 4\\} &= \\frac{1}{4} = \\Pr\\{X_1 = 3 | X_0 = 4\\}\\\\\r\n\\Pr\\{X_1 = 2 | X_0 = 4\\} &= \\frac{3}{8}\\\\\r\n\\Pr\\{X_1 = 0 | X_0 = 5\\} &= 0\\\\\r\n\\end{align*}\r\nIf 5 tails appear in the previous toss, 0, 1, 2, 3, 4 or 5 tail(s) will appear in this toss where the probabilities are 1/32, 5/32, 5/16, 5/16, 5/32 and 1/32 respectively:\r\n\\begin{align*}\r\n\\Pr\\{X_1 = 0 | X_0 = 5\\} &= \\frac{1}{32} = \\Pr\\{X_1 = 5 | X_0 = 5\\} \\\\\r\n\\Pr\\{X_1 = 1 | X_0 = 5\\} &= \\frac{5}{32} = \\Pr\\{X_1 = 4 | X_0 = 5\\}\\\\\r\n\\Pr\\{X_1 = 2 | X_0 = 5\\} &= \\frac{5}{16} = \\Pr\\{X_1 = 3 | X_0 = 5\\}\\\\\r\n\\end{align*}\r\nTherefore, the transition probability matrix is given as\r\n \\[\r\n\\mathbf{P} = \r\n\\begin{array}{l}\r\n\\begin{array}{lllllll}\r\n\\hspace{0.125cm} &   \\ \\ \\ \\ 0 \\ & \\hspace{0.15cm} \\ \\ \\ 1 \\ \\  & \\hspace{0.125cm}  \\ \\ \\ 2 \\ \\ & \\hspace{0.125cm}  \\  \\ \\ 3 \\ \\ \\ \\ & \\hspace{0.125cm} \\  4 \\  \\ \\ \\ & \\hspace{0.125cm}  \\ 5 \\  \\ \\ \\ \\\\\r\n\\end{array}\\\\\r\n\\begin{array}{c}\r\n0\\\\\r\n1\\\\\r\n2\\\\\r\n3\\\\\r\n4\\\\\r\n5\\\\\r\n\\end{array}\r\n\\begin{Vmatrix}\r\n1  \t & 0\t& 0 \t& 0 \t& 0 \t& 0    \\\\ \r\n1/2  & 1/2  & 0 \t& 0 \t& 0 \t& 0     \\\\ \r\n1/4  & 1/2  & 1/4 \t& 0 \t& 0 \t& 0   \\\\ \r\n1/8  & 3/8 \t& 3/8 \t& 1/8 \t& 0 \t& 0  \\\\ \r\n1/16 & 1/4 \t& 3/8 \t& 1/4 \t& 1/16 \t& 0  \\\\ \r\n1/32 & 5/32 & 5/16 \t& 5/16 \t& 5/32 \t& 1/32  \\\\ \r\n\\end{Vmatrix}\r\n\\end{array}\r\n\\]\r\nLet\r\n\\[ \\ p_i = \\Pr\\{ \\text{reaching state 1 without passing state 0} \\ | \\ \\text{begining from state} \\ i \\}\\]\r\n\\[ \\therefore p_0 = 0, p_1 = 1 \\]\r\n\\begin{align}\r\np_2 &= \\frac{1}{4} p_0 + \\frac{1}{2} p_1 + \\frac{1}{4} p_2 = \\frac{1}{2} + \\frac{1}{4} p_2 \\\\\r\np_3 &= \\frac{3}{8} + \\frac{3}{8} p_2 + \\frac{1}{8} p_3 \\\\\r\np_4 &= \\frac{1}{4} + \\frac{3}{8} p_2 + \\frac{1}{4} p_3 + \\frac{1}{16} p_4 \\\\\r\np_5 &= \\frac{5}{32} + \\frac{5}{16} p_2 + \\frac{5}{16} p_3 + \\frac{5}{32} p_4 + \\frac{1}{32} p_5\r\n\\end{align}\r\nBy solving the above linear system of equations, we have $p_2 = 2/3$, $p_3 = 5/7$, $p_4 = 76/105$ and $\\underline{p_5 = 157/217}$. The desired probability is\r\n\\begin{align*}\r\n\\Pr\\{X = 1\\} &=  p_5 \\\\\r\n&= 157/217 \\approx 0.7235\r\n\\end{align*}", "linkability1": 2.0, "linkability2": 3.0, "linkability3": 3.0, "linkability4": 2.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": 0.2, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [9], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 88, "fields": {"code": "3.4.19", "category": 3, "problem": "$\\textit{Computer Challenge}$. Let $ N $ be a positive integer and let $ Z_1,...,Z_N $ be independent random variables, each having the geometric distribution\r\n \\[\\Pr\\{ Z = k \\} = \\left( \\frac{1}{2} \\right) ^k , \\text{for} \\ k=1,2,....\\]\r\n  Since these are discrete random variables, the maximum among them may be unique, or there may be ties for the maximum. Let $ p_N $ be the probability that the maximum is unique. How does $ p_N $ behave when $ N $ is large? (Alternative formulation: You toss $ N $ dimes. Those that are heads you set aside; those that are tails you toss again. You repeat this until all of the coins are heads. Then, $ p_N $ is the probability that the last toss was of a single coin.)", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "A. It will converge to 0.", "choicesb": "B. It will converge to a certain number between 0 and 1.", "choicesc": "C. It will converge to 1.", "choicesd": "D. It will diverge.", "choicese": "E. It cannot be determined. It behaves like a random variable independent of $N$.", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "B", "solutionspicture1": "theall/image/P3.4.19.png", "solutionspicture2": "", "solutionspicture3": "", "solutions": "This problem is an extension of Problem 3.4.10. In other words, the setup in Problem 3.4.10 is a special case of this problem with $ N $ = 5. The transition probability matrix is given as\r\n \\[\r\n\\mathbf{P} = \r\n\\begin{array}{l}\r\n\\begin{array}{lllllll}\r\n\\hspace{0.1cm} & \\ \\ \\ \\ \\  0 \\ & \\hspace{0.15cm} \\  1 \\ \\  & \\hspace{0.125cm} \\   2 \\ \\  & \\hspace{0.125cm}  \\ 3 & \\hspace{0.2cm}  \\cdots   & \\hspace{0.175cm}  N \\  \\ \\ \\ \\\\\r\n\\end{array}\\\\\r\n\\begin{array}{c}\r\n0\\\\\r\n1\\\\\r\n2\\\\\r\n3\\\\\r\n\\vdots\\\\\r\nN\\\\\r\n\\end{array}\r\n\\begin{Vmatrix}\r\n1  \t & 0\t& 0 \t& 0 \t& \\cdots \t& 0    \\\\ \r\n1/2  & 1/2  & 0 \t& 0 \t& \\cdots \t& 0     \\\\ \r\n1/4  & 1/2  & 1/4 \t& 0 \t& \\cdots \t& 0   \\\\ \r\n1/8  & 3/8 \t& 3/8 \t& 1/8 \t& \\cdots \t& 0  \\\\ \r\n\\vdots & \\vdots \t& \\vdots \t& \\vdots \t& \\ddots \t& \\vdots  \\\\ \r\n\\frac{C^N_0}{2^N} & \\frac{C^N_1}{2^N} & \\frac{C^N_2}{2^N} \t& \\frac{C^N_3}{2^N} \t& \\cdots \t& \\frac{C^N_N}{2^N}  \\\\ \r\n\\end{Vmatrix}\r\n\\end{array}\r\n\\]\r\n\\[\r\n\\text{where} \\ C^n_r = \r\n\\begin{pmatrix}\r\nn\\\\ \r\nr\\\\\r\n\\end{pmatrix} = \\frac{n ! }{(n - r)! \\ r!} \\\r\n\\text{is called the \\textit{combination} or \\textit{binomial coefficient}.}\r\n\\]\r\nLet \\[ \r\np_i = \\Pr\\{\\text{reaching state 1 without passing through state 0} \\ | \\ \\text{begining from state} \\ i \\}.\r\n\\]\r\nThen, \\[\r\np_0 = 0, p_1 = 1, \\]\r\n\\[\r\np_i = \\sum_{j = 0}^{N} \\textbf{P}_{ij} p_j \\ \\text{for} \\ i \\neq 0 \\ \\text{or} \\ 1 \r\n\\]\r\nA matrix equation can be set up:\r\n\\[ \\left[\r\n\\mathbf{I}_N - \\begin{pmatrix}\r\n0 & 0 & 0 & \\cdots & 0\\\\\r\n0 & 0 & 0 & \\cdots & 0\\\\\r\n1/4 & 1/2 & 1/4 & \\cdots & 0\\\\\r\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots\\\\\r\n\\frac{C^N_0}{2^N} & \\frac{C^N_1}{2^N} & \\frac{C^N_2}{2^N} \t& \\frac{C^N_3}{2^N} \t& \\cdots \t& \\frac{C^N_N}{2^N}  \\\\\r\n\\end{pmatrix}\r\n\\right] \\begin{bmatrix}\r\np_0\\\\\r\np_1\\\\\r\np_2\\\\\r\n\\vdots\\\\\r\np_N\\\\\r\n\\end{bmatrix}\r\n= \\begin{bmatrix}\r\n1\\\\\r\n0\\\\\r\n0\\\\\r\n\\vdots\\\\\r\n0\\\\\r\n\\end{bmatrix}\r\n\\]\r\n\\[\r\n\\text{where} \\ I \\ \\text{is the $N$ by $N$ identity matrix.}\r\n\\]\\\\\r\nBy solving the above matrix equation, we have:\r\n\\[\r\np_5 = \\frac{157}{217} \\approx 0.7235, \\ p_{10} = \\frac{1436}{1991} \\approx 0.7212, \\ p_{20} = \\frac{999}{1385} \\approx 0.7213,\\]\r\n\\[\r\np_{50} = \\frac{1429}{1981} \\approx 0.7214, \\ p_{100} = \\frac{919}{1274} \\approx 0.7214, \\ p_{150} = \\frac{409}{567} \\approx 0.7213\\]\r\nTherefore, we can see that the probability $p_N$ is converging to approximately 0.7213 when $ N $ is large. <br>\r\nYou can also see how $p_N$ varies from $N = 1$ to $N = 150$ in the following figure.", "linkability1": 3.0, "linkability2": 3.0, "linkability3": 2.0, "linkability4": 2.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": 0.2, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [6, 9], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 89, "fields": {"code": "3.4.13", "category": 3, "problem": "A Markov chain $ X_0,X_1,X_2,... $ has the transition probability matrix \r\n  \\[\r\n \\mathbf{P} = \r\n \\begin{array}{l}\r\n \\begin{array}{llll}\r\n \\hspace{0.075cm} & \\ \\ \\ 0 \\ & \\hspace{0.125cm} \\  1 \\ \\  & \\hspace{0.125cm}   2 \\ \\  \\\\\r\n \\end{array}\\\\\r\n \\begin{array}{c}\r\n 0\\\\\r\n 1\\\\\r\n 2\\\\\r\n \\end{array}\r\n \\begin{Vmatrix}\r\n 0.3 & 0.2 & 0.5   \\\\ \r\n 0.5 & 0.1 & 0.4  \\\\ \r\n 0 & 0 & 1  \\\\ \r\n \\end{Vmatrix}\r\n \\end{array}\r\n \\]\r\n and is known to start in state $ X_0 =0 $. Eventually, the process will end up in state 2. What is the probability that the time $ T = \\min \\{n \\geq 0; X_n = 2 \\} $ is an odd number?", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "A. 43/133", "choicesb": "B. 53/133", "choicesc": "C. 80/133", "choicesd": "D. 90/133", "choicese": "E. 100/133", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "A", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "Let\\[\r\nZ_n = (OE(T),X_n), \\\\ \\] \r\n\\[\\text{where} \\ OE(T) = \\begin{cases}\r\nO & \\text{if} \\ \\ \\frac{1 + (-1)^T}{2} = 1\\\\\r\nE & \\text{if} \\ \\ \\frac{1 + (-1)^T}{2} = 0\\\\\r\n\\end{cases}\r\n \\ \\text{is an odd/even number indicator function.}\r\n\\]\r\nThen, $Z_n$ is a Markov chain with state $ \\{0, 1, 2, 3, 4, 5 \\} = \\{(O,0), (O,1), (O,2), (E,0), (E,1), (E,2) \\} $. The transition probability matrix now becomes:\r\n \\[\r\n\\mathbf{P} = \r\n\\begin{array}{l}\r\n\\begin{array}{lllllll}\r\n\\hspace{0.075cm} & \\ \\ \\ 0 \\ & \\hspace{0.125cm} \\  1 \\ \\  & \\hspace{0.125cm}   2 \\ \\  & \\hspace{0.125cm}  3 \\  & \\hspace{0.15cm}  4 \\  \\ \\ & \\hspace{0.1cm}  5 \\  \\ \\ \\ \\\\\r\n\\end{array}\\\\\r\n\\begin{array}{c}\r\n0\\\\\r\n1\\\\\r\n2\\\\\r\n3\\\\\r\n4\\\\\r\n5\\\\\r\n\\end{array}\r\n\\begin{Vmatrix}\r\n0  \t \t& 0\t\t& 0 \t& 0.3 \t& 0.2 \t& 0.5    \\\\ \r\n0  \t \t& 0\t\t& 0 \t& 0.5 \t& 0.1 \t& 0.4    \\\\  \r\n0  \t \t& 0\t\t& 0 \t& 0 \t& 0 \t& 1    \\\\ \r\n0.3 \t& 0.2 \t& 0.5  \t& 0 \t& 0 \t& 0    \\\\ \r\n0.5 \t& 0.1 \t& 0.4\t& 0 \t& 0 \t& 0    \\\\ \r\n0 \t\t& 0 \t& 1 \t& 0 \t& 0 \t& 0    \\\\ \r\n\\end{Vmatrix}\r\n\\end{array}\r\n\\]\r\nLet \\[\r\np_i = \\Pr\\{\\text{reaching state 2 without passing state 5} \\ | \\ \\text{begining from state} \\ i \\}.\r\n\\]\r\nThen, we have:\r\n\\[\r\np_2 = 1, p_5 = 0,\r\n\\]\r\n\\begin{align}\r\np_0 &= 0.3p_3 + 0.2p_4 + 0.5p_5\\\\\r\np_1 &= 0.5p_3 + 0.1p_4 + 0.4p_5\\\\\r\np_2 &= 1\\\\\r\np_3 &= 0.3p_0 + 0.2p_1 + 0.5p_2\\\\\r\np_4 &= 0.5p_0 + 0.1p_1 + 0.4p_2\\\\\r\np_5 &= 0\r\n\\end{align}\r\nBy solving the above linear system of equations, we have $\\underline{p_0 = 43/133}$, $p_1 = 53/133$, $p_3 = 90/133$ and $p_4 = 80/133$. The desired probability is\r\n\\[\r\np_0 = 43/133\r\n\\]", "linkability1": 2.0, "linkability2": 3.0, "linkability3": 2.0, "linkability4": 2.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": 0.2, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [9], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 101, "fields": {"code": "4.1.1", "category": 3, "problem": "Five balls are distributed between two urns, labeled A and B. Each period, an urn is selected at random, and if it is not empty, a ball from that urn is removed and placed into the other run. In the long run, what fraction of time is urn A is empty?", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "1/10", "choicesb": "1/5", "choicesc": "1/14", "choicesd": "Cannot be determined", "choicese": "None of above", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "A", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "First we define the random variable $X$ be the number of ball in urn A. It takes value from 0 to 5.<br>\r\nTo consider the transitional matrix, we know $P_{01}=P_{54}$ must be 1 as one urn is empty. For other possible transition, we know $P_{i(i+1)}=P_{i(i-1)}=1/2$. Therefore, \r\n\\[P=\r\n\\begin{array}{c|cccccc|}\r\n&0&1&2&3&4&5\\\\\r\n0&0&1&0&0&0&0\\\\\r\n1&1/2&0&1/2&0&0&0\\\\\r\n2&0&1/2&0&1/2&0&0\\\\\r\n3&0&0&1/2&0&1/2&0\\\\\r\n4&0&0&0&1/2&0&1/2\\\\\r\n5&0&0&0&0&1&0\r\n\\end{array}\\]\r\nThen we consider $\\pi_j=\\sum_kP_{kj}\\pi_k$\r\n\\begin{align*}\r\n\\pi_0&=\\pi_1/2\\\\\r\n\\pi_1&=\\pi_0+\\pi_2/2\\\\\r\n\\pi_2&=\\pi_1/2+\\pi_3/2\\\\\r\n\\pi_3&=\\pi_2/2+\\pi_4/2\\\\\r\n\\pi_4&=\\pi_3/2+\\pi_5\\\\\r\n\\pi_5&=\\pi_4/2\r\n\\end{align*}\r\nand\r\n\\begin{equation*}\r\n\\pi_1+\\pi_2+\\pi_3+\\pi_4+\\pi_5=1\r\n\\end{equation*}\r\nSolving the equations we have $\\pi_0=0.1$\r\nTherefore, 1/10 of the time urn A is empty.", "linkability1": 0.0, "linkability2": 0.0, "linkability3": 0.0, "linkability4": 0.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "1. A clearer way to understand the relation $\\pi_j=\\sum_kP_{kj}\\pi_k$ is the new state $\\pi_j$ is equal to all possible transition from old states $\\pi_k$. <br>\r\n2. A quicker way to solve the system is by symmetry. We know $\\pi_0=\\pi_5$, $\\pi_1=\\pi_4$, $\\pi_2=\\pi_3$. Then by the second equation we have $\\pi_1=\\pi_2$. As $\\pi_0+\\pi_1+\\pi_2=0.5$, it is then obvious that $\\pi_0=0.1$, $\\pi_1=\\pi_2=0.2$", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": null, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [3, 37, 39], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 102, "fields": {"code": "4.1.4", "category": 3, "problem": "A finite state regular Markov chain has transition probability matrix $\\mathbf{P}=|P_{ij}|$ and limiting distribution $\\pi=|\\pi_i|$. In the long run, what fraction of the transitions are from the prescribed state $k$ to a prescibed state $m$?", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "$\\pi_k$", "choicesb": "$\\frac{\\pi_mP_{mk}}{\\pi_k}$", "choicesc": "$\\frac{\\pi_kP_{km}}{\\pi_m}$", "choicesd": "$\\pi_m$", "choicese": "$\\frac{P_{km}}{\\sum_iP_{im}}$", "choicesf": "None of the above", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "C", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "Mathematically, we are considering\r\n\\begin{equation*}\r\nP(X_{n+1}=m\\cap X_n=k|X_{n+1}=m)\r\n\\end{equation*}\r\nas\r\n\\begin{equation*}\r\nP(X_{n+1}=m\\cap X_n=k)=P(X_{n+1}=m|X_n=k)P(X_n=k)=P_{km}\\pi_k\r\n\\end{equation*}\r\nand\r\n\\begin{equation*}\r\nP(X_{n+1}=m)=\\pi_m\r\n\\end{equation*}\r\nso\r\n\\begin{equation*}\r\nP(X_{n+1}=m\\cap X_n=k|X_{n+1}=m)=\\frac{\\pi_kP_{km}}{\\pi_m}\r\n\\end{equation*}", "linkability1": 0.0, "linkability2": 0.0, "linkability3": 0.0, "linkability4": 0.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "You can prove your answer with another method, which is related to Prob4.1.13.\r\nConsider\r\n\\begin{align*}\r\nP(X_{n+1}=m\\cap X_n=k|X_{n+1}=m)&=P(X_{n+1}=m|X_n=k\\cap X_{n+1}=m)P(X_n=k|X_{n+1}=m)\\\\\r\n&=1\\times P(X_n=k|X_{n+1}=m)\r\n\\end{align*}\r\nNow you can match the answer with Prob 4.1.13.", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": null, "difficulty": 3, "calculateddifficulty": null, "linkneuron": [3, 27, 37], "rightproblems": [], "wrongproblems": [134, 135, 136], "twinproblems": [105, 134, 135]}}, {"model": "mathematics.question", "pk": 103, "fields": {"code": "4.1.7", "category": 3, "problem": "Determine the limiting distribution for the Markov chain whose transition probability matrix is\r\n\\[P=\r\n\\begin{array}{c|cccc|}\r\n&0&1&2&3\\\\\r\n0&\\frac{1}{2}&0&0&\\frac{1}{2}\\\\\r\n1&1&0&0&0\\\\\r\n2&0&\\frac{1}{2}&\\frac{1}{3}&\\frac{1}{6}\\\\\r\n3&0&0&1&0\r\n\\end{array}\r\n\\]", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "\\begin{align*}\r\n\\pi_0=1/11\\\\\r\n\\pi_1=2/11\\\\\r\n\\pi_2=4/11\\\\\r\n\\pi_3=4/11\r\n\\end{align*}", "choicesb": "\\begin{align*}\r\n\\pi_0=2/11\\\\\r\n\\pi_1=1/11\\\\\r\n\\pi_2=4/11\\\\\r\n\\pi_3=4/11\r\n\\end{align*}", "choicesc": "The Markov chain is not regular.", "choicesd": "\\begin{align*}\r\n\\pi_0=2/11\\\\\r\n\\pi_1=2/11\\\\\r\n\\pi_2=4/11\\\\\r\n\\pi_3=3/11\r\n\\end{align*}", "choicese": "None of the above", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "A", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "Consider the relation $\\pi_j=\\sum_kP_{kj}\\pi_k$, one can read off the system of equations(skim through the matrix column by column ):\r\n\\begin{align*}\r\n\\pi_0&=\\pi_0/2+\\pi_1\\\\\r\n\\pi_1&=\\pi_2/2\\\\\r\n\\pi_2&=\\pi_2/3+\\pi_3/6\\\\\r\n\\pi_3&=\\pi_2\r\n\\end{align*}\r\nSolving the equations we have\r\n\\begin{equation*}\r\n\\pi_0:\\pi_1:\\pi_2:\\pi_3=1:2:4:4\r\n\\end{equation*}\r\nRemember the conservation of probability\r\n\\begin{equation*}\r\n\\pi_0+\\pi_1+\\pi_2+\\pi_3=1\r\n\\end{equation*}\r\nTherefore, $\\pi_0=1/11$, $\\pi_1=2/11$, $\\pi_2=\\pi_3=4/11$", "linkability1": 0.0, "linkability2": 0.0, "linkability3": 0.0, "linkability4": 0.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": null, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [3, 37, 39], "rightproblems": [134], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 104, "fields": {"code": "4.1.10", "category": 3, "problem": "Consider a Markov chain with transition probability matrix\r\n\\[P=\r\n\\begin{array}{|ccccc|}\r\np_0&p_1&p_2&\\dots&p_N\\\\\r\np_N&p_0&p_1&\\dots&p_{N-1}\\\\\r\np_{N-1}&p_N&p_0&\\dots&p_{N-2}\\\\\r\n\\vdots&\\vdots&\\vdots&&\\vdots\\\\\r\np_1&p_2&p_3&\\dots&p_0\r\n\\end{array}\r\n\\]\r\nwhere $0<p_0<1$ and $p_0+p_1+\\dots+p_n=1$. Determine the limiting distribution.", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "$\\pi_j=p_j$", "choicesb": "$\\pi_j=p_{N+1-j}$", "choicesc": "$\\pi_j=1/(N+1)$", "choicesd": "None of the above", "choicese": "", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "C", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "Since the transition is so symmetric, we can guess the answer is 1/(N+1).\r\nWe shall prove this by verifying the condition $\\pi_j=\\sum_{k=0}^NP_{jk}\\pi_k$ where \r\n$P_{jk}=\\begin{cases}\r\np_{j-i}& \\text{if } j-i\\geq0\\\\\r\np_{j-i+N+1}&\\text{if } j-i<0\r\n\\end{cases}$\r\nSo \r\n\\begin{equation*}\r\n\\sum_{j=0}^NP_{jk}\\pi_k=\\frac{1}{N+1}\\sum_{k=0}^Np_k=1/(N+1)=\\pi_j\r\n\\end{equation*}", "linkability1": 0.0, "linkability2": 0.0, "linkability3": 0.0, "linkability4": 0.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": null, "difficulty": 3, "calculateddifficulty": null, "linkneuron": [3, 37, 39], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 105, "fields": {"code": "4.1.13", "category": 3, "problem": "A Markov chain has the transition probability matrix\r\n\\[P=\r\n\\begin{array}{c|ccc|}\r\n&0&1&2\\\\\r\n0&0.4&0.4&0.2\\\\\r\n1&0.6&0.2&0.2\\\\\r\n2&0.4&0.2&0.4\r\n\\end{array}\r\n\\]\r\nAfter a long period of time, you observe the chain and see that it is in state 1. What is the conditional probability that the previous state was 2? That is, find\r\n\\begin{equation*}\r\n\\lim_{n\\to\\infty}\\text{Pr}\\{X_{n-1}=2|X_n=1\\}\r\n\\end{equation*}", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "0.2", "choicesb": "12/70", "choicesc": "6/7", "choicesd": "1/4", "choicese": "None of the above", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "B", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "The transition matrix is about $P(X_{n}|X_{n-1})$, so the obvious choice is to apply Bayes' theorem.\r\n\\begin{align*}\r\n\\lim_{n\\to\\infty}\\text{Pr}\\{X_{n-1}=2|X_n=1\\}&=\\lim_{n\\to\\infty}\\text{Pr}\\{X_n=1|X_{n-1}=2\\}\\frac{\\text{Pr}\\{X_{n-1}=2\\}}{\\text{Pr}\\{X_n=1\\}}\\\\\r\n&=P_{21}\\frac{\\pi_2}{\\pi_1}\r\n\\end{align*}\r\nSolving the long time behaviour, we have $\\pi_0=11/24$, $\\pi_1=7/24$, $\\pi_2=1/4$. Therefore, \r\n\\begin{equation*}\r\n\\lim_{n\\to\\infty}\\text{Pr}\\{X_{n-1}=2|X_n=1\\}=12/70\r\n\\end{equation*}", "linkability1": 0.0, "linkability2": 0.0, "linkability3": 0.0, "linkability4": 0.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": null, "difficulty": 3, "calculateddifficulty": null, "linkneuron": [3, 25, 27, 37, 39], "rightproblems": [], "wrongproblems": [], "twinproblems": [102]}}, {"model": "mathematics.question", "pk": 106, "fields": {"code": "4.2.3", "category": 3, "problem": "Suppose that a production process changes state according to a Markov process whose transition probability matrix is given by \r\n\\[P=\r\n\\begin{array}{c|cccc|}\r\n&0&1&2&3\\\\\r\n0&0.2&0.2&0.4&0.2\\\\\r\n1&0.5&0.2&0.2&0.1\\\\\r\n2&0.2&0.3&0.4&0.1\\\\\r\n3&0.1&0.2&0.4&0.3\r\n\\end{array}\r\n\\]\r\nSuppose that states 0 and 1 are \"in-control\", while states 2 and 3 are deemed \"out-of-control\", In the long run, what fraction of time is the process out-of-control?", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "11/20", "choicesb": "26/51", "choicesc": "14/51", "choicesd": "The  MC is irregular", "choicese": "None of the above", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "B", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "So we want to calculate $\\pi_2+\\pi_3$\r\nThe system of equation can be written as \r\n\\begin{align*}\r\n\\pi_0&=\\pi_0/5+\\pi_1/2+\\pi_2/5+\\pi_3/10\\\\\r\n\\pi_1&=\\pi_0/5+\\pi_1/5+3\\pi_2/10+\\pi_3/5\\\\\r\n\\pi_2&=2\\pi_0/5+\\pi_1/5+2\\pi_2/5+2\\pi_3/5\\\\\r\n\\pi_3&=\\pi_0/5+\\pi_1/10+\\pi_2/10+3\\pi_3/10\r\n\\end{align*}\r\nwith \r\n\\begin{equation*}\r\n\\pi_0+\\pi_1+\\pi_2+\\pi_3=1\r\n\\end{equation*}\r\n$\\pi_0=13/51$? $\\pi_1=4/17$, $\\pi_2=6/17$, $\\pi_3=8/51$ and $\\pi_2+\\pi_3=26/51$", "linkability1": 0.0, "linkability2": 0.0, "linkability3": 0.0, "linkability4": 0.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": null, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [3, 37, 39, 40], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 107, "fields": {"code": "4.2.6", "category": 3, "problem": "Consider a computer system that fails on a given day with probability $p$ and remains \"up\" with probability $1-p$. Suppose the repair time is a random variable $N$ having the probability mass function $p(k)=\\beta(1-\\beta)^{k-1}$ for $k=1,2,...,$ where $0<\\beta<1$. Let $X_n=1$ if the computer is operating on day $n$ and $X_n=0$ if not. Determine the long run probability that the computer is operating in terms of $\\beta,p$.", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "$\\pi_0=\\pi_1=1/2$", "choicesb": "$\\pi_0=p(1-\\beta) \\qquad \\pi_1=p\\beta$", "choicesc": "$\\pi_0=p \\qquad \\pi_1=q$", "choicesd": "$\\pi_0=\\frac{p}{\\beta+p} \\qquad \\pi_1=\\frac{\\beta}{\\beta+p}$", "choicese": "None of the above", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "D", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "Observe that the repair day follow a geometric distribution, it is clearly memoryless. We can conclude that when the computer is down, it has $\\beta$ chance getting repaired and $\\alpha=1-\\beta$ chance not getting repaired. When the computer is up, it has $q$ chance remain up, and $p$ chance being down. The transition matrix is then\r\n\\[\r\n\\begin{array}{c|cc|}\r\n&0&1\\\\\r\n0&1-\\beta&\\beta\\\\\r\n1&p&1-p\r\n\\end{array}\r\n\\]\r\nThe long run probability then have the relation $\\beta\\pi_0=p\\pi_1$ and $\\pi_0+\\pi_1=1$\r\n\\begin{equation*}\r\n\\pi_0=\\frac{p}{\\beta+p} \\qquad \\pi_1=\\frac{\\beta}{\\beta+p}\r\n\\end{equation*}", "linkability1": 0.0, "linkability2": 0.0, "linkability3": 0.0, "linkability4": 0.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": null, "difficulty": 3, "calculateddifficulty": null, "linkneuron": [3, 34, 37, 39], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 133, "fields": {"code": "4.3.1", "category": 3, "problem": "A two-state Markov chain has the transition probability matrix\r\n\\[\\mathbf{P}=\r\n\\begin{array}{c|cc|}\r\n&0&1\\\\\r\n0&1-a&a\\\\\r\n1&b&1-b\r\n\\end{array}\r\n\\]\r\nDetermine the first return probability\r\n\\begin{equation*}\r\nf^{(n)}_{00}=\\text{Pr}\\{X_1\\neq0,\\dots,X_{n-1}\\neq0,X_n=0|X_0=0\\}\r\n\\end{equation*}", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "$b(1-b)^{n-1}a$", "choicesb": "$(1-b)^{n-1}a$", "choicesc": "$b(1-b)^{n-1}$", "choicesd": "$b(1-b)^{n-2}a$", "choicese": "None of the above", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "D", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "\\begin{align*}\r\nf^{(n)}_{00}&=\\text{Pr}\\{X_1\\neq0,\\dots,X_{n-1}\\neq0,X_n=0|X_0=0\\}\\\\\r\n&=\\text{Pr}\\{X_2\\neq0,\\dots,X_{n-1}\\neq0,X_n=0|X_1=1\\}\\text{Pr}\\{X_1=1|X_0=0\\}\\\\\r\n&=\\text{Pr}\\{X_2\\neq0,\\dots,X_{n-1}\\neq0,X_n=0|X_1=1\\}P_{01}\\\\\r\n&=\\text{Pr}\\{X_3\\neq0,\\dots,X_{n-1}\\neq0,X_n=0|X_2=1\\}P_{11}P_{01}\\\\\r\n&=\\text{Pr}\\{X_n=0|X_{n-1}=1\\}P_{11}^{n-2}P_{01}\\\\\r\n&=P_{10}P_{11}^{n-2}P_{01}\r\n\\end{align*}\r\n\r\nSo the probability is $b(1-b)^{n-2}a$", "linkability1": 0.0, "linkability2": 0.0, "linkability3": 0.0, "linkability4": 0.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": null, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [3, 7, 28], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 155, "fields": {"code": "4.1.2", "category": 3, "problem": "Five balls are distributed between two urns, labeled A and B. Each period, one of the five balls is selected at random, and whichever urn it\u2019s in, it is moved to the other urn. In the long run, what fraction of time is urn A empty?", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "A. 1/32", "choicesb": "B. 5/32", "choicesc": "C. 5/16", "choicesd": "D. 1/2", "choicese": "E. 1/4", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "A", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "Let $X_n$ be the number of balls in urn A at the end of period $n$. Then, $\\{X_n\\}$ is a Markov chain with state $ \\{0, 1, 2, 3, 4, 5\\} $. <br> <br>\r\n\r\nThe long-run fraction of time that urn A contain $i$ balls is defined as $\\pi_i$, expressed in the following matrix equation for $i = 0, 1, 2, 3, 4, 5$: \r\n\\begin{align*}\r\n\\left[\\pi_0 \\ \\pi_1 \\ \\pi_2 \\ \\pi_3 \\ \\pi_4 \\ \\pi_5 \\right] = \\mathbf{\\pi}\r\n&= \\mathbf{\\pi} \\cdot \\mathbf{P} = \\mathbf{\\pi} \\cdot \\begin{bmatrix}\r\n0 & 1 & 0 & 0 & 0 & 0\\\\\r\n1/5 & 0 & 4/5 & 0 & 0 & 0\\\\\r\n0 & 2/5 & 0 & 3/5 & 0 & 0\\\\\r\n0 & 0 & 3/5 & 0 & 2/5 & 0\\\\\r\n0 & 0 & 0 & 4/5 & 0 & 1/5\\\\\r\n0 & 0 & 0 & 0 & 1 & 0\\\\\r\n\\end{bmatrix} \\\\\r\n\\mathbf{\\pi}^T\r\n&= \\mathbf{P}^T \\cdot \\mathbf{\\pi}^T \\\\\r\n\\left(\\mathbf{P}^T - \\mathbf{I}_3 \\right) \\cdot \\mathbf{\\pi}^T \r\n&= \\mathbf{0} \\hspace{0.5cm} \r\n\\end{align*}\r\ntogether with $\\pi_0 + \\pi_1 + \\pi_2 + \\pi_3 + \\pi_4 + \\pi_5 = 1$ to solve the solution of $\\pi$, we have:\r\n\\begin{align*}\r\n\\left[\r\n\\begin{array}{c}\r\n\\begin{array}{ccc}\r\n& & \\\\\r\n& \\mathbf{P}^T - \\mathbf{I}_6 & \\\\\r\n& & \\\\\r\n\\end{array}\\\\\r\n\\begin{array}{cccccc}\r\n\\hline\r\n1 & 1 & 1 & 1 & 1 & 1\r\n\\end{array}\r\n\\end{array} \\right] \\cdot  \\mathbf{\\pi}^T \r\n&= \\left[ \\begin{array}{c}\r\n0\\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ 1\\\\\r\n\\end{array} \\right]\r\n\\end{align*}\r\n\r\nwhere $\\mathbf{I}_6$ is the 6 by 6 identity matrix. <br> <br>\r\nLet \r\n\\[\r\n\\mathbf{A} =\r\n\\left[\r\n\\begin{array}{c}\r\n\\begin{array}{ccc}\r\n& & \\\\\r\n& \\mathbf{P}^T - \\mathbf{I}_6 & \\\\\r\n& & \\\\\r\n\\end{array}\\\\\r\n\\begin{array}{cccccc}\r\n\\hline\r\n1 & 1 & 1 & 1 & 1 & 1\r\n\\end{array}\r\n\\end{array} \\right]\r\n\\ , \\\r\n\\mathbf{b} = \\left[ \\begin{array}{c}\r\n0\\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ 1\\\\\r\n\\end{array} \\right]\r\n\\] \\\\\r\nBy least square method, the optimal solution of $\\pi$ is given as:\r\n\\begin{align*}\r\n\\therefore \\ \\mathbf{A} \\mathbf{\\pi}^T &= \\mathbf{b}\\\\\r\n\\mathbf{\\pi}^T &= \\left(\\mathbf{A}^T \\mathbf{A} \\right)^{-1} \\mathbf{A}^T \\mathbf{b} \\\r\n\\end{align*}\r\nFinally, we have:\r\n\\[\r\n\\underline{\\pi_0 = \\frac{1}{32}} \\ , \\ \\pi_1 = \\frac{5}{32} \\ , \\ \\pi_2 = \\frac{5}{16} \\ , \\ \\pi_3 = \\frac{5}{16} \\ , \\ \\pi_4 = \\frac{5}{32} \\ \\ \\text{and} \\ \\ \\pi_5 = \\frac{1}{32}.\r\n\\] \r\nand the desired long run fraction is $\\underline{\\pi_0 = 1/32 \\approx 0.0312}$.", "linkability1": 2.0, "linkability2": 3.0, "linkability3": 1.0, "linkability4": 2.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": 0.2, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [37], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 156, "fields": {"code": "4.1.5", "category": 3, "problem": "The four towns A,B,C, and D are connected by railroad lines as shown in the following diagram (Figure. 4.1.5). <br>\r\nEach day, in whichever town it is in, a train chooses one of the lines out of that town at random and traverses it to the next town, where the process repeats on the next day. In the long run, what is the probability of finding the train in town D?", "problempicture1": "theall/image/4.1.5_WnCN0JZ.png", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "A. 1/8", "choicesb": "B. 1/4", "choicesc": "C. 3/8", "choicesd": "D. 5/8", "choicese": "E. 3/4", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "B", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "Let $X_n$ be the town that the train stops at the end of day $n$. Then, $\\{X_n\\}$ is a Markov chain with state $ \\{A, B, C, D\\} = \\{0, 1, 2, 3\\} $. <br> <br>\r\nThe long-run fraction of time that urn A contain $i$ balls is defined as $\\pi_i$, expressed in the following matrix equation for $i = 0, 1, 2, 3$: \r\n\\begin{align*}\r\n\\left[\\pi_0 \\ \\pi_1 \\ \\pi_2 \\ \\pi_3 \\ \\right] = \\mathbf{\\pi}\r\n&= \\mathbf{\\pi} \\cdot \\mathbf{P} = \\mathbf{\\pi} \\cdot \\begin{bmatrix}\r\n0 & 1/2 & 0 & 1/2 \\\\\r\n1/3 & 0 & 1/3 & 1/3 \\\\\r\n0 & 1 & 0 & 0\\\\\r\n1/2 & 1/2 & 0 & 0 \\\\\r\n\\end{bmatrix} \\\\\r\n\\mathbf{\\pi}^T\r\n&= \\mathbf{P}^T \\cdot \\mathbf{\\pi}^T \\\\\r\n\\left(\\mathbf{P}^T - \\mathbf{I}_4 \\right) \\cdot \\mathbf{\\pi}^T \r\n&= \\mathbf{0} \\hspace{0.5cm} \r\n\\end{align*}\r\ntogether with $\\pi_0 + \\pi_1 + \\pi_2 + \\pi_3 = 1$ to solve the solution of $\\pi$, we have:\r\n\\begin{align*}\r\n\\left[\r\n\\begin{array}{c}\r\n\\begin{array}{ccc}\r\n& & \\\\\r\n& \\mathbf{P}^T - \\mathbf{I}_4 & \\\\\r\n& & \\\\\r\n\\end{array}\\\\\r\n\\begin{array}{cccc}\r\n\\hline\r\n1 & 1 & 1 & 1 \r\n\\end{array}\r\n\\end{array} \\right] \\cdot  \\mathbf{\\pi}^T \r\n&= \\left[ \\begin{array}{c}\r\n0\\\\ 0\\\\ 0\\\\ 0\\\\ 1\\\\\r\n\\end{array} \\right]\r\n\\end{align*}\r\n\r\nwhere $\\mathbf{I}_4$ is the 4 by 4 identity matrix. <br> <br>\r\nLet \r\n\\[\r\n\\mathbf{A} =\r\n\\left[\r\n\\begin{array}{c}\r\n\\begin{array}{ccc}\r\n& & \\\\\r\n& \\mathbf{P}^T - \\mathbf{I}_4 & \\\\\r\n& & \\\\\r\n\\end{array}\\\\\r\n\\begin{array}{cccc}\r\n\\hline\r\n1 & 1 & 1 & 1 \r\n\\end{array}\r\n\\end{array} \\right]\r\n\\ , \\\r\n\\mathbf{b} = \\left[ \\begin{array}{c}\r\n0\\\\ 0\\\\ 0\\\\ 0\\\\ 1\\\\\r\n\\end{array} \\right]\r\n\\] \r\nBy least square method, the optimal solution of $\\pi$ is given as:\r\n\\begin{align*}\r\n\\therefore \\ \\mathbf{A} \\mathbf{\\pi}^T &= \\mathbf{b}\\\\\r\n\\mathbf{\\pi}^T &= \\left(\\mathbf{A}^T \\mathbf{A} \\right)^{-1} \\mathbf{A}^T \\mathbf{b} \\\r\n\\end{align*}\r\nFinally, we have:\r\n\\[\r\n\\pi_0 = \\frac{1}{4} \\ , \\ \\pi_1 = \\frac{3}{8} \\ , \\ \\pi_2 = \\frac{1}{8} \\ \\text{and} \\ \\underline{\\pi_3 = \\frac{1}{4}}.\r\n\\]\r\nand the desired long run fraction is $\\underline{\\pi_3 = 1/4 = 0.25}$.", "linkability1": 2.0, "linkability2": 3.0, "linkability3": 1.0, "linkability4": 2.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": 0.2, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [37], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 157, "fields": {"code": "4.1.8", "category": 3, "problem": "A transition probability matrix is given as\r\n \\[\r\n \\mathbf{P} = \r\n \\begin{array}{l}\r\n \\begin{array}{llllll}\r\n \\hspace{0.125cm} &   \\ \\ \\ 0 \\ & \\hspace{0.125cm} \\ \\ 1 \\ \\  & \\hspace{0.1cm}  \\  2 \\ \\ & \\hspace{0.1cm}  \\   3 \\ \\ \\ & \\hspace{0.1cm}   4 \\  \\ \\ \\ \\\\\r\n \\end{array}\\\\\r\n \\begin{array}{c}\r\n 0\\\\\r\n 1\\\\\r\n 2\\\\\r\n 3\\\\\r\n 4\\\\\r\n \\end{array}\r\n \\begin{Vmatrix}\r\n 0    & 1/2\t& 1/2 \t& 0 \t& 0 \t    \\\\ \r\n 1/2  & 0   & 1/2 \t& 0 \t& 0 \t     \\\\ \r\n 1/3  & 1/3 & 0 \t& 1/3 \t& 0 \t  \\\\ \r\n 0\t  & 0 \t& 1/2 \t& 0 \t& 1/2 \t  \\\\ \r\n 1/2  & 0 \t& 0 \t& 1/2 \t& 0 \t \\\\ \r\n \\end{Vmatrix}\r\n \\end{array}\r\n \\] \r\n Compute the limiting distribution.", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "A. $\\pi_0 = \\frac{5}{38} \\ , \\ \\pi_1 = \\frac{3}{38} \\ , \\ \\pi_2 = \\frac{9}{19} \\ , \\ \\pi_3 = \\frac{4}{19} \\ \\text{and} \\ \\pi_4 = \\frac{2}{19}$", "choicesb": "B. $\\pi_0 = \\frac{18}{43} \\ , \\ \\pi_1 = \\frac{16}{43} \\ , \\ \\pi_2 = \\frac{9}{86} \\ , \\ \\pi_3 = \\frac{5}{86} \\ \\text{and} \\ \\pi_4 = \\frac{2}{43}$", "choicesc": "C. $\\pi_0 = \\frac{22}{87} \\ , \\ \\pi_1 = \\frac{20}{87} \\ , \\ \\pi_2 = \\frac{9}{29} \\ , \\ \\pi_3 = \\frac{4}{29} \\ \\text{and} \\ \\pi_4 = \\frac{2}{29}$", "choicesd": "D. $\\pi_0 = \\frac{22}{73} \\ , \\ \\pi_1 = \\frac{20}{73} \\ , \\ \\pi_2 = \\frac{16}{73} \\ , \\ \\pi_3 = \\frac{9}{73} \\ \\text{and} \\ \\pi_4 = \\frac{6}{73}$", "choicese": "E. $\\pi_0 = \\frac{22}{69} \\ , \\ \\pi_1 = \\frac{20}{69} \\ , \\ \\pi_2 = \\frac{5}{23} \\ , \\ \\pi_3 = \\frac{3}{23} \\ \\text{and} \\ \\pi_4 = \\frac{1}{23}$", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "C", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "The long-run fraction of time that urn A contain $i$ balls is defined as $\\pi_i$, expressed in the following matrix equation for $i = 0, 1, 2, 3, 4$: \r\n\\begin{align*}\r\n\\left[\\pi_0 \\ \\pi_1 \\ \\pi_2 \\ \\pi_3 \\ \\pi_4 \\right] = \\mathbf{\\pi}\r\n&= \\mathbf{\\pi} \\cdot \\mathbf{P} = \\mathbf{\\pi} \\cdot \\begin{bmatrix}\r\n 0    & 1/2\t& 1/2 \t& 0 \t& 0 \t    \\\\ \r\n1/2  & 0   & 1/2 \t& 0 \t& 0 \t     \\\\ \r\n1/3  & 1/3 & 0 \t& 1/3 \t& 0 \t  \\\\ \r\n0\t  & 0 \t& 1/2 \t& 0 \t& 1/2 \t  \\\\ \r\n1/2  & 0 \t& 0 \t& 1/2 \t& 0 \t \\\\ \r\n\\end{bmatrix} \\\\\r\n\\mathbf{\\pi}^T\r\n&= \\mathbf{P}^T \\cdot \\mathbf{\\pi}^T \\\\\r\n\\left(\\mathbf{P}^T - \\mathbf{I}_5 \\right) \\cdot \\mathbf{\\pi}^T \r\n&= \\mathbf{0} \\hspace{0.5cm} \r\n\\end{align*}\r\ntogether with $\\pi_0 + \\pi_1 + \\pi_2 + \\pi_3 + \\pi_4 = 1$ to solve the solution of $\\pi$, we have:\r\n\\begin{align*}\r\n\\left[\r\n\\begin{array}{c}\r\n\\begin{array}{ccc}\r\n& & \\\\\r\n& \\mathbf{P}^T - \\mathbf{I}_5 & \\\\\r\n& & \\\\\r\n\\end{array}\\\\\r\n\\begin{array}{ccccc}\r\n\\hline\r\n1 & 1 & 1 & 1 & 1\r\n\\end{array}\r\n\\end{array} \\right] \\cdot  \\mathbf{\\pi}^T \r\n&= \\left[ \\begin{array}{c}\r\n0\\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ 1\\\\\r\n\\end{array} \\right]\r\n\\end{align*}\r\n\r\nwhere $\\mathbf{I}_5$ is the 5 by 5 identity matrix. <br> <br>\r\nLet \r\n\\[\r\n\\mathbf{A} =\r\n\\left[\r\n\\begin{array}{c}\r\n\\begin{array}{ccc}\r\n& & \\\\\r\n& \\mathbf{P}^T - \\mathbf{I}_5 & \\\\\r\n& & \\\\\r\n\\end{array}\\\\\r\n\\begin{array}{ccccc}\r\n\\hline\r\n1 & 1 & 1 & 1 & 1\r\n\\end{array}\r\n\\end{array} \\right]\r\n\\ , \\\r\n\\mathbf{b} = \\left[ \\begin{array}{c}\r\n0\\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ 1\\\\\r\n\\end{array} \\right]\r\n\\] \r\nBy least square method, the optimal solution of $\\pi$ is given as:\r\n\\begin{align*}\r\n\\therefore \\ \\mathbf{A} \\mathbf{\\pi}^T &= \\mathbf{b}\\\\\r\n\\mathbf{\\pi}^T &= \\left(\\mathbf{A}^T \\mathbf{A} \\right)^{-1} \\mathbf{A}^T \\mathbf{b} \\\r\n\\end{align*}\r\nFinally, we have:\r\n\\[\r\n\\pi_0 = \\frac{22}{87} \\ , \\ \\pi_1 = \\frac{20}{87} \\ , \\ \\pi_2 = \\frac{9}{29} \\ , \\ \\pi_3 = \\frac{4}{29} \\ \\text{and} \\ \\pi_4 = \\frac{2}{29}.\r\n\\]\r\nis the desired limiting distribution.", "linkability1": 2.0, "linkability2": 3.0, "linkability3": 1.0, "linkability4": 2.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": 0.2, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [37], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 158, "fields": {"code": "4.1.11", "category": 3, "problem": "Suppose that a production process changes state according to a Markov process whose transition probability matrix is given by\r\n\\[\r\n\\mathbf{P} = \r\n\\begin{array}{l}\r\n\\begin{array}{lllll}\r\n\\hspace{0.075cm} &   \\ \\ \\ 0 \\ & \\hspace{0.15cm} \\ 1 \\ \\  & \\hspace{0.1cm}   2 \\ \\ & \\hspace{0.125cm}    \r\n 3 \\ \\ \\ \\  \\\\\r\n\\end{array}\\\\\r\n\\begin{array}{c}\r\n0\\\\\r\n1\\\\\r\n2\\\\\r\n3\\\\\r\n\\end{array}\r\n\\begin{Vmatrix}\r\n0.3    & 0.5\t& 0 \t& 0.2 \\\\ \r\n0.5  & 0.2   & 0.2 \t& 0.1 \\\\ \r\n0.2  & 0.3 & 0.4 \t& 0.1\t\\\\ \r\n0.1\t  & 0.2 \t& 0.4 \t& 0.3  \\\\ \r\n\\end{Vmatrix}\r\n\\end{array}\r\n\\] <br>\r\n(a) Suppose that states 0 and 1 are \u201cIn-Control\u201d while states 2 and 3 are deemed \u201cOut-of-Control.\u201d In the long run, what fraction of time is the process Out-of-Control? <br>\r\n(b) In the long run, what fraction of transitions are from an In-Control state to an Out-of-Control state?", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "A. (a). 81/379 (b). 81/379", "choicesb": "B. (a). 62/379 (b). 62/758", "choicesc": "C. (a). 81/379 (b). 81/758", "choicesd": "D. (a). 143/379 (b). 143/758", "choicese": "E. (a). 143/379 (b). 143/379", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "E", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "(a). <br>\r\nThe long-run fraction of time that urn A contain $i$ balls is defined as $\\pi_i$, expressed in the following matrix equation for $i = 0, 1, 2, 3$: \r\n\\begin{align*}\r\n\\left[\\pi_0 \\ \\pi_1 \\ \\pi_2 \\ \\pi_3 \\ \\right] = \\mathbf{\\pi}\r\n&= \\mathbf{\\pi} \\cdot \\mathbf{P} = \\mathbf{\\pi} \\cdot \\begin{bmatrix}\r\n0.3    & 0.5\t& 0 \t& 0.2 \\\\ \r\n0.5  & 0.2   & 0.2 \t& 0.1 \\\\ \r\n0.2  & 0.3 & 0.4 \t& 0.1\t\\\\ \r\n0.1\t  & 0.2 \t& 0.4 \t& 0.3  \\\\ \r\n\\end{bmatrix} \\\\\r\n\\mathbf{\\pi}^T\r\n&= \\mathbf{P}^T \\cdot \\mathbf{\\pi}^T \\\\\r\n\\left(\\mathbf{P}^T - \\mathbf{I}_4 \\right) \\cdot \\mathbf{\\pi}^T \r\n&= \\mathbf{0} \\hspace{0.5cm} \r\n\\end{align*}\r\ntogether with $\\pi_0 + \\pi_1 + \\pi_2 + \\pi_3 = 1$ to solve the solution of $\\pi$, we have:\r\n\\begin{align*}\r\n\\left[\r\n\\begin{array}{c}\r\n\\begin{array}{ccc}\r\n& & \\\\\r\n& \\mathbf{P}^T - \\mathbf{I}_4 & \\\\\r\n& & \\\\\r\n\\end{array}\\\\\r\n\\begin{array}{cccc}\r\n\\hline\r\n1 & 1 & 1 & 1 \r\n\\end{array}\r\n\\end{array} \\right] \\cdot  \\mathbf{\\pi}^T \r\n&= \\left[ \\begin{array}{c}\r\n0\\\\ 0\\\\ 0\\\\ 0\\\\ 1\\\\\r\n\\end{array} \\right]\r\n\\end{align*}\r\n\r\nwhere $\\mathbf{I}_4$ is the 4 by 4 identity matrix. <br> <br>\r\nLet \r\n\\[\r\n\\mathbf{A} =\r\n\\left[\r\n\\begin{array}{c}\r\n\\begin{array}{ccc}\r\n& & \\\\\r\n& \\mathbf{P}^T - \\mathbf{I}_4 & \\\\\r\n& & \\\\\r\n\\end{array}\\\\\r\n\\begin{array}{cccc}\r\n\\hline\r\n1 & 1 & 1 & 1 \r\n\\end{array}\r\n\\end{array} \\right]\r\n\\ , \\\r\n\\mathbf{b} = \\left[ \\begin{array}{c}\r\n0\\\\ 0\\\\ 0\\\\ 0\\\\ 1\\\\\r\n\\end{array} \\right]\r\n\\] \r\nBy least square method, the optimal solution of $\\pi$ is given as:\r\n\\begin{align*}\r\n\\therefore \\ \\mathbf{A} \\mathbf{\\pi}^T &= \\mathbf{b}\\\\\r\n\\mathbf{\\pi}^T &= \\left(\\mathbf{A}^T \\mathbf{A} \\right)^{-1} \\mathbf{A}^T \\mathbf{b} \\\r\n\\end{align*}\r\nFinally, we have:\r\n\\[\r\n\\pi_0 = \\frac{117}{379} \\ , \\ \\pi_1 = \\frac{119}{379} \\ , \\ \\pi_2 = \\frac{81}{379} \\ \\text{and} \\ \\pi_3 = \\frac{62}{379}.\r\n\\]\r\nand the desired long run fraction is $\\underline{\\pi_2 + \\pi_3 = 81/379 + 62/379 = 143/379 \\approx 0.3773}$. <br> \r\n<br>\r\n(b). <br>\r\n The fraction of transitions are from an In-Control state to an Out-of-Control state is:\r\n\\begin{align*}\r\n&\\lim\\limits_{n \\longrightarrow \\infty} P(X_{n+1} = 2 \\cup X_{n+1} = 3 \\ | \\ X_n = 0 \\cup X_n = 1)\\\\\r\n&= \\lim\\limits_{n \\longrightarrow \\infty} P(X_{n+1} = 2 \\cup X_{n+1} = 3 )\\\\\r\n&= \\pi_2 + \\pi_3 \\\\\r\n&= 81/379 + 62/379 = \\underline{143/379}\r\n\\end{align*}", "linkability1": 2.0, "linkability2": 3.0, "linkability3": 1.0, "linkability4": 2.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": 0.2, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [37], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 159, "fields": {"code": "4.2.1", "category": 3, "problem": "Consider a discrete-time periodic review inventory model (see Chapter 3, Section 3.3.1),and let $ n $ be the total demand in period $ n $. Let $X_n$ be the inventory quantity on hand at the end of period n. Instead of following an ($s,S$) policy, a ($q,Q$) policy will be used: If the stock level at the end of a period is less than or equal to $q = 2$ units, then $Q = 2$ additional units will be ordered and will be available at the beginning of the next period. Otherwise, no ordering will take place. This is a ($q,Q$) policy with $q = 2$ and $Q = 2$. Assume that demand that is not filled in a period is lost (no back ordering). <br>\r\n\r\nSuppose that $\\xi_1, \\xi_2, ...$ are independent random variables, each having the probability distribution where\r\n\\[\r\n\\begin{array}{ccccccc}\r\n\\hline \r\nk & = & 0 & 1 & 2 & 3 & 4 \\\\\r\n\\Pr\\{\\xi = k \\} & = & 0.1 & 0.3 & 0.3 & 0.2 & 0.1 \\\\\r\n\\hline\r\n\\end{array}\r\n\\]\r\nThen, $X_0, X_1, ...$ is a Markov chain.  In the long run, during what fraction of periods are orders placed?", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "A. 3/8", "choicesb": "B. 189/680", "choicesc": "C. 15/68", "choicesd": "D. 43/340", "choicese": "E. 297/340", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "E", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "The relationship between $X_{n+1}, X_{n}$ and $\\xi_{n+1}$ according to the problem description is given as\r\n\r\n\\[\r\nX_{n+1} =\r\n\\begin{cases}\r\nX_n + 2 - \\xi_{n+1} & \\ \\ \\text{if} \\ \\ X_n \\leq 2 \\\\\r\nX_n - \\xi_{n+1} & \\ \\ \\text{if} \\ \\ X_n > 2 \\\\\r\n0 & \\ \\ \\text{if} \\ \\ X_n < 0 \\\\\r\n\\end{cases}\r\n\\] \r\n\r\nTherefore, the transition probability is given as:\r\n\\[\r\n\\mathbf{P} = \r\n\\begin{array}{l}\r\n\t\\begin{array}{llllll}\r\n\t\t\\hspace{0.125cm} &   \\ \\ 0 \\ & \\hspace{0.15cm} \\ 1 \\ \\  & \\hspace{0.125cm}  2 \\ \\ & \\hspace{0.125cm}   3 \\ \\  & \\hspace{0.125cm}  4 \\  \\ \\ \\ \\\\\r\n\t\\end{array}\\\\\r\n\t\\begin{array}{c}\r\n\t\t0\\\\\r\n\t\t1\\\\\r\n\t\t2\\\\\r\n\t\t3\\\\\r\n\t\t4\\\\\r\n\t\\end{array}\r\n\t\\begin{Vmatrix}\r\n\t\t0.6  & 0.3\t& 0.1 \t& 0 \t& 0 \t    \\\\ \r\n\t\t0.3  & 0.3  & 0.3 \t& 0.1 \t& 0 \t \\\\ \r\n\t\t0.1  & 0.2  & 0.3 \t& 0.3 \t& 0.1 \t  \\\\ \r\n\t\t0.3  & 0.3  & 0.3 \t& 0.1 \t& 0 \t \\\\ \r\n\t\t0.6  & 0.3\t& 0.1 \t& 0 \t& 0 \t    \\\\ \r\n\t\\end{Vmatrix}\r\n\\end{array}\r\n\\]\r\n\r\nThe long-run fraction of time that urn A contain $i$ balls is defined as $\\pi_i$, expressed in the following matrix equation for $i = 0, 1, 2, 3, 4$:\r\n\r\n\\begin{align*}\r\n\\left[\\pi_0 \\ \\pi_1 \\ \\pi_2 \\ \\pi_3 \\ \\pi_4 \\right] = \\mathbf{\\pi}\r\n&= \\mathbf{\\pi} \\cdot \\mathbf{P} = \\mathbf{\\pi} \\cdot \\begin{bmatrix}\r\n0.6  & 0.3\t& 0.1 \t& 0 \t& 0 \t    \\\\ \r\n0.3  & 0.3  & 0.3 \t& 0.1 \t& 0 \t \\\\ \r\n0.1  & 0.2  & 0.3 \t& 0.3 \t& 0.1 \t  \\\\ \r\n0.3  & 0.3  & 0.3 \t& 0.1 \t& 0 \t \\\\ \r\n0.6  & 0.3\t& 0.1 \t& 0 \t& 0 \t    \\\\ \r\n\\end{bmatrix} \\\\\r\n\\mathbf{\\pi}^T\r\n&= \\mathbf{P}^T \\cdot \\mathbf{\\pi}^T \\\\\r\n\\left(\\mathbf{P}^T - \\mathbf{I}_5 \\right) \\cdot \\mathbf{\\pi}^T \r\n&= \\mathbf{0} \\hspace{0.5cm} \r\n\\end{align*}\r\ntogether with $\\pi_0 + \\pi_1 + \\pi_2 + \\pi_3 + \\pi_4 = 1$ to solve the solution of $\\pi$, we have:\r\n\\begin{align*}\r\n\\left[\r\n\\begin{array}{c}\r\n\\begin{array}{ccc}\r\n& & \\\\\r\n& \\mathbf{P}^T - \\mathbf{I}_5 & \\\\\r\n& & \\\\\r\n\\end{array}\\\\\r\n\\begin{array}{ccccc}\r\n\\hline\r\n1 & 1 & 1 & 1 & 1\r\n\\end{array}\r\n\\end{array} \\right] \\cdot  \\mathbf{\\pi}^T \r\n&= \\left[ \\begin{array}{c}\r\n0\\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ 1\\\\\r\n\\end{array} \\right]\r\n\\end{align*}\r\n\r\nwhere $\\mathbf{I}_5$ is the 5 by 5 identity matrix. <br> <br>\r\nLet \r\n\\[\r\n\\mathbf{A} =\r\n\\left[\r\n\\begin{array}{c}\r\n\\begin{array}{ccc}\r\n& & \\\\\r\n& \\mathbf{P}^T - \\mathbf{I}_5 & \\\\\r\n& & \\\\\r\n\\end{array}\\\\\r\n\\begin{array}{ccccc}\r\n\\hline\r\n1 & 1 & 1 & 1 & 1\r\n\\end{array}\r\n\\end{array} \\right]\r\n\\ , \\\r\n\\mathbf{b} = \\left[ \\begin{array}{c}\r\n0\\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ 1\\\\\r\n\\end{array} \\right]\r\n\\] \r\nBy least square method, the optimal solution of $\\pi$ is given as:\r\n\\begin{align*}\r\n\\therefore \\ \\mathbf{A} \\mathbf{\\pi}^T &= \\mathbf{b}\\\\\r\n\\mathbf{\\pi}^T &= \\left(\\mathbf{A}^T \\mathbf{A} \\right)^{-1} \\mathbf{A}^T \\mathbf{b} \\\r\n\\end{align*}\r\nFinally, we have:\r\n\\[\r\n\\pi_0 = \\frac{3}{8} \\ , \\ \\pi_1 = \\frac{189}{680} \\ , \\ \\pi_2 = \\frac{15}{68} \\ , \\ \\pi_3 = \\frac{71}{680} \\ \\text{and} \\ \\pi_4 = \\frac{3}{136}.\r\n\\]\r\nand the desired long run fraction is $\\underline{\\pi_0 + \\pi_1 + \\pi_2 = 3/8 + 189/680 + 15/68 = 297/340 \\approx 0.8735}$.", "linkability1": 2.0, "linkability2": 3.0, "linkability3": 3.0, "linkability4": 2.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": 0.2, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [37], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 160, "fields": {"code": "4.2.4", "category": 3, "problem": "A component of a computer has an active life, measured in discrete units, that is a random variable $\\xi$, where <br>\r\n\\[\r\n\\begin{array}{cccccc}\r\n\\hline \r\nk & =  & 1 & 2 & 3 & 4 \\\\\r\n\\Pr\\{\\xi = k \\} & = & 0.1 & 0.3 & 0.2 & 0.4 \\\\\r\n\\hline\r\n\\end{array}\r\n\\] <br>\r\nSuppose that one starts with a fresh component, and each component is replaced by a new component upon failure. Let $X_n$ be the remaining life of the component in service at the end of period $n$. When $X_n = 0$, a new item is placed into service at the start of the next period. <br> <br>\r\n(a). Determine the long run probability that the item in service at the end of a period has no remaining life and therefore will be replaced.<br>\r\n(b). Determine the mean life of a component.", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "A. (a). 10/39; (b). 62/29", "choicesb": "B. (a). 10/39; (b). 62/39", "choicesc": "C. (a). 29/39; (b). 62/29", "choicesd": "D. (a). 29/39; (b). 62/39", "choicese": "E. (a). 4/39; (b). 62/29", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "A", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "The transition probability is given as:\r\n\\[\r\n\\mathbf{P} = \r\n\\begin{array}{l}\r\n\\begin{array}{llllll}\r\n\\hspace{0.125cm} & \\    0 \\ & \\hspace{0.1cm}  1 \\ \\  & \\hspace{0.075cm}   2 \\ \\ & \\hspace{0.125cm}   3 \\ \\ & \\hspace{0.125cm}  4 \\  \\ \\ \\ \\\\\r\n\\end{array}\\\\\r\n\\begin{array}{c}\r\n0\\\\\r\n1\\\\\r\n2\\\\\r\n3\\\\\r\n4\\\\\r\n\\end{array}\r\n\\begin{Vmatrix}\r\n0\t& 0.1\t& 0.3 \t& 0.2 \t& 0.4 \t    \\\\ \r\n1   & 0\t\t& 0 \t& 0 \t& 0 \t \\\\ \r\n0   & 1 \t& 0 \t& 0 \t& 0 \t  \\\\ \r\n0   & 0  \t& 1 \t& 0 \t& 0 \t \\\\ \r\n0   & 0\t\t& 0 \t& 1 \t& 0 \t    \\\\ \r\n\\end{Vmatrix}\r\n\\end{array}\r\n\\]\r\n\r\nThe long-run fraction of time that urn A contain $i$ balls is defined as $\\pi_i$, expressed in the following matrix equation for $i = 0, 1, 2, 3, 4$:\r\n\r\n\\begin{align*}\r\n\\left[\\pi_0 \\ \\pi_1 \\ \\pi_2 \\ \\pi_3 \\ \\pi_4 \\right] = \\mathbf{\\pi}\r\n&= \\mathbf{\\pi} \\cdot \\mathbf{P} = \\mathbf{\\pi} \\cdot \\begin{bmatrix}\r\n0\t& 0.1\t& 0.3 \t& 0.2 \t& 0.4 \t    \\\\ \r\n1   & 0\t\t& 0 \t& 0 \t& 0 \t \\\\ \r\n0   & 1 \t& 0 \t& 0 \t& 0 \t  \\\\ \r\n0   & 0  \t& 1 \t& 0 \t& 0 \t \\\\ \r\n0   & 0\t\t& 0 \t& 1 \t& 0 \t    \\\\ \r\n\\end{bmatrix} \\\\\r\n\\mathbf{\\pi}^T\r\n&= \\mathbf{P}^T \\cdot \\mathbf{\\pi}^T \\\\\r\n\\left(\\mathbf{P}^T - \\mathbf{I}_5 \\right) \\cdot \\mathbf{\\pi}^T \r\n&= \\mathbf{0} \\hspace{0.5cm} \r\n\\end{align*}\r\ntogether with $\\pi_0 + \\pi_1 + \\pi_2 + \\pi_3 + \\pi_4 = 1$ to solve the solution of $\\pi$, we have:\r\n\\begin{align*}\r\n\\left[\r\n\\begin{array}{c}\r\n\\begin{array}{ccc}\r\n& & \\\\\r\n& \\mathbf{P}^T - \\mathbf{I}_5 & \\\\\r\n& & \\\\\r\n\\end{array}\\\\\r\n\\begin{array}{ccccc}\r\n\\hline\r\n1 & 1 & 1 & 1 & 1\r\n\\end{array}\r\n\\end{array} \\right] \\cdot  \\mathbf{\\pi}^T \r\n&= \\left[ \\begin{array}{c}\r\n0\\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ 1\\\\\r\n\\end{array} \\right]\r\n\\end{align*}\r\n\r\nwhere $\\mathbf{I}_5$ is the 5 by 5 identity matrix. <br> <br>\r\nLet \r\n\\[\r\n\\mathbf{A} =\r\n\\left[\r\n\\begin{array}{c}\r\n\\begin{array}{ccc}\r\n& & \\\\\r\n& \\mathbf{P}^T - \\mathbf{I}_5 & \\\\\r\n& & \\\\\r\n\\end{array}\\\\\r\n\\begin{array}{ccccc}\r\n\\hline\r\n1 & 1 & 1 & 1 & 1\r\n\\end{array}\r\n\\end{array} \\right]\r\n\\ , \\\r\n\\mathbf{b} = \\left[ \\begin{array}{c}\r\n0\\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ 1\\\\\r\n\\end{array} \\right]\r\n\\] \r\nBy least square method, the optimal solution of $\\pi$ is given as:\r\n\\begin{align*}\r\n\\therefore \\ \\mathbf{A} \\mathbf{\\pi}^T &= \\mathbf{b}\\\\\r\n\\mathbf{\\pi}^T &= \\left(\\mathbf{A}^T \\mathbf{A} \\right)^{-1} \\mathbf{A}^T \\mathbf{b} \\\r\n\\end{align*}\r\nFinally, we have:\r\n\\[\r\n\\pi_0 = \\frac{10}{39} \\ , \\ \\pi_1 = \\frac{10}{39} \\ , \\ \\pi_2 = \\frac{3}{13} \\ , \\ \\pi_3 = \\frac{2}{13} \\ \\text{and} \\ \\pi_4 = \\frac{4}{39}.\r\n\\]\r\nand the desired long run fraction is $\\underline{\\pi_0 = 10/39 \\approx 0.2564}$. <br>\r\n\r\nThe mean life time of a component is:\r\n\r\n\\[\r\nE(\\xi) = \\sum_{k = 1}^{4} k \\cdot \\left(\\frac{\\pi_k}{\\sum_{k = 1}^{4} \\pi_k}\\right) =  \\left( \\frac{1 \\cdot \\pi_1 + 2 \\cdot \\pi_2 + 3 \\cdot \\pi_3 + 4 \\cdot \\pi_4}{\\pi_1 + \\pi_2 + \\pi_3 + \\pi_4} \\right) = \\underline{62/29} \\approx 2.1379\r\n\\]", "linkability1": 3.0, "linkability2": 3.0, "linkability3": 1.0, "linkability4": 2.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": 0.2, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [37], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 161, "fields": {"code": "4.2.7", "category": 3, "problem": "Customers arrive for service and take their place in a waiting line. There is a single service facility, and a customer undergoing service at the beginning of a period will complete service and depart at the end of the period with probability $\\beta$ and will continue service into the next period with probability $\\alpha = 1 - \\beta$, and then the process repeats. This description implies that the service time $\\xi$ of an individual is a random variable with the geometric distribution, <br>\r\n\\[\r\n\\Pr\\{\\xi = k \\} = \\beta \\alpha^{k-1} \\ \\ \\text{for} \\ k = 1, 2, ...,\r\n\\]\r\n<br>\r\n and the service times of distinct customers are independent random variables. <br>\r\n At most a single customer can arrive during a period. We suppose that the actual number of arrivals during the nth period is a random variable $ \\xi_n $ taking on the values 0 or 1 according to <br>\r\n \\[\r\n \\Pr\\{\\xi_n = 0 \\} = p\r\n \\]\r\n and <br>\r\n \\[\r\n \\Pr\\{\\xi_n = 1 \\} = q = 1 - p \\ \\ \\text{for} \\ n = 0, 1, ...\r\n \\]\r\n<br>\r\n  The state $ X_n $ of the system at the start of period $ n $ is defined to be the number of customers in the system, either waiting or being served. Then, $ \\{X_n \\} $ is a Markov chain. Specify the following transition probabilities in terms of $\\alpha, \\beta, p $ and $ q $ : $ P_{00},P_{01},P_{02}, P_{10}, P_{11}, $ and $ P_{12} $.", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "A. \r\n\\[\\begin{array}{l}\r\n\\begin{array}{lllll}\r\n\\hspace{0.125cm} & \\   \\ 0 \\ & \\hspace{0.375cm} \\ \\ \\ 1 \\ \\  & \\hspace{0.425cm}  \\ \\ 2 \\ \\ & \\hspace{0.05cm}  \\cdots \\ \\ \\ \\  \\\\\r\n\\end{array}\\\\\r\n\\begin{array}{c}\r\n0\\\\\r\n1\\\\\r\n2\\\\\r\n\\vdots\\\\\r\n\\end{array}\r\n\\begin{Vmatrix}\r\np \\beta\t& q \\beta + \\alpha\t& 0 \t& \\cdots    \\\\ \r\np \\beta   & q \\beta + p \\alpha\t\t& q \\beta \\alpha \t& \\cdots \t \t \\\\ \r\n\\vdots   & \\vdots \t& \\vdots \t& \\cdots \t \t  \\\\ \r\n\\vdots   & \\vdots  \t& \\vdots \t& \\cdots \t \t \\\\ \r\n\\end{Vmatrix}\r\n\\end{array}\\]", "choicesb": "B. \r\n\\[\\begin{array}{l}\r\n\t\\begin{array}{lllll}\r\n\\hspace{0.125cm} & \\   \\ \\ \\ \\ 0 \\ & \\hspace{0.675cm} \\ \\ \\ 1 \\ \\  & \\hspace{0.425cm}  \\ \\ \\ 2 \\ \\ & \\hspace{0.05cm}  \\cdots \\ \\ \\ \\  \\\\\r\n\t\\end{array}\\\\\r\n\t\\begin{array}{c}\r\n\t\t0\\\\\r\n\t\t1\\\\\r\n\t\t2\\\\\r\n\t\t\\vdots\\\\\r\n\t\\end{array}\r\n\t\\begin{Vmatrix}\r\n\t\tp + q \\beta\t& q \\beta \\alpha\t& 0 \t& \\cdots    \\\\ \r\n\t\tp \\beta   & q \\beta + p \\alpha\t\t& q \\beta \\alpha \t& \\cdots \t \t \\\\ \r\n\t\t\\vdots   & \\vdots \t& \\vdots \t& \\cdots \t \t  \\\\ \r\n\t\t\\vdots   & \\vdots  \t& \\vdots \t& \\cdots \t \t \\\\ \r\n\t\\end{Vmatrix}\r\n\\end{array}\\]", "choicesc": "C. \\[\\begin{array}{l}\r\n\\begin{array}{lllll}\r\n\\hspace{0.125cm} & \\   \\ 0 \\ & \\hspace{0.375cm} \\ \\ \\ 1 \\ \\  & \\hspace{0.425cm}  \\ \\ 2 \\ \\ & \\hspace{0.05cm}  \\cdots \\ \\ \\ \\  \\\\\r\n\\end{array}\\\\\r\n\\begin{array}{c}\r\n0\\\\\r\n1\\\\\r\n2\\\\\r\n\\vdots\\\\\r\n\\end{array}\r\n\\begin{Vmatrix}\r\n q \\beta\t& q \\alpha + p\t& 0 \t& \\cdots    \\\\ \r\np \\beta   & q \\beta + p \\alpha\t\t& q \\beta \\alpha \t& \\cdots \t \t \\\\ \r\n\\vdots   & \\vdots \t& \\vdots \t& \\cdots \t \t  \\\\ \r\n\\vdots   & \\vdots  \t& \\vdots \t& \\cdots \t \t \\\\ \r\n\\end{Vmatrix}\r\n\\end{array}\\]", "choicesd": "D. \\[\\begin{array}{l}\r\n\\begin{array}{lllll}\r\n\\hspace{0.125cm} & \\   \\ 0 \\ & \\hspace{0.375cm} \\ \\ \\ 1 \\ \\  & \\hspace{0.425cm}  \\ \\ 2 \\ \\ & \\hspace{0.05cm}  \\cdots \\ \\ \\ \\  \\\\\r\n\\end{array}\\\\\r\n\\begin{array}{c}\r\n0\\\\\r\n1\\\\\r\n2\\\\\r\n\\vdots\\\\\r\n\\end{array}\r\n\\begin{Vmatrix}\r\np \t& q \\beta\t& q  \\alpha \t& \\cdots    \\\\ \r\np \\beta   & q \\beta + p \\alpha\t\t& q \\beta \\alpha \t& \\cdots \t \t \\\\ \r\n\\vdots   & \\vdots \t& \\vdots \t& \\cdots \t \t  \\\\ \r\n\\vdots   & \\vdots  \t& \\vdots \t& \\cdots \t \t \\\\ \r\n\\end{Vmatrix}\r\n\\end{array}\\]", "choicese": "E. \\[\\begin{array}{l}\r\n\\begin{array}{lllll}\r\n\\hspace{0.125cm} & \\   \\ \\ \\ \\ 0 \\ & \\hspace{0.475cm} \\ \\ 1 \\ \\  & \\hspace{0.15cm} 2 \\ & \\hspace{0.05cm}  \\cdots \\ \\ \\ \\  \\\\\r\n\\end{array}\\\\\r\n\\begin{array}{c}\r\n0\\\\\r\n1\\\\\r\n2\\\\\r\n\\vdots\\\\\r\n\\end{array}\r\n\\begin{Vmatrix}\r\np + q \\beta\t& q \\beta \\alpha\t& 0 \t& \\cdots    \\\\ \r\np \t& q \\beta\t& q  \\alpha \t& \\cdots \t \t \\\\ \r\n\\vdots   & \\vdots \t& \\vdots \t& \\cdots \t \t  \\\\ \r\n\\vdots   & \\vdots  \t& \\vdots \t& \\cdots \t \t \\\\ \r\n\\end{Vmatrix}\r\n\\end{array}\\]\\\\", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "B", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "Assume $\\xi_1, \\xi_2, ...$ are independent identically distributed (iid) random variables, the transition probability matrix is given as:\r\n\r\n\\begin{align*}\r\n\\mathbf{P} \r\n&= \r\n\\begin{array}{l}\r\n\\begin{array}{lllll}\r\n\\hspace{0.125cm} &   \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ 0 \\ & \\hspace{1.75cm} \\ \\ \\ \\ \\ \\ \\ \\ \\ 1 \\ \\  & \\hspace{2.025cm}  \\ \\ \\ \\ \\ \\ \\ \\ 2 \\ \\ & \\hspace{0.725cm}   \\ \\ \\ \\cdots \\ \\ \\ \\  \\\\\r\n\\end{array}\\\\\r\n\\begin{array}{c}\r\n0\\\\\r\n1\\\\\r\n2\\\\\r\n\\vdots\\\\\r\n\\end{array}\r\n\\begin{Vmatrix}\r\np + (1-p) \\beta\t& (1-p) \\beta (1 - \\beta)\t& 0 \t& \\cdots    \\\\ \r\np \\beta   & (1-p) \\beta + p (1 - \\beta)\t\t& (1-p)\\beta(1-\\beta) \t& \\cdots \t \t \\\\ \r\n\\vdots   & \\vdots \t& \\vdots \t& \\cdots \t \t  \\\\ \r\n\\vdots   & \\vdots  \t& \\vdots \t& \\cdots \t \t \\\\ \r\n\\end{Vmatrix}\r\n\\end{array} \\\\\r\n&= \r\n\\begin{array}{l}\r\n\\begin{array}{lllll}\r\n\\hspace{0.125cm} & \\   \\ \\ \\ \\ 0 \\ & \\hspace{0.675cm} \\ \\ \\ 1 \\ \\  & \\hspace{0.425cm}  \\ \\ \\ 2 \\ \\ & \\hspace{0.05cm}  \\cdots \\ \\ \\ \\  \\\\\r\n\\end{array}\\\\\r\n\\begin{array}{c}\r\n0\\\\\r\n1\\\\\r\n2\\\\\r\n\\vdots\\\\\r\n\\end{array}\r\n\\begin{Vmatrix}\r\np + q \\beta\t& q \\beta \\alpha\t& 0 \t& \\cdots    \\\\ \r\np \\beta   & q \\beta + p \\alpha\t\t& q \\beta \\alpha \t& \\cdots \t \t \\\\ \r\n\\vdots   & \\vdots \t& \\vdots \t& \\cdots \t \t  \\\\ \r\n\\vdots   & \\vdots  \t& \\vdots \t& \\cdots \t \t \\\\ \r\n\\end{Vmatrix}\r\n\\end{array}\r\n\\end{align*}", "linkability1": 3.0, "linkability2": 1.0, "linkability3": 3.0, "linkability4": 2.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": 0.2, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 162, "fields": {"code": "4.3.2", "category": 3, "problem": "Which of the following property/properties that a finite-state aperiodic irreducible Markov chain has:", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "A. Regular", "choicesb": "B. Recurrent", "choicesc": "C. Both A and B", "choicesd": "D. Neither A and B", "choicese": "E. It cannot be determined.", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "C", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "An aperiodic irreducible Markov chain is regular since the states communicate each other will have a well-mixed transition probability matrix as long as it is not periodic. \\\\\r\n\r\nAs the Markov chain is regular, there exists a limiting distribution such that all diagonal entires are positive. The condition of a recurrent Markov chain is $\\sum_{n=1}^{\\infty} P_{ii}^{(n)} = \\infty$, which is also satisfied.\\\\\r\n\r\nSo an aperiodic irreducible Markov chain is regular and recurrent.", "linkability1": 3.0, "linkability2": 1.0, "linkability3": 3.0, "linkability4": 1.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": 0.2, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [35, 52, 53, 56], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 163, "fields": {"code": "7.1.1", "category": 3, "problem": "Determine whether the following equivalences for the age and the excess life in a renewal process $ N(t) $ are correct or not: (Assume $ t > x $)\r\n \\begin{eqnarray*}\r\n Pr\\{\\delta_t\\geq x,\\gamma_t > y\\}&=& Pr\\{N(t-x)=N(t+y)\\}\\\\\r\n &=& \\sum_{k=0}^{\\infty}Pr\\{W_k < t-x,W_{k+1 } > t+y\\}\\\\\r\n &=& [1-F(t+y)]+\\sum_{k=1}^{\\infty}\\int_{0}^{t-x}[1-F(t+y-z)]dF_k(z)\r\n \\end{eqnarray*}\r\nIf correct, carry out the evaluation when the interoccurrence times are exponentially distributed with parameter $ \\lambda $, so that $ dF_k(z) $ is gamma density\r\n$$ dF_k(z) = \\frac{\\lambda^kz^{k-1}}{(k-1)!}e^{-\\lambda z}dz ~~~ for ~z > 0.$$", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "Not true.", "choicesb": "True, and the evaluation above is $ \\lambda e^{-\\lambda x - \\lambda y} $.", "choicesc": "True, and the evaluation above is $  e^{-\\lambda x - \\lambda y} $.", "choicesd": "True, and the evaluation above is $  e^{\\lambda x + \\lambda y} $.", "choicese": "None of the above is correct.", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "C", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "First, we prove the statement is true.\r\n With the definition of age and excess life, we have\r\n \\begin{eqnarray*}\r\n Pr\\{\\delta_t\\geq x,\\gamma_t > y\\}&=& Pr(W_{N(t)}\\leq t-x, W_{N(t)+1}>t+y)\\\\\r\n &=& Pr(N(t-x)\\geq N(t), N(t+y)<N(t)+1)\\\\\r\n &=& Pr (N(t-x)=N(t)=N(t+y))\\\\\r\n &=& Pr(N(t-x)=N(t+y))\\\\\r\n &=& \\sum_{k=0}^{\\infty}Pr(W_k<t-x, W_{k+1}>t+y)\\\\\r\n &=& Pr(W_0<t-x,W_1>t+y)+\\sum_{k=1}^{\\infty}Pr(W_k<t-x,W_{k+1}>t+y)\\\\ \r\n &=&[1-Pr(W_1\\leq t+y)]+\\sum_{k=1}^{\\infty}[Pr(W_k<t-x)-Pr(W_k<t-x,W_{k+1}=W_k+X_{k+1}\\leq t+y)]\\\\\r\n &=& [1-F(t+y)]+\\sum_{k=1}^{\\infty}[\\int_{0}^{t-x}dF_k(z)-\\int_{0}^{t-x}\\int_{0}^{t+y-z}dF(\\xi)dF_k(z)]\\\\\r\n &=& [1-F(t+y)]+\\sum_{k=1}^{\\infty}\\int_{0}^{t-x}[1-F(t+y-z)]dF_k(z) \r\n \\end{eqnarray*}\r\nSo we finish the proof of the statement. Now we assume that $$ dF_k(z) = \\frac{\\lambda^kz^{k-1}}{(k-1)!}e^{-\\lambda z}dz ~~~ for ~z>0.$$\r\nSo we have $ F(z)=1-e^{-\\lambda z} $, then\r\n\\begin{eqnarray*}\r\n Pr\\{\\delta_t\\geq x,\\gamma_t > y\\}&=& e^{-\\lambda t-\\lambda y}+\\sum_{k=1}^{\\infty}\\int_{0}^{t-x}\\frac{\\lambda^k z^{k-1}}{(k-1)!}e^{-\\lambda t-\\lambda y}dz\\\\\r\n &=& e^{-\\lambda t-\\lambda y} +\\sum_{k=1}^{\\infty} \\frac{\\lambda^k (t-x)^{k}}{k!}e^{-\\lambda t-\\lambda y}\\\\\r\n &=& \\sum_{k=0}^{\\infty} \\frac{\\lambda^k (t-x)^{k}}{k!}e^{-\\lambda t-\\lambda y}\\\\\r\n &=& e^{-\\lambda t-\\lambda y}\\times e^{\\lambda t-\\lambda x}\\\\\r\n &=& e^{-\\lambda x-\\lambda y}\r\n\\end{eqnarray*}\r\nSo the correct answer is c.", "linkability1": 3.0, "linkability2": 3.0, "linkability3": 2.0, "linkability4": 1.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": 0.0, "errors": "", "alternativesolutions": "", "messagefailure": "Oops! Please check whether there are some mistakes in your computation.", "messagesuccess": "Congratulations! You have mastered the definition of the renewal process\r\nand known how to use it.", "sensitivity": 1.0, "gussingparameter": null, "difficulty": 4, "calculateddifficulty": null, "linkneuron": [76, 83], "rightproblems": [], "wrongproblems": [164, 166, 169], "twinproblems": [164, 166]}}, {"model": "mathematics.question", "pk": 164, "fields": {"code": "7.1.2", "category": 3, "problem": "For $ k\\geq 1 $, determine whether the following statement is true:\r\n \\begin{eqnarray*}\r\n Pr\\{N(t) = k\\} &=& Pr\\{W_k\\leq t < W_{k+1}\\}\\\\\r\n &=& \\int_{0}^{t} [1-F(t-x)]dF_k(x)\r\n \\end{eqnarray*}\r\nIf true, carry out the evaluation when the interoccurrence times are exponentially distributed with parameter $ \\lambda $, so that $ dF_k(z) $ is gamma density\r\n$$ dF_k(z) = \\frac{\\lambda^kz^{k-1}}{(k-1)!}e^{-\\lambda z}dz ~~~ for ~z>0.$$", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "Not true.", "choicesb": "True, and the evaluation above is $ \\frac{(\\lambda t)^k}{k!}e^{-\\lambda t} $.", "choicesc": "True, and the evaluation above is $ e^{-\\lambda kt} $.", "choicesd": "True, and the evaluation above is $  \\frac{(\\lambda t)^k}{(k-1)!}e^{-\\lambda kt} $.", "choicese": "None of the above is correct.", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "B", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "First, we prove the statement is true.\r\n With the definition of age and excess life, we have\r\n \\begin{eqnarray*}\r\nPr\\{N(t) = k\\} &=&Pr\\{N(t)\\geq k\\}-Pr\\{N(t)\\geq k+1\\}\\\\\r\n&=& Pr\\{W_k\\leq t\\}-Pr\\{  W_{k+1}\\leq t\\}\\\\\r\n&=& Pr\\{W_k\\leq t < W_{k+1}\\}\\\\\r\n&=& \\int_{0}^{t}\\int_{t-z}^{\\infty} dF(\\xi)dF_k(z)\\\\\r\n&=&\\int_{0}^{t} [1-F(t-z)]dF_k(z)\r\n \\end{eqnarray*}\r\nSo we finish the proof of the statement. Now we assume that $$ dF_k(z) = \\frac{\\lambda^kz^{k-1}}{(k-1)!}e^{-\\lambda z}dz ~~~ for ~z>0.$$\r\nSo we have $ F(z)=1-e^{-\\lambda z} $, then\r\n\\begin{eqnarray*}\r\n Pr\\{N(t) = k\\} &=& \\int_{0}^{t} e^{-\\lambda t+ \\lambda z}\\frac{\\lambda^k z^{k-1}}{(k-1)!}e^{-\\lambda z} dz\\\\\r\n &=& \\frac{(\\lambda t)^k}{k!}e^{-\\lambda t}\r\n\\end{eqnarray*}\r\nSo the correct answer is c.", "linkability1": 3.0, "linkability2": 2.0, "linkability3": 2.0, "linkability4": 1.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": 0.0, "errors": "", "alternativesolutions": "", "messagefailure": "Oops! Please check whether there are some mistakes in your computation.", "messagesuccess": "Congratulations! You have mastered the definition of the renewal process\r\nand known how to use it.", "sensitivity": null, "gussingparameter": null, "difficulty": 3, "calculateddifficulty": null, "linkneuron": [76], "rightproblems": [], "wrongproblems": [163], "twinproblems": [163]}}, {"model": "mathematics.question", "pk": 165, "fields": {"code": "7.1.3", "category": 3, "problem": "A fundamental identity involving the renewal function, vaild for all renewal processes, is\r\n $$ E[W_{N(t)+1}] = E[X_1](M(t)+1) ,$$\r\n where $ M(t) = E[N(t)]$. Using this identity, compute the mean excess life $ E[\\gamma_t] .$ The  $ E[\\gamma_t] $ is:", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "$ E[X_1](1+M(t)) -t $", "choicesb": "$ E[X_1](1+M(t))  $", "choicesc": "$ E[X_1](1+M(t)) +t $", "choicesd": "$ E[X_1]M(t) +1 $", "choicese": "None of the above is correct.", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "A", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "Since $ \\gamma_t = W_{N(t)+1} -t $, with the identity above, we have:\r\n \\begin{eqnarray*}\r\nE[\\gamma_t]&=& E[W_{N(t)+1} -t]\\\\\r\n&=& E[W_{N(t)+1}] -t\\\\\r\n&=& E[X_1](1+M(t)) -t\r\n \\end{eqnarray*}", "linkability1": 2.0, "linkability2": 1.0, "linkability3": 1.0, "linkability4": 1.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": 0.0, "errors": "", "alternativesolutions": "", "messagefailure": "Oops! Please check the definition of excess life in renewal process.", "messagesuccess": "Congratulations! You have mastered the definition of the renewal process\r\nand known how to use it.", "sensitivity": null, "gussingparameter": null, "difficulty": 1, "calculateddifficulty": null, "linkneuron": [80, 81, 83], "rightproblems": [], "wrongproblems": [167, 168], "twinproblems": [167, 168]}}, {"model": "mathematics.question", "pk": 166, "fields": {"code": "7.1.4", "category": 3, "problem": "Let $ \\gamma_t $ be the excess life and $ \\delta_t $ the age in a renewal process having interoccurrence distribution function $ F(x) $. Determine the conditional probability $ Pr(\\gamma_t>y|\\delta_t = x) $ and the conditional mean $ E[\\gamma_t|\\delta_t =x] $.", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "$ 1-F(x+y) $, $ \\int_{0}^{\\infty}1-F(x+y)dy  $", "choicesb": "$ 1-F(x-y) $, $ \\int_{0}^{\\infty}1-F(x-y)dy  $", "choicesc": "$ 1-F(x+\\frac{1}{2}y) $, $ \\int_{0}^{\\infty}1-F(x+\\frac{1}{2}y)dy  $", "choicesd": "$ 1-F(x-\\frac{1}{2}y) $, $ \\int_{0}^{\\infty}1-F(x-\\frac{1}{2}y)dy  $", "choicese": "None of the above is correct.", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "A", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "With the defintion, we have:\r\n \\begin{eqnarray*}\r\n Pr(\\gamma_t>y|\\delta_t = x) &= & Pr(W_{N(t)+1}>t+y|t = W_{N(t)}+x)\\\\\r\n &=& Pr(W_{N(t)+1}-W_{N(t)}>x+y| W_{N(t)}=t-x)\\\\\r\n &=& Pr(X_{N(t)+1}>x+y|W_{N(t)}=t-x)\\\\\r\n &=& Pr(X_{N(t)+1}>x+y)\\\\\r\n &=& 1 - F(x+y)\r\n \\end{eqnarray*}\r\nAnd \r\n$$ E[\\gamma_t|\\delta_t=x] = \\int_{0}^{\\infty}  Pr(\\gamma_t>y|\\delta_t = x) =\\int_{0}^{\\infty}1-F(x+y)dy $$\r\nSo the right answer is (a).", "linkability1": 3.0, "linkability2": 1.0, "linkability3": 2.0, "linkability4": 1.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": 0.0, "errors": "", "alternativesolutions": "", "messagefailure": "Oops! Please check the definition of the age and excess life in renewal process.", "messagesuccess": "Congratulations! You have mastered the definition of the renewal process\r\nand known how to use it.", "sensitivity": null, "gussingparameter": null, "difficulty": 3, "calculateddifficulty": null, "linkneuron": [76, 83], "rightproblems": [], "wrongproblems": [163], "twinproblems": [163]}}, {"model": "mathematics.question", "pk": 167, "fields": {"code": "7.3.1", "category": 3, "problem": "In another form of sum quota sampling, a sequence of nonnegative independent and identically distributed random variables $ X_1, X_2, \\ldots $ is observed, the sampling continuing until the first time that the sum of the observations exceeds the quota $ t $. In renewal process terminology, the sample size is $ N(t)+1 $. The sample mean is  \r\n$$ \\frac{W_{N(t)+1}}{N(t)+1}=\\frac{X_1+\\cdots+X_{N(t)+1}}{N(t)+1}.$$\r\nAn important question in statistical theory is whether or not this sample mean is unbiased. That is, how does the expected value of this sample mean relate to the expected value of, say, $ X_1 $? Assume that the individual $ X $ summands are exponentially distributed with parameter $ \\lambda $, so that $ N(t) $ is a Poisson process. Evaluate $ E[\\frac{W_{N(t)+1}}{N(t)+1}] $:", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "$ \\frac{1}{\\lambda t}[1-e^{-\\lambda t}](1+\\frac{1}{\\lambda t}) $", "choicesb": "$ [1-e^{-\\lambda t}](1+\\frac{1}{\\lambda t}) $", "choicesc": "$ [1-e^{-\\lambda t}] $", "choicesd": "$ \\frac{1}{\\lambda}[1-e^{-\\lambda t}](1+\\frac{1}{\\lambda t}) $", "choicese": "None of the above is correct.", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "D", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "With the result of erercise 7.3.3. We have $  W_{N(t)+1}$ and $ N(t) $ are independent. So we just need to compute $ E[W_{N(t)+1}] $ and $ E[\\frac{1}{N(t)+1}] $ separately.\r\n $$ E[W_{N(t)+1}] = E[X_1](E[N(t)+1]) = \\frac{1}{\\lambda}(\\lambda t+1)$$and\r\n \\begin{eqnarray*}\r\n E[\\frac{1}{N(t)+1}] &=& \\sum_{k=0}^{\\infty} \\frac{(\\lambda t)^k e^{-\\lambda t}}{k!}\\frac{1}{k+1}\\\\\r\n &=& (\\sum_{k=0}^{\\infty} \\frac{(\\lambda t)^k e^{-\\lambda t}}{k!}-e^{-\\lambda t})\\frac{1}{\\lambda t}\\\\\r\n &=& (1-e^{-\\lambda t})\\frac{1}{\\lambda t}\r\n \\end{eqnarray*}\r\nSo $$ E[\\frac{W_{N(t)+1}}{N(t)+1}] = E[W_{N(t)+1}]E[\\frac{1}{N(t)+1}] = \\frac{1}{\\lambda}[1-e^{-\\lambda t}](1+\\frac{1}{\\lambda t})$$\r\nSo the right answer is (d).", "linkability1": 3.0, "linkability2": 2.0, "linkability3": 1.0, "linkability4": 1.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": 0.0, "errors": "", "alternativesolutions": "", "messagefailure": "Oops! Please check the result of exercise 7.3.3.", "messagesuccess": "Congratulations! You have mastered the definition of the renewal process\r\nand known how to use it.", "sensitivity": null, "gussingparameter": null, "difficulty": 3, "calculateddifficulty": null, "linkneuron": [77, 80, 81], "rightproblems": [], "wrongproblems": [165], "twinproblems": [165]}}, {"model": "mathematics.question", "pk": 168, "fields": {"code": "7.3.2", "category": 3, "problem": "A fundamental identity involving the renewal function, vaild for all renewal processes, is \r\n$$E[W_{N(t)+1}] = E[X_1](M(t)+1).$$\r\nEvaluate the left side the renewal counting process is a Poisson process. $E[W_{N(t)+1}]$ is equal to:", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "$ \\lambda t+1 $", "choicesb": "$  t+\\frac{1}{\\lambda} $", "choicesc": "$ \\lambda t $", "choicesd": "$ e^{-\\lambda t} $", "choicese": "None of the above is correct.", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "B", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "With the defintion of the poisson process, we have:\r\n \\begin{eqnarray*}\r\n E[W_{N(t)+1}] &=& \\int_{0}^{\\infty} P(W_{N(t)+1}>x)dx\\\\\r\n &=& \\int_{0}^{\\infty} P(N(x) < N(t)+1)dx\\\\\r\n &=& t+\\int_{t}^{\\infty}P(N(t-x) < 1)dx\\\\\r\n &=& t+\\int_{t}^{\\infty}e^{-\\lambda (x-t)}dx\\\\\r\n &=& t+\\frac{1}{\\lambda}\r\n \\end{eqnarray*}\r\nSo the right answer is (b).", "linkability1": 2.0, "linkability2": 2.0, "linkability3": 1.0, "linkability4": 1.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": 0.0, "errors": "", "alternativesolutions": "", "messagefailure": "Oops! Please check the knowledge of this part.", "messagesuccess": "Congratulations! You have mastered the knowledge of this part\r\nand known how to use it.", "sensitivity": null, "gussingparameter": null, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [75, 77, 81], "rightproblems": [169], "wrongproblems": [165], "twinproblems": [165]}}, {"model": "mathematics.question", "pk": 169, "fields": {"code": "7.3.3", "category": 3, "problem": "Pulses arrive at a counter according to a Poisson process of rate $ \\lambda $. All physically realizable counters are imperfect, incapable of detecting all signals that enter their detection chambers. After a particle or signal arrives, a counter must recuperate, or renew itself, in preparation for the nest arrival. Signals arriving during the readjustment period, called dead time or locked time, are lost. We must distinguish between the arriving particles and the recorded particles. The experimenter observes only the particles recorded; from this observation he desires to infer the properties of the arrival process.\r\n<br>\r\nSuppose the each arriving pulse locks the counter for a fixed time $ \\tau $. Assume that $ t>\\tau $, determine the probability $ p(t) $ that the counter is free at time $ t $", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "$ e^{-2\\lambda \\tau} $", "choicesb": "$  e^{-\\lambda \\tau}$", "choicesc": "$ e^{-2\\lambda t} $", "choicesd": "$ e^{-\\lambda t} $", "choicese": "None of the above is correct.", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "B", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "With the defintion of the current life $ \\delta_t $, we know that\r\n $$ p(t) = Pr\\{\\delta_t>\\tau\\}$$\r\n For Poisson process, we know that when $ t>\\tau $,\r\n $$ Pr\\{\\delta_t>\\tau\\} = e^{-\\lambda \\tau} $$\r\nSo the right answer is (b).", "linkability1": 2.0, "linkability2": 1.0, "linkability3": 2.0, "linkability4": 2.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": 0.0, "errors": "", "alternativesolutions": "", "messagefailure": "Oops! Please check the knowledge of this part.", "messagesuccess": "Congratulations! You have mastered the knowledge of this part\r\nand known how to use it.", "sensitivity": null, "gussingparameter": null, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [77, 83], "rightproblems": [168], "wrongproblems": [163, 171], "twinproblems": [171]}}, {"model": "mathematics.question", "pk": 170, "fields": {"code": "7.3.4", "category": 3, "problem": "This problem is designed to aid in the understanding of length-biased sampling. Let $ X $ be a uniformly distributed random variable on $ [0,1] $. Then, $ X $ divides $ [0,1] $ into the subintervals $ [0,X] $ and $ (X,1] $. By symmetry, each subinterval has mean length $ \\frac{1}{2} $. Now pick one of these subintervals at random in the following way: Let $  Y $ be independent of $ X $ and uniformly distributed on $ [0,1] $, and pick the subinterval $ [0,X] $ or $ (X,1] $ that $ Y $ falls in. Let $ L $ be the length of the subinterval so chosen. Formally,\r\n\\[  L= \\left\\{\r\n\\begin{array}{ll}\r\nX, & Y\\leq X \\\\\r\n1-X, & Y > X \\\\\r\n\r\n\\end{array} \r\n\\right. \\]\r\nDetermine the mean of $ L $.", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "1/2", "choicesb": "2/3", "choicesc": "3/4", "choicesd": "4/5", "choicese": "5/6", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "B", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "We need to use the tower property of conditional expectation, which is \r\n $$E(L) = E(E(L|X))$$\r\n so \r\n \\begin{eqnarray*}\r\n  E(L) &=& E[E[XPr(Y\\leq X)+(1-X)Pr(Y>X)|X]]\\\\\r\n  &=& E(X^2 +(1-X)^2)\\\\\r\n  &=& 2/3\r\n \\end{eqnarray*}\r\n\r\nSo the right answer is (b).\r\n<br>\r\nIf you are not familiar with conditional expectation, you can compute the expectation directly.", "linkability1": 1.0, "linkability2": 1.0, "linkability3": 2.0, "linkability4": 1.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": 0.0, "errors": "", "alternativesolutions": "", "messagefailure": "Oops! You can check the knowledge of conditional expectation to solve this problem.", "messagesuccess": "Congratulations! You have mastered the knowledge of this part\r\nand known how to use it.", "sensitivity": null, "gussingparameter": null, "difficulty": 3, "calculateddifficulty": null, "linkneuron": [84], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 171, "fields": {"code": "7.3.5", "category": 3, "problem": "Birds are perched along a wire as shown according to a Poisson process of rate $ \\lambda $ per unit distance. At a fixed point t along the wire, let $ D(t) $ be the random distance to the nearest bird. What is the mean value of $ D(t) $? What is the probability density function $ f_t(x) $ for $ D(t) $ when $ 0 < x < t $ ?", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "$E[D(t)] = 1-\\frac{1}{2\\lambda}e^{-2\\lambda t} $ , $  f_t(x) = 1 - e^{-2\\lambda x}$", "choicesb": "$E[D(t)] = 1-\\frac{1}{\\lambda}e^{-\\lambda t} $ , $  f_t(x) = 1 - e^{-\\lambda x}$", "choicesc": "$E[D(t)] = 1-\\frac{2}{\\lambda}e^{-\\frac{1}{2}\\lambda t} $ , $  f_t(x) = 1 - e^{-\\frac{1}{2}\\lambda x}$", "choicesd": "$E[D(t)] = 1-e^{-\\lambda t} $ , $  f_t(x) = 1 - e^{-\\lambda x}$", "choicese": "None of the above is correct.", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "A", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "We need to realize that $ D(t) = \\min\\{\\delta_t, \\gamma_t\\} $. So when $ 0 < x < t $, the density funtion of $ D(t) $ is:\r\n<br>\r\n \\begin{eqnarray*}\r\nP(D(t)\\leq x)&=& 1-P(D(t) >  x)\\\\\r\n&=& 1-P(\\min\\{\\delta_t, \\gamma_t\\}> x)\\\\\r\n&=& 1-P(\\delta_t>x, \\gamma_t> x)\\\\\r\n&=& 1-e^{-2\\lambda x}\r\n \\end{eqnarray*}\r\nAfter knowing the density function, the expectation is easy to compute that  $ E[D(t)] = 1-\\frac{1}{2\\lambda}e^{-2\\lambda t} $.\r\n \r\n\r\nSo the right answer is (a).", "linkability1": 2.0, "linkability2": 2.0, "linkability3": 1.0, "linkability4": 2.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": 0.0, "errors": "", "alternativesolutions": "", "messagefailure": "Oops! Please check the knowledge of this part.", "messagesuccess": "Congratulations! You have mastered the knowledge of this part\r\nand known how to use it.", "sensitivity": null, "gussingparameter": null, "difficulty": 3, "calculateddifficulty": null, "linkneuron": [77, 83], "rightproblems": [], "wrongproblems": [169], "twinproblems": [169]}}, {"model": "mathematics.question", "pk": 172, "fields": {"code": "7.4.1", "category": 3, "problem": "Suppose that a renewal function has form $ M(t) = t +[1-\\exp(-at)] $. Determine the mean and variance of the interoccurrence distribution.", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "$ \\mu = 1, \\sigma^2 = 1 $", "choicesb": "$ \\mu = 1, \\sigma^2 = 3 $", "choicesc": "$ \\mu = 2, \\sigma^2 = 1 $", "choicesd": "$ \\mu = 2, \\sigma^2 = 3 $", "choicese": "None of the above is correct.", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "B", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "With the use of the elementary renewal theorem and refined renewal theorem, this question is very easy.\r\n The theorem tells us that:\r\n $$\\lim_{t\\rightarrow \\infty}\\frac{M(t)}{t} = \\frac{1}{\\mu}$$\r\n and\r\n $$ \\lim_{t\\rightarrow \\infty}[M(t)-\\frac{t}{\\mu}] = \\frac{\\sigma^2-\\mu^2}{2\\mu^2}$$\r\n With the $ M(t) = t +[1-\\exp(-at)] $, we know that \r\n $$ \\frac{1}{\\mu} = 1 $$ and $$  \\frac{\\sigma^2-\\mu^2}{2\\mu^2} = t+1-\\frac{t}{\\mu}.$$\r\n So  $ \\mu = 1, \\sigma^2 = 3 $. So the right answer is (b).", "linkability1": 3.0, "linkability2": 1.0, "linkability3": 1.0, "linkability4": 1.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": 0.0, "errors": "", "alternativesolutions": "", "messagefailure": "Oops! Please see the elementary renewal theorem and refined renewal theorem.", "messagesuccess": "Congratulations! You have already known about  the knowledge of asymptotic behavior of renewal process.", "sensitivity": null, "gussingparameter": null, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [85], "rightproblems": [], "wrongproblems": [173, 174, 175], "twinproblems": [174]}}, {"model": "mathematics.question", "pk": 173, "fields": {"code": "7.4.2", "category": 3, "problem": "A system is subject to failures. Each failure requires a repair time that is exponentially distributed with rate parameter $ \\alpha $. The operating time of the system until the next failure is exponentially distributed with rate parameter $ \\beta $. The repair times and the operating times are all statistically independent. Suppose that the system is operating at time 0. Using refined renewal theorem, determine an approximate expression for the mean number of failures up to time $ t $, the approximation holding for $ t\\gg 0 $.", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "$ \\frac{t\\alpha\\beta}{\\alpha+\\beta}-\\frac{\\alpha\\beta}{(\\alpha+\\beta)^2} $", "choicesb": "$ \\frac{t\\alpha\\beta+\\alpha}{\\alpha+\\beta}-\\frac{\\alpha\\beta}{(\\alpha+\\beta)^2} $", "choicesc": "$ \\frac{t\\alpha\\beta+\\beta}{\\alpha+\\beta}-\\frac{\\alpha\\beta}{(\\alpha+\\beta)^2} $", "choicesd": "$ \\frac{t\\alpha\\beta}{\\alpha+\\beta}-\\frac{\\alpha\\beta}{(\\alpha+\\beta)^2}+1 $", "choicese": "None of the above is correct.", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "C", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "This is a tough question. We use two steps to solve this question: first, with the use of refined renewal theorem, we can compute the mean number of the complement of repair up to time $ t $. Here, we use $ N(t) $ to stand for it. In other word, we account the time of finishing repair machine. With the refined renewal theorem,\r\n $$ \\lim_{t\\rightarrow \\infty}[M(t)-\\frac{t}{\\mu}] = \\frac{\\sigma^2-\\mu^2}{2\\mu^2}$$\r\n SInce our $ X_1 $ here is operating time plus repair time. We know they follow exponential distribution and they are independent. So we have:\r\n $$ \\mu = \\frac{1}{\\alpha}+\\frac{1}{\\beta}, \\sigma^2 = \\frac{1}{\\alpha^2}+\\frac{1}{\\beta^2} $$\r\n So \r\n $$ E[N(t)] = M(t) = \\frac{t\\alpha\\beta}{\\alpha+\\beta}-\\frac{\\alpha\\beta}{(\\alpha+\\beta)^2}  $$\r\n However, please remember we just know the mean number of time of finishing repair machine $ M(t) $, which is not equal to the mean number of failures, which we use $ \\tilde{M}(t) $ to stand for. Our second step is just to know relationship between them. It is not difficult to see that, if at time $ t $, it is the repair time. $ M(t)+1 =\\tilde{M}(t) $. If at time $ t $, it is the operating time. $ M(t) =\\tilde{M}(t) $. We use the event $ A $ to stand that time $ t $  is the repair time. So the $ A^c $ is that time $ t $  is the operating time. So $$ \\tilde{M}(t) = (M(t)+1)P(A)+M(t)P(A^c)$$.\r\n It is easy to compute that $$ P(A) = \\frac{1/\\alpha}{1/\\alpha+1/\\beta}= \\frac{\\beta}{\\alpha+\\beta}, P(A^c) = \\frac{\\alpha}{\\alpha+\\beta}.  $$\r\n So $$\\tilde{M}(t) = \\frac{t\\alpha\\beta+\\beta}{\\alpha+\\beta}-\\frac{\\alpha\\beta}{(\\alpha+\\beta)^2} $$\r\n So the right answer is (c).", "linkability1": 3.0, "linkability2": 3.0, "linkability3": 2.0, "linkability4": 3.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": 0.0, "errors": "", "alternativesolutions": "", "messagefailure": "Oops! Please see the refined renewal theorem.", "messagesuccess": "Congratulations! You have mastered the knowledge of this part.", "sensitivity": null, "gussingparameter": null, "difficulty": 5, "calculateddifficulty": null, "linkneuron": [83, 85], "rightproblems": [], "wrongproblems": [172], "twinproblems": [175]}}, {"model": "mathematics.question", "pk": 174, "fields": {"code": "7.4.3", "category": 3, "problem": "Suppose that the life of a lightbulb is a random variable $ X $ with hazard rate $ h(x) = \\theta x$ for $ x>0 $. Each failed lightbulb is immediately replaced with a new one. Determine an asymptotic expression for the mean age of the lightbulb in service at time $ t $, vaild for $ t\\gg 0 $.", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "$ \\sqrt{\\frac{2}{\\pi\\theta}}$", "choicesb": "$ \\sqrt{\\frac{1}{\\pi\\theta}} $", "choicesc": "$ 2\\sqrt{\\frac{1}{\\pi\\theta}} $", "choicesd": "$ 2\\sqrt{\\frac{2}{\\pi\\theta}} $", "choicese": "None of the above is correct.", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "D", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "It is easy to see that this question just ask us to compute that $ E(\\beta_t) $, which is equal to $ E(\\delta_t) + E(\\gamma_t)$. With $ h(x) =\\theta x $, we know that $ H(X) = \\frac{1}{2}\\theta x^2 $, which is equal to $ -\\ln(1-F(x)) $. So \r\n$$1-F(X) = e^{-\\frac{1}{2}\\theta x^2}$$\r\nSince $$ E(\\delta_t)= E(\\gamma_t) = \\frac{\\sigma^2+\\mu^2}{2\\mu} $$\r\nWith $ 1-F(X) = e^{-\\frac{1}{2}\\theta x^2} $, it is easy to compute that $ \\mu = \\sqrt{\\frac{\\pi}{2\\theta}}, \\mu^2+\\sigma^2 = \\frac{2}{\\theta}$.\r\nSo $ E(\\beta_t) =  2\\sqrt{\\frac{2}{\\pi\\theta}} $. So the right answer is (d).", "linkability1": 3.0, "linkability2": 2.0, "linkability3": 2.0, "linkability4": 1.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": 0.0, "errors": "", "alternativesolutions": "", "messagefailure": "Oops! Please see the asymptotic behavior of Age and Excess life.", "messagesuccess": "Congratulations! You have already known about  the knowledge of asymptotic behavior of renewal process.", "sensitivity": null, "gussingparameter": null, "difficulty": 3, "calculateddifficulty": null, "linkneuron": [83, 85], "rightproblems": [], "wrongproblems": [172, 176], "twinproblems": [172]}}, {"model": "mathematics.question", "pk": 175, "fields": {"code": "7.4.4", "category": 3, "problem": "A developing country is attempting to control its population growth by placing restrictions on the number of children each family can have. This society places a high premium on female children, and it is felt that any policy that ignores the desire to have female children will fail. The proposed policy is to allow any married couple to have children up to the first female baby, at which point they must cease having children. Assume that male and female children are equally likely. The number of children in any family is a random variable $ N $. In the population as a whole, what fraction of children are female? Use the elementary renewal theorem to compute it.", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "1/2", "choicesb": "2/3", "choicesc": "3/4", "choicesd": "4/5", "choicese": "5/6", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "A", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "There is a renewal process inside question where our $ X_1 $ follow geometric distribution with $ p = q = 1/2 $.\r\n This question just ask to compute $ \\frac{M(t)}{t} $. With the use of elementary renewal theorem:\r\n $$\\lim_{t\\rightarrow \\infty}\\frac{M(t)}{t} = \\frac{1}{\\mu}=\\frac{1}{2}$$", "linkability1": 1.0, "linkability2": 1.0, "linkability3": 2.0, "linkability4": 3.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": 0.0, "errors": "", "alternativesolutions": "", "messagefailure": "Oops! Please see the elementary renewal theorem.", "messagesuccess": "Congratulations! You have already known about  the knowledge of asymptotic behavior of renewal process.", "sensitivity": null, "gussingparameter": null, "difficulty": 3, "calculateddifficulty": null, "linkneuron": [85], "rightproblems": [], "wrongproblems": [172], "twinproblems": [173]}}, {"model": "mathematics.question", "pk": 176, "fields": {"code": "7.4.5", "category": 3, "problem": "A Markov chain $ X_0, X_1, X_1,\\ldots $ has the transition probability matrix\r\n $$ \\qquad  \\,\\, \\,\\,\\, 0\\qquad 1\\qquad 2  $$\r\n$${ P} =\\matrix{ 0 \\cr 1 \\cr 2    }\r\n\\pmatrix{\r\n\t0.3 &  0.7  &  0              \\cr\r\n\t0.6\t&   0  &  0.4      \\cr\r\n\t0\t &   0.5  &   0.5          \\cr\r\n}\r\n$$\r\nA sojourn in a state is an uninterrupted sequence of consecutive visits to that state. Determine the mean duration of a typical sojourn in state 0, which we use $ x $ to stand for. And determine the long run fraction of time that the process is in state 1, which we use $ y $ to stand for. Compute the value of $ x $ and $ y $.", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "$ x = 10/3, y = 35/93$", "choicesb": "$ x = 10/7, y=35/93$", "choicesc": "$ x= 10/3, y = 58/93 $", "choicesd": "$ x = 10/3, y = 58/93 $", "choicese": "None of the above is correct.", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "B", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "$ x $ is easy to compute. We can regard the number of duration of sojourn in state 0 as a geometric distribution with $ p = 0.3, q = 0.7 $. So the $ x = 10/7 $. With the knowledge of renewal theory, we know $y= \\pi_1$ where $ \\pi $ satisfy that:\r\n$$ \\pi P = \\pi $$\r\nSo $ \\pi_0 = 10/31, \\pi_1 = 35/93, \\pi_2 = 28/93 $. So our answer is (b).", "linkability1": 3.0, "linkability2": 2.0, "linkability3": 2.0, "linkability4": 1.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": 0.0, "errors": "", "alternativesolutions": "", "messagefailure": "Oops! Please review the renewal theorem.", "messagesuccess": "Congratulations! You have already known about  the knowledge of asymptotic behavior of renewal process.", "sensitivity": null, "gussingparameter": null, "difficulty": 3, "calculateddifficulty": null, "linkneuron": [85], "rightproblems": [], "wrongproblems": [174], "twinproblems": []}}, {"model": "mathematics.question", "pk": 195, "fields": {"code": "5.2.1", "category": 3, "problem": "Let $X(n,p)$ have a binomial distribution with parameters $n$ and $p$. Let $n\\to\\infty$ and $p\\to0$ in such a way that $np=\\lambda$.  Calculate\r\n\\begin{equation*}\r\n\\lim_{n\\to\\infty}\\text{Pr}\\{X(n,p)=0\\}\r\n\\end{equation*}\r\nand \r\n\\begin{equation*}\r\n\\lim_{n\\to\\infty}\\frac{\\text{Pr}\\{X(n,p)=k+1\\}}{\\text{Pr}\\{X(n,p)=k\\}}\r\n\\end{equation*}", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "\\begin{equation*}\r\n\\lim_{n\\to\\infty}\\text{Pr}\\{X(n,p)=0\\}=\\lambda\r\n\\end{equation*}\r\n\\begin{equation*}\r\n\\lim_{n\\to\\infty}\\frac{\\text{Pr}\\{X(n,p)=k+1\\}}{\\text{Pr}\\{X(n,p)=k\\}}=\\frac{\\lambda}{k}\r\n\\end{equation*}", "choicesb": "\\begin{equation*}\r\n\\lim_{n\\to\\infty}\\text{Pr}\\{X(n,p)=0\\}=e^{-\\lambda}\r\n\\end{equation*}\r\n\\begin{equation*}\r\n\\lim_{n\\to\\infty}\\frac{\\text{Pr}\\{X(n,p)=k+1\\}}{\\text{Pr}\\{X(n,p)=k\\}}=\\frac{\\lambda}{k}\r\n\\end{equation*}", "choicesc": "\\begin{equation*}\r\n\\lim_{n\\to\\infty}\\text{Pr}\\{X(n,p)=0\\}=\\lambda\r\n\\end{equation*}\r\n\\begin{equation*}\r\n\\lim_{n\\to\\infty}\\frac{\\text{Pr}\\{X(n,p)=k+1\\}}{\\text{Pr}\\{X(n,p)=k\\}}=\\frac{\\lambda}{k+1}\r\n\\end{equation*}", "choicesd": "\\begin{equation*}\r\n\\lim_{n\\to\\infty}\\text{Pr}\\{X(n,p)=0\\}=e^{-\\lambda}\r\n\\end{equation*}\r\n\\begin{equation*}\r\n\\lim_{n\\to\\infty}\\frac{\\text{Pr}\\{X(n,p)=k+1\\}}{\\text{Pr}\\{X(n,p)=k\\}}=\\frac{\\lambda}{k+1}\r\n\\end{equation*}", "choicese": "None of the above", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "D", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "\\begin{equation*}\r\n\\lim_{n\\to\\infty}\\text{Pr}\\{X(n,p)=0\\}=(1-p)^n=(1-\\frac{\\lambda}{n})^n=e^{-\\lambda}\r\n\\end{equation*}\r\n\\begin{align*}\r\n\\lim_{n\\to\\infty}\\frac{\\text{Pr}\\{X(n,p)=k+1\\}}{\\text{Pr}\\{X(n,p)=k\\}}&=\\frac{\\frac{n!}{(k+1)!(n-k-1)!}p^{k+1}(1-p)^{n-k-1}}{\\frac{n!}{(k)!(n-k)!}p^{k}(1-p)^{n-k}}\\\\&=\\frac{n-k}{k+1}\\frac{p}{1-p}\\\\\r\n&=\\frac{n-k}{k+1}\\frac{\\lambda/n}{1-\\lambda/n}\\\\\r\n&\\approx\\frac{\\lambda}{k+1}\r\n\\end{align*}", "linkability1": 0.0, "linkability2": 0.0, "linkability3": 0.0, "linkability4": 0.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "An alternative solution is to derive the Poisson distribution from Binomial distribution. Please check Proposition 5.1 on lecture note. Here we provide another derivation using the Stirling approximation.\r\nFor binomial distribution with probability p and total number of events n, \r\n\\begin{equation*}\r\nP(k)=\\binom{n}{k}p^k(1-p)^{n-k}=\\frac{n!}{k!(n-k)!}p^k(1-p)^{n-k}\r\n\\end{equation*}\r\nSince $n$ is large, we take Stirling approximation to $n!$ and $(n-k)!$ so that\r\n\\begin{equation*}\r\nn!\\approx\\sqrt{2\\pi n}(\\frac{n}{e})^n \\qquad (n-k)!\\approx\\sqrt{2\\pi (n-k)}(\\frac{n-k}{e})^{n-k}\\approx\\sqrt{2\\pi n}(\\frac{n-k}{e})^{n-k}\r\n\\end{equation*}\r\nBefore we go into the algebra, keep in mind that $\\left(1+\\frac{a}{n}\\right)^n=\\left(1-\\frac{a}{n}\\right)^{-n}=e^a$. <br> What we do is to: <br>\r\n1. Turn $p$ into $\\frac{\\lambda}{n}$ <br>\r\n2. Group terms into power of $n$ or power of $k$\r\n\\begin{align*}\r\nP(k)&=\\frac{n!}{k!(n-k)!}p^k(1-p)^{n-k}\\\\\r\n&=\\frac{(\\frac{n}{e})^n}{k!(\\frac{n-k}{e})^{n-k}}p^k(1-p)^{n-k}\\\\\r\n&=\\frac{1}{k!}(\\frac{n}{n-k})^n(n-k)^ke^{-k}p^k(1-p)^{n}(1-p)^{-k}\\\\\r\n&=\\frac{1}{k!}(1-\\frac{k}{n})^{-n}(n-k)^ke^{-k}(\\frac{\\lambda}{n})^k(1-\\frac{\\lambda}{n})^{n}(1-\\frac{\\lambda}{n})^{-k}\\\\\r\n&=\\frac{1}{k!}e^{k}(n-k)^ke^{-k}(\\frac{\\lambda}{n})^ke^{-\\lambda}(1-\\frac{\\lambda}{n})^{-k}\\\\\r\n&=\\frac{1}{k!}e^{-\\lambda}(n-k)^k(\\frac{\\lambda}{n})^k(\\frac{n}{n-\\lambda})^{k}\\\\\r\n&=\\frac{1}{k!}e^{-\\lambda}(\\frac{n-k}{n-\\lambda})^k\\lambda^k\\\\\r\n&\\approx \\frac{e^{-\\lambda}\\lambda^k}{k!}\r\n\\end{align*}\r\nOnce we get the Poisson distribution, we have \r\n\\begin{equation*}\r\n\\lim_{n\\to\\infty}\\text{Pr}\\{X(n,p)=0\\}=\\frac{\\lambda^0}{0!}e^{-\\lambda}=e^{-\\lambda}\r\n\\end{equation*}\r\nand\r\n\\begin{equation*}\r\n\\lim_{n\\to\\infty}\\frac{\\text{Pr}\\{X(n,p)=k+1\\}}{\\text{Pr}\\{X(n,p)=k\\}}=\\frac{\\lambda^{k+1}}{\\lambda^k}\\frac{1/(k+1)!}{1/k!}=\\frac{\\lambda}{k+1}\r\n\\end{equation*}", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": null, "difficulty": 3, "calculateddifficulty": null, "linkneuron": [62, 63, 65, 66, 68, 69], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}, {"model": "mathematics.question", "pk": 196, "fields": {"code": "5.2.4", "category": 3, "problem": "Suppose that N points are uniformly distributed over the interval\r\n$[0, N)$. Determine the probability distribution for the number of points k in\r\nthe interval $[0, 1)$ as $N\\to\\infty$.", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "$1/N$", "choicesb": "$\\frac{e^{-k}}{k!}$", "choicesc": "$\\frac{e^{-1}}{k!}$", "choicesd": "$(\\frac{1}{N})^k$", "choicese": "None of the above", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "C", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "Consider the question this way:\r\nFor each point, it has a probability p fall into the interval $[0,1)$ and probability 1-p fall outside the interval $[0,1)$. The uniformly distributed condition give you $p=1/N$. Therefore, it is just a binomial distribution. <br>\r\nAs N tends to infinity, you know $p=1/N$ go to 0, so it must converge to a Poisson distribution. $\\lambda=pN=1$. The distribution is, therefore, $\\frac{1^k}{k!}e^{-1}=\\frac{e^{-1}}{k!}$", "linkability1": 0.0, "linkability2": 0.0, "linkability3": 0.0, "linkability4": 0.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": null, "difficulty": 3, "calculateddifficulty": null, "linkneuron": [63, 66], "rightproblems": [], "wrongproblems": [], "twinproblems": [197]}}, {"model": "mathematics.question", "pk": 197, "fields": {"code": "5.2.7", "category": 3, "problem": "$N$ bacteria are spread independently with uniform distribution on a\r\nmicroscope slide of area A. An arbitrary region having area $a$ is selected for\r\nobservation. Determine the probability of $k$ bacteria within the region of\r\narea $a$. Show that as $N\\to\\infty$ and $a\\to0$ such that $(a/A)N\\to c$ ($0<c<\\infty$),\r\nthen $p(k)\\to e^{-c}c^k/k!$", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "$P(k)=\\frac{(N)^ke^{-N}}{k!}$", "choicesb": "$P(k)=\\frac{((a/A)N)^ke^{-(a/A)N}}{k!}$", "choicesc": "$P(k)=\\frac{((a/A))^ke^{-(a/A)}}{k!}$", "choicesd": "$P(k)=aN/A$", "choicese": "None of the above", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "B", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "The probability p of one bacteria being selected is $a/A$. As N go to infinity, it turns from a binomial distribution (selected vs not selected) to a Poisson distribution. $\\lambda=pN=(a/A)N$, so $P(k)=\\frac{((a/A)N)^ke^{-(a/A)N}}{k!}$", "linkability1": 0.0, "linkability2": 0.0, "linkability3": 0.0, "linkability4": 0.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": null, "difficulty": 3, "calculateddifficulty": null, "linkneuron": [], "rightproblems": [], "wrongproblems": [], "twinproblems": [196]}}, {"model": "mathematics.question", "pk": 236, "fields": {"code": "5.1.4", "category": 3, "problem": "The probability generating function of Poisson process is given by \r\n\\begin{equation*}\r\ng(s)=E[s^X]=e^{-\\mu(1-s)}\r\n\\end{equation*}\r\n<br>\r\nLet $X$ and $Y$ be independent random variables, Poisson distributed with parameters $\\alpha$ and $\\beta$, respectively. Calculate the generating function of their sum.", "problempicture1": "", "problempicture2": "", "problempicture3": "", "problempicture4": "", "problempicture5": "", "problempicture6": "", "choicesa": "\\begin{equation*}\r\ng_N(s)=e^{-(\\alpha+\\beta)(1-s)}\r\n\\end{equation*}", "choicesb": "\\begin{equation*}\r\ng_N(s)=e^{-(\\alpha\\beta)(1-s)}\r\n\\end{equation*}", "choicesc": "\\begin{equation*}\r\ng_N(s)=e^{-(\\alpha)(1-e^{-\\beta(1-s)})}\r\n\\end{equation*}", "choicesd": "None of the above", "choicese": "", "choicesf": "", "choicepicturea": "", "choicepictureb": "", "choicepicturec": "", "choicepictured": "", "choicepicturee": "", "choicepicturef": "", "answer": "A", "solutionspicture1": "", "solutionspicture2": "", "solutionspicture3": "", "solutions": "For the probability generating function of the sum of two independent distributions, we are calculating\r\n\\begin{equation*}\r\nE[s^{X+Y}]=E[s^X]E[s^Y]\r\n\\end{equation*}\r\nTherefore,\r\n\\begin{equation*}\r\ne^{-\\alpha(1-s)}e^{-\\beta(1-s)}=e^{-(\\alpha+\\beta)(1-s)}\r\n\\end{equation*}", "linkability1": 0.0, "linkability2": 0.0, "linkability3": 0.0, "linkability4": 0.0, "linkability5": 0.0, "linkability6": 0.0, "linkpersonaility": null, "errors": "", "alternativesolutions": "", "messagefailure": "", "messagesuccess": "", "sensitivity": null, "gussingparameter": null, "difficulty": 2, "calculateddifficulty": null, "linkneuron": [], "rightproblems": [], "wrongproblems": [], "twinproblems": []}}]
export default data;